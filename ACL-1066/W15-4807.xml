<sec_map><section><chunk>Grammar Design with Multi-tape Automata and Composition Mans Hulden University of Colorado Boulder mans.hulden@colorado.edu Abstract In this paper we show how traditional composition-based finite-state grammars can be augmented to preserve intermediate results in a chain of compositions. These intermediate strings can be very helpful for various tasks: enriching information while parsing or generating, providing ac- curate information for debugging purposes as well as offering explicit alignment in- formation between morphemes and tags in morphological grammars. The imple- mentation strategies discussed in the paper hinge on a representation of multi-tape au- tomata as a single-tape automaton. A sim- ple composition algorithm for such multi- tape automata is provided. </chunk></section><section><heading>1 Introduction </heading><chunk>Applications for morphological and phonological analysis using finite-state techniques tend to fol- low established design patterns based on the com- position of transducers that encode morphotac- tics and morphophonological alternations. Not counting a few exceptions that concern noncon- catenative morphologies, this well-established ap- proach is indeed quite successful and streamlined in the domain of morphophonology if the goal is to produce a monolithic transducer that provides mappings between lemmas/tags and actual surface forms of words. Some types of grammatical information are dif- ficult to include in such a design, however. In morphological modeling, one may want to recover the alignment of morphological tags to the actual morphemes; in phonological modeling, one may want to recover intermediate representations that show how a particular phonological alternation targets specific segments in a word, what order phonological alternations occurred in, and what they were conditioned on. The ability to do so would make finite-state devices more attractive for linguistic research, where computational methods could help streamline the work of lining up large amounts of data and testing hypothetical gener- alizations; it might therefore increase linguists use of finite-state methods, whose potential has to date been underexploited in the linguistics litera- ture (Karttunen, 2003). In this paper, we argue that a multi-tape model constructed by composition of individual multi- tape lexicon or alternation transducers offers a simple framework that addresses the problem of intermediate forms, while at the same time re- taining the straightforward design of morphol- ogy and morphophonology. Apart from expand- ing the expressive power of the grammar, the method also offers the grammar designer the op- tion to re-convert the multi-tape grammar to a sim- ple underlying-to-surface transducer, if desired as may be the case if the multi-tape representation is only used for obtaining debugging information. When drafting a morphological grammar, de- bugging the alternation rules and lexicon descrip- tion becomes much less burdensome under the multi-tape model, since information about each step in the process of mapping from underlying to surface form is retained and is available for in- spection. 1 </chunk></section><section><heading>2 Traditional rewrite-rule grammars </heading><chunk>A significant portion of morphological analysis tools are written with the design alluded to above: (1) a transducer that encodes morphotactics and tag sequences, and (2) a series of transducers that model morphophonological/orthographic alterna- tion. The latter may be expressed as Sound Pattern of English-inspired rewrite rules (Chomsky and Halle, 1968) or as two-level parallel constraints </chunk></section><section><chunk>1 The code and the examples in this paper are available at http://foma.googlecode.com  tupalan-uo papi-uo pulpu-un pulpu kiuikiui muNkumuNku Underlying form tupalankuo /k/-epenthesis papiwuo /w/-epenthesis pulpun Vowel Deletion pulpa kiuikiu muNkumuNka Final Lowering kiuikiu muNkumuNk Apocope muNkumuN Cluster Reduction muNkumu Non-apical Truncation kiuikio Sonorantization tupalankuo papiwuo pulpun pulpa kiuikio muNkumu Surface form Table 1: Interaction of multiple phonological processes in Lardil. (Koskenniemi, 1983), the former being the ar- guably more popular choice at present. The result of composing the lexicon transducer and the mor- phophonological transducers is one monolithic transducer that directly performs the bidirectional mapping from underlying-to-surface forms (gen- eration) and vice versa (parsing). The prevalence of this design is probably partly due to known algorithms (Kaplan and Kay, 1994; Kempe and Karttunen, 1996; Mohri and Sproat, 1996; Hulden, 2009a) or software tools designed around this paradigm (such as Xeroxs lexc/xfst/twol (Beesley and Karttunen, 2003), foma (Hulden, 2009b), or Kleene (Beesley, 2012)). In the following, we shall assume the more common rewrite-rule paradigm. Table 1 illustrates this standard design using some example words from a grammar of Lardil an example language often used to illustrate com- plex rule ordering and word-final phonology with rules that are sensitive to ordering. The original data stems from Hale (1973), and we follow anal- yses by Kenstowicz and Kisseberth (1979); Hayes (2011); Round (2011). Due to the rich interaction of word-final deletion rules, this is a widely used data set that has been a target of many analyses, all of which illustrate the difficulty of marshaling a complex set of phonological alternations. To ex- plain the workings of the grammar, we show all the intermediate steps in mapping from lemma- and-inflection forms to actual surface realizations. In actuality, if modeled by transducer composi- tion, all the intermediate forms are lost through the composition process, which is one of the short- comings addressed below. That is, a final compos- ite transducer simply provides mappings between parse and surface. For phonological analysis, pos- sible grammar debugging, and perhaps language documentation purposes, it would be very desir- able to be able to produce a rich representation such as the one in table 1 from either an underly- ing form (morphological information) or the sur- face form showing all the processes that the word undergoes step-by-step. Under the standard composition model, there is no easy way to do this, save by applying an un- derlying form to each of the individual transduc- ers representing the alternation rules in order, sav- ing the results, and passing them on as input to the next transducer. However, in the inverse di- rection, such a strategy is not directly feasible, in addition to the fact that not composing the trans- ducers partly defeats the purpose of using a finite- state model in the first place. There is no principled reason, however, why the composition algorithm should destroy the interme- diate representations if they are desired later. In other words, when creating a composite transducer modeling x:z from transducers x:y and y:z, one can in principle expand the composition algorithm to yield x:y:z in some representation, retaining all the intermediate information. </chunk></section><section><heading>3 Previous work </heading><chunk>The importance of the preservation of intermediate results in composition has been noted and partly addressed in Kempe et al. (2004), among others. Our formulation below differs in representation and algorithms, and also in that it is intended to be simple and easily implementable without spe- cial algorithms for multi-tape automata, i.e. only using established algorithms for single-tape au- tomata and transducers. We use the representation of Hulden (2009a) for multi-tape automata. In that work, conversion from transducers is not consid- ered, and no composition algorithm is given, as the assumption is that multi-tape automata are con- structed through intersections of constraints on co- AB Concatenation A|B Union A * Kleene Star  A Complement ? Any symbol in alphabet 0 The empty string (epsilon) Ak k-ary concatenation % Escape symbol [ and ] Grouping brackets A:B Cross product A/B A ignoring intervening B T.2 Output projection of T A -&gt; B Rewrite A as B || C _ D Context specifier .#. End or beginning of string def F(X1,...,Xn) definition of macro def X definition of language constant Table 2: Regular expression notation in xfst/foma. occurrence of symbols on the various tapes, akin to two-level grammars. 4 Notation We assume familiarity with regular expression no- tation to construct automata and transducers. For ease of replication, we employ the Xerox regular expression notation (Beesley and Karttunen, 2003) to define and manipulate automata and transducers in this paper; the examples should be directly com- pilable with the xfst or foma tools. The formalism used is summarized in table 2. Multi-tape addi- tions are implemented through a Python interface discussed in section 8. 5 A multi-tape encoding In the following we will assume a relatively sim- ple interleaving encoding of a multi-tape automa- ton and represent one as a single-tape automaton where the length of any accepted string is always an even multiple of the number of tapes. Infor- mally, the automaton first encodes the first column of the legal contents of an n-tape multi-tape au- tomaton, top-down, then the second column, etc. etc. Every symbol in position k in the single-tape representation corresponds toin the case of n tapesposition k/n on tape (k mod n). We assume a special representation for empty symbols (-symbols) in the single-tape model, and repre- sent them with the symbol . A string of length ln in the single-tape representation would corre- spond to the multi-tape representation as follows, where, in parentheses, the tape number is shown first, followed by the symbol position in the multi- tape representation. T 0 (0,0) (1,0) . . . (l,0) . . . T n1 (0,n 1) (1,n 1) . . . (l, n 1) T n (0,n) (1,n) . . . (l, n) For example, if a single-tape representation contains in its language the string abcde, this corresponds to a valid configuration a d b e c seen from the multi-tape point-of-view (a 3-tape configuration); i.e. a multi-tape automaton that ac- cepts the string ad as input, translates it into be, and then translates this into c (the -symbol rep- resenting the empty string). </chunk></section><section><heading>5.1 Conversion from transducers </heading><chunk>An existing transducer can evidently be converted to this multi-tape representation that is, to a 2- tape representationwithout much effort. To con- vert a transducer where transitions are encoded as symbol pairs, one simply expands each sym- bol pair x:y to a two-symbol sequence x y in the corresponding n-tape automaton. We call this op- eration flattening. If the original transducer T maps a string x 1 . . . x n to y 1 . . . y n by a sequence of transitions with labels ((x 1 , y 1 ), . . . , (x n , y n )), then the automaton flatten(T) accepts a string (x 1 y 1 . . . x n y n ). In the result, -symbols are re- placed with the -symbol. So-called UNKNOWN symbolsin the Xerox formalism, placeholders for future alphabet expansion in incremental con- struction of automata (Beesley and Karttunen, 2003), which we denote by ? in regular expres- sions and @ in automatacan be retained as is. Conversion of transducers is particularly con- venient since we can take advantage of existing algorithms for building complex transducers for NLP use. This includes replacement-rule trans- ducers available in many toolkits, as well as lex- icon transducers constructed through essentially right-linear grammars. Figure 1 shows a replace- ment rule compiled into a transducer, and the re- sult of subsequently converting that transducer to a 2-tape automaton in the encoding used here. </chunk></section><section><heading>6 Multi-tape composition </heading><chunk>Interestingly, a multi-tape composition algorithm in this representation can be encoded entirely al- 0 @ 1 x 2 &lt;x:0&gt; @ x &lt;x:0&gt; 0 1 @ 2 x @ 3 4 x @ x x -&gt; || _ .#. flatten(x -&gt; || _ .#.) Figure 1: Illustration of a replacement-rule en- coded as a transducer (left) and subsequently con- verted to a 2-tape automaton using the encoding presented here. multi-tape composition 1 ### Assume m-tape automaton A ### 2 ### and n-tape automaton B as input ### 3 4 def eInsertA [0:2^m [0:?^(n-1)-0:2^(n-1)]]; 5 def PadA [?^m 0:?^(n-1)]; 6 7 def eInsertB [[0:?^(m-1) - 0:2^(m-1)] 0:2^n]; 8 def PadB [0:?^(m-1) ?^n]; 9 10 def ExtendA [A .o. [eInsertA|PadA] * ].2; 11 def ExtendB [B .o. [eInsertB|PadB] * ].2; 12 13 def Sync ?^(m+n-1); 14 15 ### Define composition filter ### 16 def X0 ?^(m-1) 2^n ; 17 def XY [?^(m-1) - 2^(m-1)] 2 [?^(n-1) - 2^(n-1)]; 18 def 0Y 2^m ?^(n-1) ; 19 20 def Filter ~[Sync * [0Y [X0|XY] | X0 [0Y|XY]] ? * ]; 21 def Composition ExtendA &amp; ExtendB &amp; Filter ; Figure 2: The multi-tape composition algorithm in Xerox notation. The variables m and n in- terspersed in the regular expressions denote the number of tapes assumed to be present in the two multi-tape automata to be composed. gebraically, which is to say, as regular expressions. Given two multi-tape automata A and B encoded as above, each representing some specified num- ber of tapes m and n, the core idea is to break down their composed representation as the follow- ing process, which returns an m + n 1 tape rep- resentation of the composite. 1. Force automata A and B to be of the same number of tapes (m + n 1) by alternatively inserting columns of empty () symbols fol- lowed (in A) or preceded (in B) by arbitrary symbols, or retaining the original columns in A an B but inserting arbitrary symbols after each column (in A) or before each column (in B). </chunk></section><section><heading>2. Call the new automata A </heading><chunk>extend and B extend : now, the result of intersecting the two A extend B extend (using standard automa- a b c d e c x x z u x w w w ? ? ? ? ? ? ? ? ? ? ? ? a b c ? ? ? A B epsilon-insertion padding padding c x x z u x w w w a b d e a a a a b b b c c c c A Figure 3: Illustration of multi-tape composition: the shaded areas show possible contents of the original multi-tape automata A and B, while the remaining areas show the result of insertions to co- erce the automata to have the same dimensions and epsilon-behavior before intersection of A and B. ton intersection) represents their composition A M T B, seen from a multi-tape point of view (with intermediate steps retained). An illustration of the main logic behind the padding and column insertion mechanisms is given in figure 3. </chunk></section><section><heading>6.1 Path filtering </heading><chunk>A well known problem of standard composition algorithms for transducers also carries over to the multi-tape representation; this is the problem of producing multiple alternate paths in the result- ing transducer when epsilon-symbols are present (-multiplicity). The cause of this is that there exist many equivalent paths that yield the same transduction: e.g. a: :b can be represented as a:b, a sequence a: :b, or a sequence :b a:; figure 4 illustrates different but equivalent out- puts for the composition of two multi-tape au- tomata. None of the multiple paths for describ- ing a relation are incorrect, but the inconvenience of handling the possibility of multiple equiva- lent parses or generations motivates an attempt to provide unambiguous paths for each composi- tion during the process itself. Furthermore, in a weighted automaton/transducer scenariowhich we will not specifically deal with hereuse of a non-idempotent semiring can yield incorrect re- sults if multiple paths are not filtered out. The common solution in the classical transducer domain is to either design a separate filter trans- A B a d b e c c z w x u w x x w A MT B a d b e c z w x u w x x w a d b e c z w x u w x x w a d b e c z w x u w x x w a d b e c z w x u w x x w a d b e c z w x u w x x w Figure 4: Various solutions to the composition of two multi-tape automata A and B, illustrating different alignments of epsilon-symbols. Here, what is shown is composition behavior with respect to two par- ticular configurations in A and B, for the purposes of illustration. A subsequent filter, expressed as an automaton, removes all the solutions except the leftmost one. ducer that serves to prefer some order of epsilon- interleaving (Mohri et al., 2002) or to incorporate this filter mechanism directly into the composition algorithm (Hulden, 2009a). In the multi-tape case, however, this filtering mechanism can be encoded entirely as a regular language filter which disal- lows certain interleavings of epsilon-symbols, in particular those where an x:-transition (when au- tomaton A has an epsilon on the last tape in some position) immediately follows or precedes a :y- transition (when automaton B inserts a symbol on its first pair of tapes). This filter can then be inter- sected with the output of the earlier algorithm. As mentioned, this regular expression (Filter) can simply be intersected with the earlier result to re- move redundant paths in the composition (shown in lines 16-20 in the algorithm). An implementa- tion of the composition algorithm including filter- ing of multiple paths is given in figure 2 using the Xerox notation. </chunk></section><section><heading>7 Composition in grammars </heading><chunk>The composition algorithm is the only extension needed to retain all the intermediate information in an ordered rewrite-rule grammar. One can sim- ply convert any individual transducers to a multi- tape representation and proceed with the compo- sition, yielding a multi-tape representation of the same grammar. Parsing and generation of a string s can be performed by creating a padded multi- tape automaton where either the underlying repre- sentation or the surface representation is in place, with arbitrary symbols present on the other tapes. This multi-tape automaton can then be intersected with the grammar G, yielding a string representa- tion of the set of legal parses or generations, with their intermediate representations intact. parsing def Parse(s, G) [s .o. [0:?^(n-1) ?] * ].2/2 &amp; G; generation def Gen(s, G) [s .o. [? 0:?^(n-1)] * ].2/2 &amp; G; </chunk></section><section><heading>7.1 Adding intermediate information </heading><chunk>It was hinted above that annotating the effect of various transducers is a very useful feature (as seen in Figure 1) for debugging or phonological analysis. Incorporating such information can be done separately from the multi-tape encoding; that is, one can first incorporate the desired informa- tion in a standard transducer and subsequently per- form the conversion to a multi-tape representation. For morphophonological processes, it suffices to modify the transducers that encode the relevant replacement rules in such a way as to add infor- mation about each process. In most cases, this would only entail naming the process in question. Such an annotation mechanism can be encoded in a macro/function in the xfst/foma formalism: def Mark(Rule, L, B) [Rule (B:0 ?:0 | B ?:L | 0:B 0:L)] &amp; [\B * (B:0 ?:0) | [?-B] * [0:?|?:0|?:?-?] [[?-B]:[?-B]|?:0|0:?] * [0:B 0:L | B ?:L] ]; Here, each alternation rule transducer is aug- mented with the following behavior: at the end of the string a label (L) is appended, preceded by a boundary mark (B). If another label is al- ready present (from a previous process in a chain of compositions), that label is simply replaced with the current label. If the rule doesnt fire (doesnt change anything for a particular input string), nothing is appended and any existing la- bels are removed. For example, a rule that deletes the latter of con- secutive vowels could be encoded as follows: def VD Mark([ V -&gt; 0 || V _ ], "Vowel Del", "#"); and would have the following effect on input words (a) papiin and (b) papi, respectively: (a) (b) p a p i i n p a p i p a p i n # Vowel Del p a p i 8 Implementation As the tools xfst, foma, and OpenFST have ex- isting Python bindings that can be used to call the underlying algorithms, we have implemented the multi-tape automaton encoding as a separate Python-class (data type) MTFSM. This allows for a certain level of transparency in the bookkeep- ing needed. For example, the information about how many tapes are encoded in an FSM is auxil- iary information that it is necessary to store during a composition process, since the multi-tape encod- ing does not inherently contain this information. A simple interface to the xfst/foma formalism allows for transparent conversion of transducers to 2-tape automata, which may then be incrementally com- posed to yield representations with multiple tapes: &gt;&gt;&gt; r1 = MTFSM("x -&gt; y || c _ ") &gt;&gt;&gt; r2 = MTFSM("y -&gt; z || _ d") &gt;&gt;&gt; composed = r1.compose(r2) &gt;&gt;&gt; print composed States: 35 Transitions: 126 Final states: 7 Deterministic: 1 Minimized: 1 Numtapes: 3 &gt;&gt;&gt; composed.generate("c x d") c x d c y d c z d </chunk></section><section><heading>8.1 An example </heading><chunk>Returning now to the original Lardil example; annotating replacement rules with additional de- scriptive symbols to be inserted at the ends of strings every time a rule fires in combination with the multi-tape composition mechanism allows us to essentially automatically replicate the linguist- friendly representation given in table 1. Table 3 shows an example parse of the word undergoing the largest number of alternations given earlier, il- lustrating the output of the multi-tape generation where each intermediate result occupies a tape. lardil.generate("muNkumuNku") m u N k u m u N k u m u N k u m u N k u m u N k u m u N k u m u N k u m u N k u m u N k u m u N k u m u N k u m u N k a # Final Lowering m u N k u m u N k # Apocope m u N k u m u N # Cluster Reduction m u N k u m u # Non-apical truncation m u N k u m u m u N k u m u Table 3: Illustration of generating a word with the multi-tape encoding. This is the result of a standard composed transducer-grammar, con- verted to a multi-tape representation, with replace- ment rules also appending their own descriptions to an input string in case they fire. </chunk></section><section><heading>9 Conclusion </heading><chunk>We have proposed a general method for construct- ing finite-state grammars in the composed rewrite- rule tradition. The method in effect replaces the use of transducers with multi-tape automata. Existing algorithms for constructing transducers from rewrite-rule specifications can still be used if converted to multi-tape representations. The model itself assumes little machinery beyond the ability to compose the resulting multi-tape au- tomata, but offers a way to produce rich represen- tations of grammars constructed in this vein. If desired (for memory efficiency reasons) the result- ing multi-tape automata can still be re-converted to transducers by eliminating the intermediate repre- sentations. This offers the possibility to only use the multi-tape representation for debugging pur- poses, if the final intent is to produce a simpler underlying-to-surface mapping, or vice versa. The above techniques may be useful for other applications as well. In modeling historical sound changes, for example, debugging problems sim- ilar to those in phonology and morphology tend to arisemuch exacerbated by the fact that one is often dealing with multiple languages at the same time. Keeping track of hundreds of proposed sound laws together with their effect on lexical items across languages is a task that is well suited for the type of modeling presented in this paper. Although the application focus of this paper has been more along the lines of modeling tra- ditional non-probabilistic grammars, the meth- ods presented abovethe composition algorithm in particularare also adaptable to weighted au- tomata. References Beesley, K. R. (2012). Kleene, a free and open-source language for finite-state program- ming. In 10th International Workshop on Finite State Methods and Natural Language Process- ing (FSMNLP), pages 5054. Beesley, K. R. and Karttunen, L. (2003). Finite State Morphology. CSLI Publications, Stan- ford, CA. Chomsky, N. and Halle, M. (1968). The Sound Pattern of English. Harper &amp; Row. Hale, K. (1973). Deep-surface canonical dispari- ties in relation to analysis and change: An Aus- tralian example. Current trends in linguistics, 11:401458. Hayes, B. (2011). Introductory Phonology. John Wiley &amp; Sons. Hulden, M. (2009a). Finite-state Machine Con- struction Methods and Algorithms for Phonol- ogy and Morphology. PhD thesis, University of Arizona. Hulden, M. (2009b). Foma: a finite-state compiler and library. In Proceedings of the 12th confer- ence of the European Chapter of the Association for Computational Linguistics,, pages 2932. Kaplan, R. M. and Kay, M. (1994). Regular mod- els of phonological rule systems. Computa- tional Linguistics, 20(3):331378. Karttunen, L. (2003). Computing with realiza- tional morphology. In Computational Linguis- tics and Intelligent Text Processing, pages 203 214. Springer. Kempe, A., Guingne, F., and Nicart, F. (2004). Algorithms for weighted multi-tape automata. XRCE Research Report 2004/031. Kempe, A. and Karttunen, L. (1996). Parallel re- placement in finite state calculus. In Proceed- ings of the 34th annual meeting of the Associa- tion for Computational Linguistics. Kenstowicz, M. and Kisseberth, C. (1979). Gen- erative phonology. Academic Press. Koskenniemi, K. (1983). Two-level morphology: A general computational model for word-form recognition and production. Publication 11, University of Helsinki, Department of General Linguistics, Helsinki. Mohri, M., Pereira, F., and Riley, M. (2002). Weighted finite-state transducers in speech recognition. Computer Speech &amp; Language, 16(1):6988. Mohri, M. and Sproat, R. (1996). An efficient compiler for weighted rewrite rules. In Pro- ceedings of the 34th annual meeting on As- sociation for Computational Linguistics, pages 231238. Association for Computational Lin- guistics. Round, E. (2011). Word final phonology in Lardil: Implications of an expanded data set. Australian Journal of Linguistics, 31(3):327350. 10 Appendix: Lardil grammar def Mark(Rule, Label) [Rule ("#":0 ?:0 | "#" ?:Label | 0:"#" 0:Label)] &amp; [\"#"* ("#":0 ?:0) | [?-"#"]* [0:?|?:0|?:?-?] [[?-"#"]:[?-"#"]|?:0|0:?]* [0:"#" 0:Label | "#" ?:Label] ]; def Vow [a | | i | u]; def Cons [p | t | | t | t |k | m | n | | | | n | n| | l | w | | j ]; def Apical [t | | n | | | l | ]; def Nasal [m | n | | | | n | n]; def kEpenthesis Mark([ [..] -&gt; k || Nasal _ u ], "k-Epenthesis"); def wEpenthesis Mark([ [..] -&gt; w || i _ u ] , "w-Epenthesis"); def VowelDeletion Mark([ Vow -&gt; 0 || Vow _ ], "Vowel Deletion"); def FinalLowering Mark([ i -&gt; , u -&gt; a || _ [.#.|"#"] ], "Final Lowering"); def Apocope Mark([ Vow -&gt; 0 || Vow Cons* Vow Cons* _ [.#.| "#"] ], "Apocope"); def ClusterRed Mark([ Cons -&gt; 0 || Cons _ [.#.|"#"] ], "Cluster Reduction"); def NonApicalDel Mark([ [Cons - Apical] -&gt; 0 || _ [.#.|"#"] ] , "Non-Apical truncation"); def Sonorantization Mark([ -&gt; || _ [.#.|"#"] ], "Sonorantization"); def Grammar kEpenthesis .o. wEpenthesis .o. VowelDeletion .o. FinalLowering .o. Apocope .o. ClusterRed .o. NonApicalDel .o. Sonorantization ; regex Grammar; </chunk></section></sec_map>