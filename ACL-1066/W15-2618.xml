<sec_map><section><chunk>Proceedings of the Sixth International Workshop on Health Text Mining and Information Analysis (Louhi), pages 131141, Lisbon, Portugal, 17 September 2015. c 2015 Association for Computational Linguistics. NLPBased Readability Assessment of HealthRelated Texts: a Case Study on Italian Informed Consent Forms Giulia Venturi , Tommaso Bellandi , Felice DellOrletta , Simonetta Montemagni Istituto di Linguistica Computazionale Antonio Zampolli (ILCCNR) ItaliaNLP Lab - www.italianlp.it {name.surname}@ilc.cnr.it Laboratorio per le attivi` a di studio e ricerca applicata, Centro Gestione Rischio Clinico e Sicurezza dei Pazienti, Patient Safety Research Lab bellandit@aou-careggi.toscana.it Abstract The paper illustrates the results of a case study aimed at investigating and enhanc- ing the accessibility of Italian health related documents by relying on advanced NLP techniques, with particular atten- tion to informed consent forms. Results achieved show that the features automati- cally extracted from the linguistically an- notated text and ranging across different levels of linguistic description have a high discriminative power in order to guarantee a reliable readability assessment. </chunk></section><section><heading>1 Introduction </heading><chunk>Within an information society, where everyone should be able to access all available information, improving access to written language is becoming more and more a central issue. This is the case of healthrelated information which should be acces- sible to all members of the society, including peo- ple who have reading difficulties e.g. as a result of a low education level, or of languagebased learn- ing disabilities, or because the language of the text is not their native language (WHO, 2015). It is a widely acknowledged fact that poor communi- cation between physician and patients predisposes to medical malpractice cases (Kohn et al., 2000). Patient safety is a global challenge since the evi- dence on the burden of adverse events emerged in the past 15 years. An estimate of 43 millions ad- verse events occur in one year globally, with more than 50% of preventable events (Jha et al., 2013). In Italy, the incidence is of 5.2% on inhospital admissions (Tartaglia et al., 2012) and the direct cost related to the prolongation of the stay are up to 3bln Euros in one year, roughly 3% of the funds of the National Healthcare Service (Albolino et al., 2013). The indirect costs related to claims is also high, amounting up to 1bln Euro in one year. For all these reasons, the medical community has always shown strong interest in the improve- ment of healthrelated information in terms of document quality and understandability. Studies carried out so far mainly focused on traditional readability assessment methods, such as e.g. the FleschKincaid measure (Kincaid, 1975) for the English language or the GulpEase index for Ital- ian (Lucisano and Piemontese, 1988). According to them, the readability of medical texts is assessed by relying on basic text features such as sentence and word length, the only ones which could be au- tomatically extracted from texts when these mea- sures were originally conceived. Recently, concerns have been raised about the effectiveness of traditional readability indices in capturing linguistic factors related to text com- plexity (Gemoets et al., 2004; Clerehan et al., 2005). This follows from the fact that now it is possible to carry out readability assessment against linguistically annotated texts, i.e. enriched with detailed and multilevel linguistic informa- tion generated by Natural Language Processing (NLP) components. Providing complex scientific information in a way that is comprehensible to a lay person is thus a challenge that nowadays can be addressed by deploying NLP techniques to capture a wide range of multilevel linguistic (e.g. lexical, syntactic, discourse) features and using statistical machine learning to build advanced readability as- sessment tools (DellOrletta et al., 2014a). So far, very few attempts have been devoted to the use of advanced NLP techniques to assess the readability of healthrelated texts; to our knowledge, none of them deals with Italian. In this paper, we report the first results of a case study aimed at assessing the readability of a cor- pus of Italian informed consent forms on the basis of NLPenabled surface, lexical and syntactic fea- tures. Among healthrelated texts, we focused on informed consent forms since ineffective doctor 131 patient communication is often due to a weak or lacking informed consent (Korenman et al., 2015). The case study was carried out in the frame- work of the collaboration between the Institute of Computational Linguistics of the Italian Na- tional Research Council (ILCCNR) and the Cen- tre for Clinical Risk Management and Patient Safety (GRC) of the Tuscany region whose fi- nal goal is the development of advanced technolo- gies to support the improvement of doctorpatient communication. In particular, it originates from the fact that in 2010 GRC was appointed to man- age a communication and compensation program on adverse events, in order to improve the ef- fectiveness and efficiency of claims management. Thanks to this programme, after 5 years the ef- ficiency has strongly improved, with an estimate saving of 50millions Euro per year and a reduction of 5 months to close the claim. Yet, the number of claims is still stable and a recurrence of cases re- lated to ineffective doctorpatient communication, often related to a weak or lacking informed con- sent, continues to be observed. The collaboration between ILCCNR and GRC is aimed at creating the prerequisites for improvig the effectiveness of doctorpatient communication. This goal is pur- sued by designing and developing a writing tool for clinical practitioners which includes advanced functionalities for the evaluation of the quality of written documents and for supporting their sim- plification (whenever needed): the paper reports the results of preliminary investigations aimed at evaluating the readability of a wide corpus of doc- uments presented to patients for informed consent, covering a wide range of clinical specialties and released by different healthcare trusts. </chunk></section><section><heading>2 Background </heading><chunk>It is a widely acknowledged fact that NLP tech- niques have an impact on the design of readabil- ity measures enabling to capture complex linguis- tic features with a significant gain in performance (Franc  ois and Miltsakaki, 2012). However, dif- ferently from other application scenarios, little ef- fort has been devoted so far in the biomedical do- main to fully exploit NLP potentialities to evalu- ate the readability of healthrelated texts and to support clinical practitioners in the simplification, whenever needed, of the documents they produce. NLPbased readability assessment approaches re- ported so far for the biomedical domain differ with respect to: whether readability assessment is car- ried out as a classification task or in terms of rank- ing; the typology of features taken into account; the application within which readability assess- ment is carried out; and, last but not least, the lan- guage dealt with. </chunk></section><section><heading>2.1 Methods and Features </heading><chunk>Classificationbased methods carry out readabil- ity assessment by assigning a given document to predefined readability classes: this is the case, for instance, of Kauchak et al. (2014) who built a machine learning classifier for predicting the difficulty of medical texts trained on a data set of aligned sentence pairs collected from English Wikipedia and Simple English Wikipedia. Inter- estingly, in the biomedical literature on readabil- ity assessment readability classes are typically re- stricted to two, i.e. easy vs. difficult. However, the main drawback of classification models is that they require training data, which may not exist, especially for a specific domain. An alternative to this method is represented by rankingbased approaches, positioning the document being anal- ysed within a readability ranking scale: this ap- proach is better suited for dealing with less re- sourced languages or to meet the needs of spe- cific domains. In the biomedical domain, this method is adopted, among others, by: Kim et al. (2007), who developed a domainspecific ap- proach to readability assessment calculating a dis- tance score based on whether and to what ex- tent text features of a test document differ from those of an easy sample (consisting in a collection of various web health information resources); or Zeng-Treitler et al. (2012) who, with the aim of improving the rankbased approach by Kim et al. (2007), used a wider set of lexical features also taking into account frequency information. For what concerns the typology of features, NLPbased approaches proposed so far mainly fo- cus on a combination of grammatical features, typ- ically represented by the distribution of PartsOf Speech or of noun phrases, and lexical features, such as the distribution of domain terms with re- spect to domainspecific vocabularies, e.g. the Unified Medical Language System (UMLS) vo- cabulary. This is the case, e.g., of Proulx et al. (2013) who, by combining grammatical and vo- cabulary features, developed a tool specifically ad- dressing the needs of clinicians and health ed- 132 ucators for both readability assessment and en- hancement. Since vocabulary plays a key role in health text readability, the most important exten- sions taken into account are concerned with lex- ical features. Starting from the assumption that more frequent terms are also easier to understand, Zeng-Treitler et al. (2012) included among the lexical features the distribution of terms with re- spect to two generalpurpose resources, i.e. the Penn Treebank (Marcus et al., 1999) and the Googles Web 1T 5gram Version 1 with ngram frequency counts (Brants and Franz, 2006). For what concerns grammatical information, readabil- ity assessment in the biomedical domain does not go beyond to the distribution of PartsOfSpeech and/or noun phrases: i.e. to our knowledge none of the domainspecific methods proposed so far makes use of syntactic features that can be ex- tracted from the output of a syntactic parser. </chunk></section><section><heading>2.2 Applications and Languages </heading><chunk>Readability assessment is tackled from various perspectives with different applications in mind, giving rise to different tasks ranging from discern- ing easy vs. difficult electronic health records (Zeng-Treitler et al., 2007b), consumer health web sites, patient blogs and patient educational mate- rial (Leroy et al., 2006), to the simplification of medical texts carried out by devising metrics that can help making healthrelated documents more comprehensible to consumers. Due to the central role of lexical features in determining the readabil- ity of healthrelated texts, lexical simplification turned out to be the most explored level of text simplification. Different methods were devised to make health documents more comprehensible to consumers by reducing vocabulary difficulty. Even if with some differences, all approaches rely on the identification of difficult words and their replacement with easier synonym words. For this purpose, both domainspecific (e.g. Uni- fied Medical Language System (UMLS), open access collaborative (OAC), consumer health vo- cabulary (CHV)) and generalpurpose (WordNet synonyms and hyperonyms, Wiktionary defini- tions, frequency counts of words in Google Web Corpus) resources were used. This is the case of Zeng-Treitler et al. (2007a) who built a prototype text translator to simplify narrative reports in elec- tronic health reports, and of Leroy et al. (2012) who developed a semiautomatic algorithm tested on patient materials available online whose orig- inal and simplified version was presented for eval- uation to a medical librarian (to measure the per- ceived difficulty) and to laymen (to measure the actual difficulty). Kandula et al. (2010) defined a text simplification method relying on both seman- tic and syntactic features: following Siddharthan (2006)s approach, their algorithm is articulated into three steps, i.e. sentences longer than 10 words are first splitted, then PartOfSpeech pat- terns are identified, and transformational rules are applied to generate shorter sentences. Readability metrics developed so far typically deal with English, with few attempts tackling other languages. The most prominent exception is represented by Swedish, for which a quantita- tive corpus analysis of a collection of radiology reports was carried out as a preliminary step to- wards the development of a Swedish text simplifi- cation tool (Kvist and Velupillai, 2013). Similarly to English, simplification algorithms for Swedish healthrelated documents were devised by relying on synonym replacement methods (Abrahamsson et al., 2014), or on automatic detection of out ofdictionary words and abbreviations, or on com- pound splitting and spelling correction (Grigonyte et al., 2014). Initiatives carried out so far for what concerns Italian are based on traditional readabil- ity formulas. This is the case of the ETHIC (Evaluation Tool of Health Information for Con- sumers) project (Cocchi et al., 2014), aimed at de- veloping an effective tool for biomedical librari- ans and health information professionals to assess the quality of produced documents and to sup- port them in preparing texts of increasing quality, suitable and comprehensible for patients and con- sumers in general. The tool carries out text read- ability and lexical understandability evaluation by resorting to the GulpEase readability formula (Lu- cisano and Piemontese, 1988) and the Basic Ital- ian Vocabulary (De Mauro, 2000). Another rel- evant case study dealing with different languages also including Italian is reported in Terranova et al. (2012), whose aim was to assess and improve the quality and readability of informed consent forms used in cardiology. Although readability as- sessment was carried out with traditional readabil- ity formulas to guarantee comparability of results across languages, the main novelty of this study is that the simplification of Italian consent forms was guided by a preliminary version of READ 133 IT (DellOrletta et al., 2011), the first NLPbased readability assessment tool for Italian. 3 The Approach Our approach to the assessment of readability of Italian healthrelated texts combines NLP enabled feature extraction and stateoftheart machine learning algorithms. In this case study, we chose to exploit a generalpurpose readabil- ity assessment tool, represented by READIT (DellOrletta et al., 2011) 1 , the first NLPbased readability assessment tool for Italian which com- bines traditional raw text features with lexical, morphosyntactic and syntactic information (see Section 3.2). In READIT, analysis of readabil- ity is modelled as a classification task. In par- ticular, readability classification is binary, i.e. it is based on a training set consisting of two cor- pora representative of difficult vs. easytoread texts. The easytoread training set is represented by Due Parole (2Par), a newspaper specifically written for an audience of adults with a rudimen- tary literacy level or with mild intellectual disabil- ities: the articles in 2Par were written by Italian linguists expert in text simplification using a con- trolled language at the lexicon and sentence struc- ture levels (Piemontese, 1996). For the selection of the difficulttoread training set we opted for texts belonging to the same class, i.e. newspa- pers. In particular, we used the daily newspaper La Repubblica (Rep): even if widely read by many people in Italy, the national statistics on lit- eracy skills report that 71% of the Italian people can hardly comprehend texts of medium difficulty such as the Rep articles. Two other qualifying features of the READIT approach to readability assessment are worth re- porting here, namely: i) readability is assessed by considering a wide range of linguistic characteris- tics automatically extracted from linguistically an- notated texts, and ii) readability analysis is carried out at both document and sentence levels. As re- ported in section 2, readability assessment in the biomedical domain typically relies on linguistic features extracted from automatically PoStagged texts: instead, our approach also includes features extracted from syntactically (i.e. dependency) parsed texts, thus making it possible to monitor a wider variety of factors affecting the readabil- ity of a text. The set of features can be parame- 1 http://www.italianlp.it/demo/read-it/ terized creating the prerequisites for specializing the readability assessment measure with respect to different target audiences, specific domains of knowledge or with respect the type of textual ob- ject, i.e. the document or individual sentences. Assessing readability at both document and sen- tence levels allows highlighting specific text por- tions which require reformulation with respect to the used vocabulary or to the grammatical struc- ture (DellOrletta et al., 2014c). In fact, similarly to other application scenarios, also in the biomedi- cal domain evaluating the readability of individual sentences represents an essential prerequisite for text simplification, to be carried out at both lex- ical and syntactic levels (Kandula et al., 2010). Despite that sentence readability assessment is a qualifying feature of READIT, in what follows we will focus on document readability only. For the experiments reported in the paper, we used general purpose readability models trained on newspaper corpora. This was an unavoidable choice, due to the lack of domainspecific re- sources annotated with grade levels to be used as training data. Although this makes achieved re- sults still preliminary, it was a way to test effec- tiveness and reliability of the method on health related texts. For what concerns the evaluation of achieved readability assessment results, the tar- get readers of 2Par (i.e. the READIT easyto read pole) were taken as coinciding with the target reader of healthrelated texts: the underlying as- sumption is that the informed consents classified as difficultto read for the 2Par low literacy read- ers are really complex and need to be simplified. Obviously, when a version of READIT special- ized for the biomedical domain will be released, a qualitative evaluation of results will be needed. Previous studies resorted to the Cloze test to val- idate the reliability of their results or integrated editing capabilities into the developed tools in or- der to receive feedback from end users. The work carried out by Kandula and Zeng-Treitler (2008) represents an exception. They assembled a panel of experts to evaluate the readability of 324 dif- ferent typology of English health documents: the rated collection was meant to be used as a gold standard to evaluate readability metrics. </chunk></section><section><heading>3.1 The corpus </heading><chunk>For this case study, we collected a corpus of 583 documents, for a total of 607,677 word tokens, 134 Features 2Par 2IC Rep Average sentence length 19.20 16.06 26.54 Average word length 4.98 6.75 5.18 % of lemmas (types) in BIV 74.58 57.24 67.09 % of lemmas (types) NOT in BIV 25.42 42.76 32.91 Type/token ratio (first 100 tokens) 0.55 0.72 0.72 Distribution of PartsOfSpeech: nouns 29.30% 28.51% 27.19% verbs 13.66% 11.83% 12.89% adjectives 5.92% 9.26% 6.40% prepositions 15.28% 16.19% 16.41% Noun/verb ratio 2.14 2.41 2.11 Average length of the longest dependency link 7.91 6.43 10.28 Average parse tree depth 5.29 4.86 6.51 Average depth of embedded complement chains 1.24 1.31 1.34 Distribution of chains by depth: 1 embedded complement 79.40% 74.25% 72.32% 2 embedded complements 17.02% 21% 21.42% 3 embedded complements 3.27% 4.73% 5.87% Main vs subordinate clauses distribution: main clauses subordinate clauses 26.14% 25.30% 32.36% Average clause length 9.81 11.29 10.12 Distribution of verbal roots with explicit subject 74.69% 57% 64.30% Table 1: Selection of linguistic features strongly characterizing the 2IC corpus. constituted by the procedures and the documents for informed consents currently used in all the 16 healthcare trust of the Regional Healthcare Ser- vice (RHS) of Tuscany, namely 4 academic hospi- tals and 12 local healthcare authorities. The docu- ments were partitioned into different groups, clas- sified according to the clinical specialty and the document type (procedure or user guide). Hence- forth, we will refer to this corpus as the Italian Informed Consent Corpus (2IC). Table 1 reports a selection of linguistic features which turned out to strongly characterize the 2IC corpus with respect to the journalistic 2Par and Rep corpora. This analysis is meant to compare domainspecific (i.e. biomedical) and general purpose corpora with the final aim of detecting the main linguistic features characterizing the lan- guage used in informed consent forms. The fea- tures were extracted from the corpus automatically tagged by the partofspeech tagger described in DellOrletta (2009) and dependencyparsed by the DeSR parser (Attardi, 2006). Starting from raw textual features, it can be noticed that the 2IC corpus is characterized by shorter sentences (calculated as the average num- ber of words per sentence) and longer words (cal- culated as the average number of characters per word) if compared with the 2Par and Rep cor- pora. Starting from the assumption underlying tra- ditional readability formulas assuming that longer sentences are more grammatically complex than shorter ones and that longer words are less com- prehensible than shorter ones, this result witnesses the efforts of the authors of informed consents to- wards the use of an unavoidably complex vocabu- lary used, however, in simpler syntactic construc- tions. Interestingly enough, this is confirmed by the values of lexical features. Among them, it is worth noting that with respect to both 2Par and Rep informed consents contain quite a lower per- centage of lemmas (types) belonging to the Basic Italian Vocabulary (De Mauro, 2000), marked as BIV in Table 1 and corresponding to a list of 7000 words highly familiar to native speakers of Italian. This is in line with the outcomes of the studies on the discriminative power of vocabulary clues in readability assessment (see, among others, Pe- tersen and Ostendorf (2009)). Obviously, this also reveals the massive use of healthrelated words specific to this domain of knowledge and here still considered as outofvocabulary lemmas. In ad- dition, 2IC texts show a higher TypeToken Ratio (TTR) value (which is computed for the first 100 tokens of each document), meaning that this text type is much richer lexically, with values which are closer to what observed with respect to Rep, here considered as representative of the class of difficulttoread texts. Consider now the distribution of PartsOf Speech across the 2Par, Rep and 2IC corpora. In- 135 formed consents are characterized by a high per- centage of adjectives, prepositions and nouns, and by a low percentage of verbs: this gives rise to a much higher noun/verb ratio. According to Biber (1993), such different distributions represent significant dimensions of variation across textual genres. In particular, the higher noun/verb ratio reveals that informed consent forms are more in- formative than newspaper articles (Biber and Con- rad, 2009), while the higher occurrence of nouns and prepositions is strongly connected with their presence within embedded complement chains governed by a nominal head and including either prepositional complements or nominal and adjec- tival modifiers. Similarly to Rep articles, health related documents contain a high percentage of complex nominal constructions (Average depth of embedded complement chains in Table 1) with deep sequences of embedded complements. This is also reflected at the level of the probability dis- tribution of embedded complement chains by depth: if on the one hand we observe a lower percentage of short sequences (i.e. with depth=1) with respect to 2Par here taken as representative of easytoread texts, on the other hand similarly to Rep a higher percentage of longer sequences (i.e. with depth=2 and = 3) is recorded. Interestingly, however, besides complexity fea- tures such as heavy nominal constructions possibly due to multiword terminology in in- formed consents low values are recorded for syn- tactic features typically associated with structural complexity, such as: parse tree depth, calculated in terms of the longest path from the root of the de- pendency tree to some leaf; length of dependency links, measured in terms of the words occurring between the syntactic head and the dependent; or the distribution of main vs. subordinate clauses. From this, we can conclude that language com- plexity in informed consent forms mainly lies at the level of local features of the parse tree. Other peculiar syntactic features of informed consents with respect to 2Par and Rep are represented by longer clauses (Average clause length in Table 1, calculated as the average number of tokens per clause), and a lower percentage of verbal roots with explicit subject (calculated with respect to the total amount of verbal roots). For what concerns the latter, even if Italian is a prodrop language, sentences characterized by elliptical constructions (e.g. verbal roots with explicit subjects) make a text more difficulttoread and need to be simpli- fied, as suggested in Barlacchi and Tonelli (2013). </chunk></section><section><heading>3.2 Readability Assessment </heading><chunk>For readability classification experiments we used READIT, the first NLPbased readability assess- ment tool devised for Italian. It operates on syntac- tically (i.e. dependency) parsed texts and assigns to each considered reading object - either a docu- ment or a sentence - a score quantifying its read- ability. READIT is a classifier based on Support Vector Machines using LIBSVM (Chang and Lin, 2001) that, given a set of features and a training corpus, creates a statistical model using the feature statistics extracted from the training corpus. Such a model is used in the assessment of readability of unseen documents or sentences. The assigned readability level ranges between 0 (easytoread) and 100 (difficulttoread) referring to the per- centage probability for the unseen documents or sentences to belong to the class of difficultto read documents. The score assigned by READIT can thus be seen as a score of text difficulty. As fully described by DellOrletta et al. (2011), the tool is trained on 2Par (taken as representative of the class easytoread texts) and on Rep (rep- resenting the class of difficulttoread texts) arti- cles and it exploits the wide typology of raw text, lexical, morphosyntactic and syntactic features summarized in Table 2. This proposed fourfold partition of features closely follows the different levels of linguistic analysis automatically carried out on the text being evaluated, i.e. tokenization, lemmatization, morphosyntactic tagging and de- pendency parsing. Such a partition was meant to identify those easy to extract features with high discriminative power in order to reduce the lin- guistic preprocessing of texts guaranteeing at the same time a reliable readability assessment. The set of features used to build the statistical model can be parameterized through a configura- tion file. This creates the prerequisites for cus- tomising the readability assessment measure with respect to the target audience or to the sublan- guage of a specific domain. According to the dif- ferent types of features considered, READIT as- signs different readability scores using the follow- ing four feature models: </chunk></section><section><heading>1. Base Model, relying on raw text features only; </heading><chunk>136 Feature category Name Raw Text Average number of words per sentence Average number of characters per word Lexical Type/Token Ratio Lexical density Basic Italian Vocabulary (BIV) (De Mauro, 2000) rate Morphosyntactic Part-Of-Speech unigrams Mood, tense and person of verbs Syntactic Distribution of dependency types Depth of the whole parse tree Average depth of embedded complement chains Distribution of embedded complement chains by depth Number of verbal roots Arity of verbal predicates Distribution of verbal predicates by arity Distribution of subordinate vs main clauses Relative ordering with respect to the main clause the Average depth of chains of embedded subordinate clauses Distribution of embedded subordinate clauses chains by depth Length of dependency links feature Table 2: Linguistic features used for readability assessment purposes. 2. Lexical Model, relying on a combination of raw text and lexical features; 3. Syntax Model, relying on morphosyntactic and syntactic features; 4. Global Model, combining all feature types, namely raw text, lexical, morphosyntactic and syntactic features. 4 Results and Discussion In this section, we discuss the outcome of the read- ability assessment experiments carried out on the 2IC corpus described in Section 3.1. In order to identify the contribution of the different types of features in the assessment of the readability of in- formed consents, we focus on the results obtained by the base, lexical and syntactic READIT mod- els (see, respectively, columns Base, Lexical and Syntax in Table 3). In what follows, we will focus on the results of the readability experiments car- ried out at the document level while an in depth in- vestigation of the linguistic aspects affecting sen- tence readability is part of an ongoing study. Table 3 reports the results obtained with re- spect to the whole corpus, for all the 29 med- ical specialties; a score for each of the 4 con- sidered macrospecialties (namely, Surgery, Inter- nal Medicine, Prevention and Medical Services) is also computed, as the average of the scores recorded for each specialty. It can be noted that the whole corpus is characterized by a low readability level, even if with significant differences among the different readability models and across macro specialties. Interestingly, the results obtained by the Base model show how raw text features such as sentence and word length are not really effective to capture the difficulty of these texts as well as the differences among them. This model can be seen as an approximation of the GulpEase index (Lu- cisano and Piemontese, 1988), i.e. the most used traditional readability measure for Italian which is based on the same raw text features (i.e. sentence and word length). This naturally follows from the results illustrated in Section 3.1, investigating the linguistic features characterizing 2IC with respect to general purpose corpora: as Table 1 shows, 2IC contains quite short sentences, a raw text feature typical of easytoread texts. By comparing the scores obtained for the macrospecialties, it is worth noting that the score obtained with the Base model for the Prevention area is misleading: i.e, the prevention forms re- sult to be more difficult than the Internal Medicine documents and only slightly easier than the Med- ical Services ones. The situation looks quite dif- ferent if we consider instead the Lexical and the Syntax models: we can observe that the Preven- tion documents are easiertoread than the doc- uments of the other macrospecialties. On the contrary, sharp differences among the 4 macro specialties and the 29 specialties occur as far as the Lexical and the Syntax models are concerned. In particular, all specialties turned out to be more difficult at the lexical than at the syntactic level. For what concerns the former, this follows from 137 the high percentage of outofvocabulary lemmas characterizing the informed consents with respect to the Basic Italian Vocabulary: as expected, Pre- vention documents represent an exception, being the easiesttoread macrospecialty at the lexical level. Consider now the results obtained with the Syn- tax model, according to which all informed con- sents turned out to be less difficulttoread with respect to the lexical level. As discussed in Sec- tion 3.1, the typology of features contributing to this result is related to local aspects of the parse tree, taken in literature as an index of language complexity, rather than to structural complexity features. This type of evidence will be used in the near future to customize the set of features to be taken into account in the construction of a domainspecific version of the Syntax readability model. Also in this case, Prevention documents turned out to be more readable than the other spe- cialties. </chunk></section><section><heading>5 Conclusion and Future Work </heading><chunk>In this paper, we illustrated the preliminary but encouraging results of a broader and longterm study devoted to enhance the accessibility of Ital- ian healthrelated documents by relying on ad- vanced Natural Language Processing techniques: the case study reported in the paper focuses on in- formed consent forms, which play a key role in doctorpatient communication. For this purpose, we used READIT, a general purpose NLPbased readability assessment tool for Italian. The re- sults obtained so far show that the features auto- matically extracted from the linguistically anno- tated text and ranging across different levels of lin- guistic description, also including syntax, have a high discriminative power to guarantee a reliable readability assessment. To our knowledge, this is the first application of an advanced NLPbased methodology for readability assessment of Italian healthrelated documents. The proposed method- ology was tested on a corpus of Italian informed consents currently used in healthcare trusts of the Regional Healthcare Service of Tuscany. The results obtained by comparing readability scores across the considered medical specialties with respect to the different READIT models re- vealed that generally speaking informed con- sents are more difficulttoread at the lexical level than at the syntactic level. This is in line with the linguistic profiling results discussed in Section 3.1, according to which the 2IC corpus contains a higher percentage of outofvocabulary words, even higher than difficulttoread texts (i.e. Rep). Behind this general trend, significant differences are reported for the different specialties, e.g. the Prevention documents turned out to be easier toread than the documents of the other (macro )specialties. The higher difficulty recorded at the lexical level suggests that the general purpose READ IT tool needs to be specialized at the level of the permitted vocabulary, which should also include a selection of basic domain terms to be used in informed consent forms without any penalization at the level of the readability score. We are al- ready working in this direction. Two experts in healthcare quality assessment are currently eval- uating the outofvocabulary lemmas automati- cally extracted from the 2IC corpus by the T 2K 2 (TexttoKnowledge) platform (DellOrletta et al., 2014c) with the final aim of creating a domain specific lexicon to be used in the specialized ver- sion of READIT we are currently developing. The lexicon will be internally organized into three classes of i) domainspecific words, i.e. words that cannot be avoided within healthrelated doc- uments (e.g. anestesia anesthesia), ii) technical words, i.e. words that are specific to the domain but that should be explained with a gloss in or- der to be fully understood by laymen (e.g. com- plicanza complication), and iii) technicalities, i.e. words that are used by experts but that should be replaced with a simpler synonym in order to be fully understood by laymen (e.g. fistola fistula). Obviously, as suggested above the specialization will also be concerned with grammatical features. From a more general perspective, these prelim- inary results show a severe lack of knowledge and skills on the design of readable informed consents within healthcare services. Clearly, we can inter- pret these findings in the bureaucratic framework within which the documents are produced, miss- ing the goal of informing patients while accom- plishing the legal duty to have a piece of paper reporting the signatures of doctors and patient in the healthcare record, without a clear explanation of the treatments. Further research is needed to design and evaluate systems to support the prepa- ration of the documents of informed consent: in this context, the customization of the READIT 138 Medical Specialty n o documents n o tokens READIT Base Lexical Syntax Anesthesiology 20 21,065 50 93.37 69.62 Colorectal surgery 2 1,997 75.18 100 93.81 Obesity surgery 3 8,091 51.63 93.42 59.20 General surgery 19 11,588 43.03 78.29 58 Plastic surgery 4 3,550 88.95 98.72 96.51 Thoracic surgery 9 5,608 94.98 99.94 95.55 Vascular surgery 16 22,739 88.64 98.13 97.62 Ophthalmology 7 10,496 49.21 98.89 61.29 Otorhinolaryngology 134 194,421 25.14 94.90 69.42 Orthopaedics 44 76,712 50.54 97.58 89.66 Obstetrics and gynecology 35 31,243 60.37 97.31 58.52 Urology 17 19,576 85.40 98.08 89.16 TOTAL: Surgery 313 407,086 63.59 95.72 78.19 Cardiology 54 39,887 66.20 94.50 78.99 Diabetology 1 297 23.05 100 45.68 Gastroenterology 9 9,856 41.12 87.90 59.82 Neurology 8 5,199 69.44 97.96 94.98 Oncology 3 1,692 46.34 99.73 96.07 Pulmonology 4 3,220 49.57 98.18 78.27 Senology 17 20,455 85.09 99.68 93.88 TOTAL: Internal Medicine 96 80,309 54.26 96.85 78.24 Psychology 13 11,651 80.44 96.25 98.32 Screening 8 2,007 53.13 65.14 50.60 Vaccine 1 2,852 33.72 100 71.76 TOTAL: Prevention 22 16,510 55.76 87.13 73.56 Genetics 11 6,416 56.26 95.65 81.45 Immunohematology and transfusion 43 45,962 56.84 93.39 83.47 Nuclear medicine 29 18,045 52.62 96.56 68.48 Radiology 24 17,358 63.78 98.61 78.68 TOTAL: Medical Services 107 87,781 57.38 96.05 78.02 General 33 8,928 51.59 87.81 88.27 Pediatrics 13 6,092 49.84 99.46 74.67 Rehabilitation 2 674 63.84 99.99 96.25 Table 3: Readability assessment results by the Base, Lexical and Syntax models organized by medical specialties. tool will play a key role. A specialized version of READIT will be possibly integrated within the Electronic Patient Record, so that the informed consent becomes part of a process of shared de- cision making where the doctors prepare a read- able message for the patient at the time of the de- cision for a clinical procedure and collect ques- tions and comments, that in turn feebacks into a software capable to learn from the daily practice. A limitation of this approach is the exclusive re- liance on written documents, while according to the current debate (Korenman, 2015) in ethics and medico-legal issues the informed consent should be the result of a process of communication where the written document supports the doctorpatient communication. Bringing this to an extreme per- spective, the informed consent could be simply the transcription of the dialogue that demonstrates the provision of comprehensive information on the possible treatments for a disease and the shared decision on the best alternative for the involved parts. However, even in this futuristic scenario NLP technologies could play a role. References S. Albolino, T. Bellandi, R. Tartaglia, and A. Biggeri. 2013. The incidence of adverse events in tuscany: results from a regional study involving 36 hospitals. Proceedings of ISQUA 30th International Confer- ence, 1316 October, Edinburgh. E. Abrahamsson, T. Forni, M. Skeppstedt, and M.Kvist. 2014. Medical text simplification us- ing synonym replacement: Adapting assessment of word difficulty to a compounding language. Pro- ceedings of the 3rd Workshop on Predicting and Im- proving Text Readability for Target Reader Popula- tions (PITR 2014, EACL Workshop), 5765. G. Attardi. 2006. Experiments with a multilan- guage non-projective dependency parser. Proceed- 139 ings of the Tenth Conference on Computational Nat- ural Language Learning (CoNLL-X 06), 166170. G. Barlacchi and S. Tonelli. 2013. ERNESTA: A Sen- tence Simplification Tool for Childrens Stories in Italian. Proceedings of the 14th Conference on Intel- ligent Text Processing and Computational Linguis- tics (CICLing-2013), 476487. D. Biber. 1993. Using Registerdiversified Corpora for General Language Studies. Computational Lin- guistics Journal, 19(2): 219241. D. Biber and S. Conrad. 2009. Genre, Register, Style. Cambridge: CUP. T. Brants and A. Franz. 2006. Web 1T 5gram Version 1. Linguistic Data Consortium, Philadelphia. C. C. Chang and C. J. Lin. 2001. LIB- SVM: a library for support vector machines. Software available at http://www.csie.ntu. edu.tw/ cjlin/libsvm R. Clerehan R. Buchbinder, and J. Moodie. 2005. A linguistic framework for assessing the quality of written patient information: Its use in assessing methotrexate information for rheumatoid arthritis. Health Education Research, 20(3):334344. S. Cocchi, M. Mazzocut, C. Cipolat Mis, I. Truc- colo, E. Cervi, R. Iori, and D. Orlandini. 2014. ETHIC. Evaluation Tool of Health Information for Consumers. Development, features and validation. Divided we fall, united we inform. Building alliances for a new European cooperation, 14th EAHIL An- nual Conference, Roma (Italy), 11-13 June. T. De Mauro. 2000. Il dizionario della lingua italiana. Torino, Paravia. F. DellOrletta. 2009. Ensemble system for Part-of- Speech tagging. Proceedings of Evalita09, Evalu- ation of NLP and Speech Tools for Italian, Reggio Emilia, December. F. DellOrletta, S. Montemagni, and G. Venturi. 2011 READIT: assessing readability of Italian texts with a view to text simplification. Proceedings of the Sec- ond Workshop on Speech and Language Processing for Assistive Technologies (SLPAT), Edinburgh, UK, 7383. F. DellOrletta, S. Montemagni, and G. Venturi. 2014a. Assessing document and sentence readability in less resourced languages and across textual genres. Re- cent Advances in Automatic Readability Assessment and Text Simplification. Special issue of Interna- tional Journal of Applied Linguistics, 165:2, John Benjamins Publishing Company, 163193. F. DellOrletta, M. Wieling, A. Cimino, G. Venturi, and S. Montemagni. 2014b Assessing the Readability of Sentences: Which Corpora and Features? Pro- ceedings of 9th Workshop on Innovative Use of NLP for Building Educational Applications (BEA 2014), Baltimore, Maryland, USA, 163173. F. DellOrletta, G. Venturi, A. Cimino, S. Montemagni. 2014c. T2K: a System for Automatically Extracting and Organizing Knowledge from Texts. In Proceed- ings of 9th Edition of International Conference on Language Resources and Evaluation (LREC 2014), pp. 20622070, 26-31 May, Reykjavik, Iceland. T. Franc  ois and Eleni Miltsakaki. 2012. Do NLP and machine learning improve traditional readabil- ity formulas? Proceedings of the NAACL-HLT 2012 Workshop on Predicting and Improving Text Read- ability for target reader populations (PITR 2012), 4957. A.K. Jha, I. Larizgoitia, C. Audera-Lopez, N. Prasopa- Plaizier, H. Waters, and D. Bates. 2013. The global burden of unsafe medical care: analytic modelling of observational studies. BMJ Quality and Safety, 22(10):80915. S. Kandula, D. Curtis, and Q. Zeng-Treitler. 2010. A semantic and syntactic text simplification tool for health content. Proceedings of the American Med- ical Informatics Association Annual Symposium, United States:36670. S. Kandula and Q. Zeng-Treitler. 2008. Creating a Gold Standard for the Readability Measurement of Health Texts. Proceedings of the American Medical Informatics Association Annual Symposium, Wash- ington, DC, USA, 353357. D. Kauchak, O. Mouradi, C. Pentoney, and G. Leroy. 2014. Text simplification tools: Using machine learning to discover features that identify difficult text. Proceedings of the 47th Hawaii International Conference on System Sciences (HICSS), Waikaloa, Big Island, Hawaii:26162625. H. Kim, S. Goryachev, G. Rosemblat, A. Browne, A. Keselman, and Q. Zeng-Treitler. 2007. Be- yond Surface Characteristics: A New Health Text- Specific Readability Measurement. Proceedings of the American Medical Informatics Association An- nual Symposium, 418422. J. P. Kincaid, L. R. P. Fishburne, R. L. Rogers and B. S. Chissom. 1975. Derivation of new readability for- mulas for Navy enlisted personnel. Research Branch Report, Millington, TN: Chief of Naval Training, pp. 875. Korenman S. 2015. Enduring and emerging chal- lenges of informed consent. N Engl J Med. 2015 May 28;372(22):2171-2. M. Kvist and S. Velupillai. 2013. Professional Lan- guage in Swedish Radiology Reports Characteri- zation for Patient-Adapted Text Simplification. Pro- ceedings of the Scandinavian Conference on Health Informatics 2013, Copenhagen, Denmark:5559. L. T. Kohn, J. M. Corrigan, D. S. Donaldson. 2000. To err is human: building a safer health system. Wash- ington, DC: National Academy Press. 140 2015. Enduring and emerging challenges of in- formed consent. New England Journal of Medicine, 372(22):2171-2. D. Gemoets, G. Rosemblat, T. Tse, and R. Logan. 2004. Assessing Readability of Consumer Health Information: An Exploratory Study. Medinfo, 868 873. G. Grigonyt  e, M. Kvist, S. Velupillai, and M. Wir  en. 2014. Improving Readability of Swedish Elec- tronic Health Records through Lexical Simplifica- tion: First Results. Proceedings of the 3rd Work- shop on Predicting and Improving Text Readability for Target Reader Populations (PITR 2014, EACL Workshop), 7483. G. Leroy, E. Eryilmaz, and B.T. Laroya. 2007. Health information text characteristics. Proceedings of the American Medical Informatics Association Annual Symposium, Washington DC:479483. G. Leroy and J. E. Endicott. 2012. Combining NLP with Evidence-based Methods to Find Text Met- rics Related to Perceived and Actual Text Diffi- culty. Proceedings of the 2Nd ACM SIGHIT In- ternational Health Informatics Symposium, Miami, Florida, USA:749754. G. Leroy, J. E Endicott, O. Mouradi, D. Kauchak, and M. L. Just. 2012. Improving Perceived and Actual Text Difficulty for Health Information Consumers using Semi-Automated Methods. Proceedings of the American Medical Informatics Association An- nual Symposium, 522531. P. Lucisano and M. E. Piemontese. 1988. Gulpease. Una formula per la predizione della difficolt` a dei testi in lingua italiana. In Scuola e Citt` a (3), pp. 5768. M. P. Marcus, M. A. Marcinkiewicz, and B. Santorini. 1999. Building a large annotated corpus of En- glish: The Penn Treebank. Computational linguis- tics, 19(2), MIT Press:313-330. M. E. Piemontese. 1996. Capire e farsi capire. Teorie e tecniche della scrittura controllata Napoli, Tecn- odid. S. E. Petersen and M. Ostendorf. 2009. A machine learning approach to reading level assessment. In Computer Speech and Language (23), 89106. J. Proulx, S. Kandula, B. Hill, and Q. Zeng-Treitler. 2013. Creating Consumer Friendly Health Content: Implementing and Testing a Readability Diagnosis and Enhancement Tool. Proceedings of the 46th Hawaii International International Conference on- Systems Science (HICSS- 46 2013), 24452453. A. Siddharthan. 2006. Syntactic Simplification and Text Cohesion. Research on Language and Com- putation, Volume 4, Issue 1, Springer Science, the Netherlands:77109. R. Tartaglia, S. Albolino, T. Bellandi, E. Bianchini, A. Biggeri, G. Fabbro, L. Bevilacqua, A. Dellerba, G. Privitera, and L. Sommella. 2012. Eventi avversi e conseguenze prevenibili: studio retrospettivo in cinque grandi ospedali italiani. Epidemiologia &amp; Prevenzione, 36(3-4):15161. G. Terranova, M. Ferro, C. Carpeggiani, V. Recchia, L. Braga, R. Semelka, and E. Picano. 2012. Low Quality and Lack of Clarity of Current Informed Consent Forms in Cardiology - How to Improve Them. Journal of the American College of Cardiol- ogy (JACC): Cardiovascular Imaging, Elsevier inc., vol. 5(6):649655. World Health Organization. 2015. WHO global strategy on peoplecentred and inte- grated health services. Interim Report avail- able at http://apps.who.int/iris/ bitstream/10665/155002/1/WHO_HIS_ SDS_2015.6_eng.pdf Q. Zeng-Treitler, H. Kim, S. Goryachev, A. Keselman, L. Slaughter, and C. Smith. 2007b. Text charac- teristics of clinical reports and their implications for the readability of personal health records. Studies in Health Technology and Informatics, 129(2):1117 1121. Q. Zeng-Treitler, S. Goryachev, H. Kim, A. Kesel- man, and D. Rosendale. 2007a. Making Texts in Electronic Health Records Comprehensible to Con- sumers: A Prototype Translator. Proceedings of the American Medical Informatics Association Annual Symposium, 846850. Q. Zeng-Treitler, S. Kandula, H. Kim, and B. Hill. 2012. A Method to Estimate Readibility of Health Content. Proceedings of the ACM SIGKDD Work- shop on Health Informatics (HI-KDD 2012), Bei- jing, China. 141 </chunk></section></sec_map>