<sec_map><section><chunk>A Hybrid Approach to Grapheme-Phoneme Conversion Kay-Michael Wurzner and Bryan Jurish Berlin-Brandenburg Academy of Sciences Jagerstrasse 22-23 10117 Berlin Germany {wuerzner,jurish}@bbaw.de Abstract We present a simple and effective ap- proach to the task of grapheme-to- phoneme conversion based on a set of manually edited grapheme-phoneme map- pings which drives not only the align- ment of words and corresponding pro- nunciations, but also the segmentation of words during model training and applica- tion, respectively. The actual conversion is performed with the help of a conditional random field model, after which a lan- guage model selects the most likely string of grapheme-phoneme segment pairs from the set of hypotheses. We evaluate our approach by comparing it to a state-of- the-art joint sequence model with respect to two different datasets of contemporary German and one of contemporary English. </chunk></section><section><heading>1 Introduction </heading><chunk>Grapheme-to-phoneme conversion (g2p) is the process of converting graphematic representations of words into corresponding phonetic transcrip- tions. The chief difficulty associated with this task stems from the ambiguity of graphemes with re- spect to pronunciation. In German for example, the letter e can be realized as stressed, closed, long /e:/ (e.g. Met, engl. mead), as stressed, open, short /E/ (e.g. kess, engl. perky), or as un- stressed /@/ (e.g. Rampe, engl. ramp). In addi- tion, e occurs in diphthongs (e.g. eu, ei) or as a length marker (e.g. ie) without being overtly pro- nounced. Automated g2p is used most prominently in text-to-speech (TTS) systems such as that de- scribed by Black et al. (2001), where phonetic transcriptions are estimated from input text to enable subsequent synthesis of a speech signal. More recently, approaches to automatic canoni- calization of historical writing systems have made use of phonetic transcriptions as a normal form for identifying spelling variants of a modern word (Ju- rish, 2010; Porta et al., 2013). 2 Previous Work g2p implementations can be roughly divided into two types: systems using manually constructed rules and systems based on some statistical model automatically induced from training data. </chunk></section><section><heading>2.1 Rule-based Approaches </heading><chunk>Beginning with the well-known The Sound Pat- tern of English (Chomsky and Halle, 1968, SPE), phonology has been a favorite topic for grammar- ians, resulting in a large number of phonological descriptions based on transformational rule sys- tems. With Johnsons (1972) proof that rule sys- tems such as those used in SPE are equivalent in power to regular grammars and rewriting systems as long as they do not require cyclic application of rules, finite-state machines became the stan- dard data structure for implementing phonological grammars. g2p converters based on a manually designed grammar exist for many languages. They have been successfully used in various TTS sys- tems, including MITalk (Allen et al., 1987), gnuspeech (Hill et al., 1995), and festival (Taylor et al., 1998). The biggest problem with hand-written, grammar-based g2p approaches is the expertise and effort required for their pro- duction and maintenance. Consider for example TETOS (Wothke, 1993), a German g2p system developed at IBM: its grammar consists of about 1,460 rules and the authors admit, It may also oc- cur that special rules will never be applied (Hei- necke and Wothke, 1992, p. 16). </chunk></section><section><heading>2.2 Statistical Approaches </heading><chunk>Statistical or data-driven approaches to g2p are based on the assumption that regularities in the correspondence between a words spelling and its pronunciation can be automatically inferred from a set of word+transcription pairs if sufficient ap- propriate data are available. The main advantage of such approaches is the fact that creating train- ing data by (manually) transcribing word pronun- ciations is a much simpler task than creating a for- mal model of word pronunciation rules, and can be performed by non-experts. Starting with Sejnowski and Rosenberg (1987), a great number of data-driven g2p techniques have been proposed. The interested reader is referred to Reichel et al. (2008) for a competitive compari- son of various techniques. Of particular interested in the current context are the works of Bisani and Ney (2008), who present a joint-sequence model which has been praised as the gold standard in this area (Novak et al., 2012b, p. 1); and Jiampo- jamarn and Kondrak (2009), who were the first to use conditional random field models (CRFs, see Sec. 3.2) as an underlying statistical framework. </chunk></section><section><heading>3 Our Approach </heading><chunk>gramophone combines a small set of manually constructed rules with a statistical model induced from a training set of pre-transcribed words. The manual contribution constrains the alignment of the grapheme and phoneme levels, with the aim of allowing only transparent and linguistically mo- tivated alignments by for example foregoing free deletion of either grapheme- or phoneme-symbols and reducing the number of errors due to inadmis- sible alignments produced by pure statistical ap- proaches. 1 The remainder of the procedure is sim- ilar to existing approaches: grapheme strings are converted to phoneme strings and the transcription pairs are rated according to their probabilities as estimated from frequency distributions extracted from the training set. </chunk></section><section><heading>3.1 Alignment </heading><chunk>Usually, phonetic transcriptions in corresponding data sets are associated with entire words instead of being explicitly aligned at the grapheme (sub- string) level. Grapheme-phoneme alignment is therefore a fundamental preprocessing step for training a g2p system. The relation between the grapheme- and phoneme-levels is of type n : m 1 The influence of alignment on the overall performance of g2p systems has been investigated for example by Lehnen et al. (2011). with n, m N. Many automatic alignment pro- cedures make use of some Levenshtein-like mech- anism (Levenshtein, 1966) to simplify the afore- mentioned relation to the more tractable case of n, m {0, 1} (Reichel, 2012; Novak et al., 2012a). Alternatively, string-to-string alignment estimation algorithms have been proposed (Ji- ampojamarn et al., 2007; Bisani and Ney, 2008). The alignment scheme proposed here is inspired by Black et al. (1998), and may be described as constraint-based alignment: given a grapheme al- phabet G , a phoneme alphabet P , and a finite set M ( + G + P ) relating grapheme sub- strings and their potential phonemic realizations, (a) words and their transcriptions are aligned for subsequent model training, and (b) admissible seg- mentations of words into grapheme-substrings are generated for runtime transcription. The align- ment step is implemented using finite-state trans- ducers (FSTs). An FST is a labeled directed graph T = Q, , , q 0 , F, with a set of states Q, the input alphabet , the output alphabet , the initial state q 0 , a set of final states F , and a transition re- lation Q Q {} {}. Given , we may define an extended transition relation such that , q Q((q, q, , ) ) and q, r, s Q x, y a, b ((q, r, x, y) (r, s, a, b) ) (q, s, xa, yb) ). Ele- ments from are called paths in T . Starting from the given set of admissible map- pings M , we create an FST E, which we hence- forth call the editor for M . For each mapping (g, p) M , a path (q 0 , q 0 , g |, p _) is added to E with q 0 serving as the initial as well as the only final state of E. | and _ are reserved de- limiter symbols. Next, we construct FSTs I G and I P which insert the respective delimiter symbol between grapheme and phoneme segments from M into words and phonetic transcriptions, respec- tively. I G contains a path (q 0 , q 0 , g, g |) for every g in the domain of M . It generates all admissible segmentations by inserting the delimiter symbol at the appropriate location(s) on its output tape. Here again, q 0 is the initial as well as the only final state. I P is defined analogously, and contains a path for every element in the codomain of M . Finally, we construct simple letter FSTs W for a word and T for its phonetic transcription. The alignment A W,T is then the result of a series of composition opera- (a) M = p : /p/, h : /h/, ph : /f/, o : /:/, o : // n : /n/, i : /I/, k : /k/, s : /s/, x : /ks/ (b) Grapheme Segmentations = { p|h|o|n|i|x|, ph|o|n|i|x| } (c) Phoneme Segmentations = { f : n I ks , f : n I k s } (d) 0 1 o: 2 p: 3 h: 4 n: 5 i: 6 k: 7 s: 8 x: 10 |: 9 h: 11 |: 12 |: 13 |: 14 |: 15 |: 16 |: 17 |: 19 :// :// 18 |: :/p/ :/h/ :/n/ :// :/k/ :/s/ :/k/ :/f/ :_ (e) Alignment = { ph|o|n|i|x| : f : n I ks } Figure 1: gramophone alignment sketch for Phonix (engl. phoenix), pronounced /f:nIks/. Phone- mic symbols on the output tape are quoted with slashes /. (a) grapheme-to-phoneme segment mapping, (b) grapheme segmentations generated by composition with I G , (c) phoneme segmentations generated by composition with I P , (d) grapheme-to-phoneme segment mapping editor E, and (e) resulting alignment. tions: 2 A W,T = 2 (W I G ) E 2 (T I P ) (1) If multiple admissible alignments were possible if A W,T contains more than one successful path then a unique alignment path was chosen ran- domly. 2 The expression 2(X) in Equations 1 and 2 denotes the 2nd projection (output tape) of the transducer X. We assume that the returned acceptors are treated as identity-transducers in the subsequent compositions. To generate the admissible segmentations S of a word for subsequent transcription during the application stage, we make use of the first sub- expression of Equation 1, repeated below as Equa- tion 2: S = 2 (W I G ) (2) A simple example of a g2p editor is sketched in Figure 1e. </chunk></section><section><heading>3.2 Transcription </heading><chunk>We treat the transcription stage as an instance of a label assignment task: from the set of known phoneme segments (labels) from M , se- lect for each grapheme segment in an admissible word segmentation (observation) the most likely phoneme segment in the given context. In our case, labeling is performed using a CRF (Lafferty et al., 2001). Such models have become extremely popular in natural language processing (NLP) and have for example been applied to morphological analysis, tokenization, and part-of-speech tagging, in addition to g2p. CRFs can be considered a gen- eralization of probabilistic finite-state automata in the sense that they relax the requirement that each label (state) may depend only on a fixed number of previous labels (states) and the current observation (Rabiner, 1989). In contrast to modeling the joint probability of a state and an observation sequence, the conditional probability of a state given an ob- servation sequence is modeled (Wallach, 2004). The CRF is inferred from aligned gra- phone strings strings of (grapheme-substring, phoneme-substring) pairs given a set of features. These features can be understood as random vari- ables expressing the characteristics of an observa- tion. The selection of useful features is a non- trivial task. In the present case, we chose to rely only on the (observable) grapheme context. We treat the size of the available context as a free pa- rameter N , which we refer to as the order of the resulting gramophone model. Each position i in the input grapheme string o = o 1 . . . o n G is assigned a feature for each substring of o of length m N within a context window of N 1 characters relative to position i. For- mally, a gramophone model of order N has 2N 2 N m=1 m distinct feature functions f k j , where N &lt; j k &lt; N and k j &lt; N , with f k j (o i ) = o i+j o i+j+1 o i+k1 o i+k . The training process is essentially the optimiza- tion of the influence (i.e. weights) of the features by maximum likelihood learning. During runtime application, the labeling by the CRF selects the b most probable transcription(s) for each admissible segmentation. </chunk></section><section><heading>3.3 Rating </heading><chunk>The segmented and labeled transcription candi- dates returned by the CRF transcription phase are then rated using an N -gram language model to de- termine a univocal best transcription for each in- put word. The model is defined over strings of grapheme-phoneme segment pairs (graphones), defining a joint probability for each such string as a product of conditional probabilities under the ap- propriate Markov independence assumptions. N - gram language models are a standard tool in NLP and can be implemented with (weighted) finite- state techniques (Pereira and Riley, 1997). The conditional probabilities of the graphone segment N -grams are determined by simply counting graphone substrings of length N and computing their relative frequencies. To amelio- rate sparse data problems, some smoothing tech- nique has to be applied. In the present case, we use interpolation (Jelinek and Mercer, 1980) of all k-gram distributions with 1 k N in combi- nation with Kneser-Ney discounting (Kneser and Ney, 1995) for treatment of out-of-vocabulary items. Effectively, the rating step selects the most probable word-transcription pair from the set of all previously generated candidates for a given word, as estimated by the graphone N -gram model in- duced from the training set. </chunk></section><section><heading>4 Evaluation </heading><chunk>We evaluated the system described above on the task of grapheme-to-phoneme conversion for con- temporary German and English. German has a rich morphology in terms of word formation processes which are also applicable to foreign words and named entities (e.g. Versaillesdiktat /vEKzaI dIkta:t/, engl. Versailles diktat). Ele- ments of German and foreign pronunciation may thus occur within a single word, which causes finite list-based exception strategies for handling such material to fail. We report the influence of model order on both word and phoneme error rates (WER and PER, respectively) for gramophone in comparison to sequitur, 3 a freely available implementation of Bisani and Neys (2008) ap- proach. </chunk></section><section><heading>4.1 Implementation </heading><chunk>Alignment and segmentation procedures were im- plemented with the help of OpenFST (Allauzen et al., 2007). For training and run-time application of CRFs we used the wapiti toolkit (Lavergne et al., 2010), employing only unigram feature tem- 3 http://www-i6.informatik.rwth-aachen. de/web/Software/g2p.html plates as described in Section 3.2 and allowing the CRF labeling phase to generate b = 3 can- didate transcriptions for each admissible segmen- tation. The final rating of candidate hypotheses was performed using the OpenGRM N -gram li- brary (Roark et al., 2012). </chunk></section><section><heading>4.2 Data </heading><chunk>We employ three different data sets for the comparative evaluation of gramophone and sequitur. The first is the Bielefeld Lexi- con Database VM-II (Gibbon and Lungen, 2000, LexDb), which contains 76,936 entries. We converted all words to lowercase, removed dupli- cates and in cases of multiple pronunciation vari- ants for a word selected the first record. 71,481 words and their corresponding phonological rep- resentations remained for evaluation purposes. 4 The second dataset we used for evaluation is based on the pronunciations provided by the Ger- man part of the wiktionary project. 5 These pro- nunciations were created manually using common guidelines, 6 and are encoded using the Interna- tional Phonetic Alphabet (International Phonetic Association, 1999, IPA). From the wiktionary XML dump retrieved on 23 rd April, 2014, we ex- tracted 148,279 entries which were flagged as Ger- man and include a phonetic transcription. Af- ter conversion to lower-case, removal of dupli- cates, and exclusion of incomplete pronunciations (e.g. when only an inflectional suffix was tran- scribed), 147,359 entries remained. Again, we se- lected the first available record in cases of mul- tiple pronunciation variants for a word. In ad- dition, we performed an extensive manual revi- sion of the data, addressing phenomena such as incorrect IPA realizations, pseudo-words or mis- transcriptions of inflected forms possibly due to copy &amp; paste editing. The complete revised list is available for download together with the soft- ware used for evaluation at http://kaskade. 4 LexDb was also chosen by Bisani and Ney (2008) to evaluate their approach on German. The authors reported ex- cellent results (WER 1.75 %, PER 0.28 %), far better than those reported for other languages or datasets of compara- ble size. Such remarkable differences may be attributed to a greater transparency of Germans orthography (versus for example that of English), but may also be due at least in part to the fact that pronunciations in LexDb were to a large ex- tent automatically generated (Lungen, p.c.), a property which make them a dubious choice for purposes of g2p evaluation. 5 http://de.wiktionary.org 6 http://de.wiktionary.org/wiki/ Wiktionary:Deutsch/Lautschrift dwds.de/gramophone/. Additionally, we used a subset of 73,736 words from the English part of the CELEX database (Baayen et al., 1995) to test gramophones per- formance on English data, which has a reputation for being especially problematic for g2p systems. The principle challenge for g2p on English data lies in its comparative lack of phonological trans- parency compared to languages such as German or Spanish. Our implementation included for exam- ple 25 different grapheme patterns associated with the unstressed mid central vowel /@/, compared to only 5 for German. </chunk></section><section><heading>4.3 Method </heading><chunk>For each dataset, we manually prepared a set of grapheme-phoneme segment mappings M as de- scribed in Section 3.1. For the SAMPA-encoded LexDb dataset we enumerated 277 distinct map- ping pairs, versus 589 such pairs for the IPA- encoded wiktionary dataset and 463 pairs for the CELEX dataset. Each dataset was randomly par- titioned into ten chunks of approximately equal size and evaluated by 10-fold cross-validation. For each of the ten training subsets and for each model order N with 1 N 5, we trained a sequitur model of order N and a gramophone model using a context window of N grapheme segments for CRF model features and a language model of order N for candidate rating as described in Sections 3.2 and 3.3, respec- tively. 5% of the training subset was reserved as a development set for testing model convergence criteria for both sequitur and CRF model train- ing. Each trained model was applied to the re- spective disjoint test subset, and both word- and phoneme-error rates were computed for the con- catenation of all test subsets. </chunk></section><section><heading>4.4 Results &amp; Discussion </heading><chunk>Evaluation results for sequitur and gramophone are given in Table 1. The gramophone system outperformed sequitur for all conditions tested, although the differences between the two systems became less pronounced as model order increased. On the English CELEX dataset with model order N = 5 for example, gramophone and sequitur differed by only 48 phoneme errors and 50 word errors, rendering the methods effectively indistinguishable in this case. sequitur gramophone Dataset N WER% PER% WER% PER% WER% PER% de-LexDB 1 98.21 34.88 86.26 21.37 12.17 38.73 de-LexDB 2 33.12 5.26 27.94 4.18 15.64 20.53 de-LexDB 3 7.26 1.00 4.19 0.55 42.29 45.00 de-LexDB 4 1.80 0.26 1.36 0.19 24.44 26.92 de-LexDB 5 1.18 0.16 1.02 0.14 13.56 12.50 de-wiktionary 1 98.62 43.21 89.77 29.68 8.97 31.31 de-wiktionary 2 59.46 12.40 51.72 9.97 13.02 19.60 de-wiktionary 3 22.78 4.13 18.78 3.31 17.56 19.85 de-wiktionary 4 12.29 2.22 11.03 1.96 10.25 11.71 de-wiktionary 5 9.61 1.74 9.05 1.66 5.83 4.60 en-CELEX 1 98.53 45.18 87.50 31.45 11.19 30.39 en-CELEX 2 67.02 17.77 51.44 12.21 23.25 31.29 en-CELEX 3 30.74 6.71 22.80 4.85 25.83 27.72 en-CELEX 4 13.58 2.81 11.36 2.37 16.35 15.66 en-CELEX 5 8.98 1.88 8.91 1.87 0.78 0.53 Table 1: Evaluation results for sequitur and gramophone. Relative error-rate reduction values in the rightmost two columns are computed as r = (r sequitur r gramophone )/r sequitur for r {WER, PER}. For both sequitur and gramophone, er- ror rates were substantially higher for wiktionary and CELEX than for LexDB. Taken together with the unusually high accuracy rates for LexDB reported by Bisani and Ney (2008), this phe- nomenon suggests that the grapheme-phoneme correspondences encoded in LexDB are them- selves particularly amenable to machine learning techniques. Given that these data were to a large extent automatically generated, this is not surpris- ing. Nonetheless, it may also be the case that the raw wiktionary data due to the distributed and collaborative nature of their creation dis- play less internal consistency than single-source datasets typically created in the context of aca- demic projects. Although we attempted to ad- dress and remove such inconsistencies as part of the data preparation process described in Section 4.2, some degree of noise is likely to remain in the wiktionary data. In general, gramophone models learned more quickly than their sequitur counterparts of the same order, but the relative improvement tends to decrease as the order of the model increases, par- ticularly with regard to phoneme error-rates. In- deed, the observed differences in transcription ac- curacy between the two approaches on all three datasets becomes negligible for N = 5. In light of these trends, it may well be the case that sequitur will overtake gramophone as model order grows beyond N = 5, since gramophones reliance on a set of manual align- ment heuristics would prevent it from discov- ering a correct transcription whenever the nec- essary segment mappings are not encoded in its editor, effectively setting an upper bound for gramophone transcription accuracy. Lack- ing any such alignment constraints, sequitur would be free to learn the proper transcriptions in such cases. </chunk></section><section><heading>5 Conclusion &amp; Outlook </heading><chunk>We have presented gramophone, a hybrid sys- tem for grapheme-to-phoneme conversion using a simple set of manually constructed alignment mappings to provide a grapheme-level segmenta- tion of each input word. Each segment is assigned a phoneme-segment label by a conditional random field model, and the resulting graphone strings are passed to an N -gram language model to select the optimal transcription. We tested our approach by comparing it to the sequitur system described by Bisani and Ney (2008) on two independent datasets of contemporary German and one of con- temporary English. Our approach outperformed sequitur on all conditions tested, although decreasing ab- solute and relative error reduction rates for gramophone with respect to sequitur lead in general to only minimal observable differences for model order N = 5. Future work should investigate whether the upper bound imposed by gramophones reliance on explicit heuristics to provide all admissible segmentations counteracts its performance benefits with respect to pure sta- tistical approaches such as sequitur for higher model orders. We are also interested in determining to what extent the gramophone architecture can be sim- ulated using purely (weighted) finite-state means, in particular with the aim of reducing memory-, I/O-, and computation overhead incurred by over- generation in the alignment phase by means of lazy best-path search in weighted transducer cascades (Mohri, 2002; Jurish, 2010a). While CRFs cannot in general be represented as WF- STs, the CRF employed by gramophone uses only observable features and thus contains no overt feature-dependency cycles; it is currently un- known to the authors whether a WFST equiva- lent exists in this case. Similarly, the shift from a transducer-like representation during the label- ing phase to a string-of-pairs representation for the rating phase cannot in general be implemented us- ing traditional (W)FSTs, since these do not admit intersection in the general case (Roche and Sch- abes, 1997). We speculate that since the maximum length of an alignment mapping is finite and deter- mined at compile-time by the finite set of mapping heuristics, an efficient WFST approximation may be possible. </chunk></section><section><heading>References </heading><chunk>Cyril Allauzen, Michael D. Riley, Johan Schalkwyk, Wojciech Skut, and Mehryar Mohri. 2007. Open- Fst: A general and efficient weighted finite-state transducer library. In Proceedings of the Twelfth In- ternational Conference on Implementation and Ap- plication of Automata, volume 4783 of LNCS, pages 1123. Springer. Jonathan Allen, M. Sharon Hunnicutt, and Dennis Klatt. 1987. From Text to Speech: the MITalk sys- tem. Cambridge University Press. R. Harald Baayen, Richard Piepenbrock, and Leon Gu- likers. 1995. The CELEX Lexical Database (Re- lease 2) [CD-ROM]. Linguistic Data Consortium, University of Pennsylvania, Philadelphia, PA. Maximilian Bisani and Hermann Ney. 2008. Joint- sequence models for grapheme-to-phoneme conver- sion. Speech Communication, 50(5):434451. Alan W. Black, Kevin Lenzo, and Vincent Pagel. 1998. Issues in building general letter to sound rules. In Third ESCA/COCOSDA Workshop on Speech Syn- thesis, pages 7780. International Speech Commu- nication Association. Alan Black, Paul Taylor, Richard Caley, Rob Clark, Korin Richmond, Simon King, Volker Strom, and Heiga Zen. 2001. The festival speech synthesis sys- tem version 1.4.2. Software, Jun. Noam Chomsky and Morris Halle. 1968. The Sound Pattern of English. Harper and Row. Dafydd Gibbon and Harald Lungen. 2000. Speech lexica and consistent multilingual vocabularies. In Wolfgang Wahlster, editor, Verbmobil: Foundations of Speech-to-Speech Translation. Springer. Johannes Heinecke and Klaus Wothke. 1992. Letter- to-phone rules for German taking into account the morphological structure of words. Technical Report 75.92.03, Heidelberg Scientific Center. David Hill, Leonard Manzara, and Craig Schock. 1995. Real-time articulatory speech-synthesis-by- rules. In Proceedings of AVIOS, volume 95, pages 2744. International Phonetic Association. 1999. Handbook of the International Phonetic Association: A guide to the use of the International Phonetic Alphabet. Cambridge University Press. Frederick Jelinek and Robert L. Mercer. 1980. In- terpolated estimation of Markov source parame- ters from sparse data. In Edzard S. Gelsema and Laveen N. Kanal, editors, Pattern Recognition in Practice, pages 381397. North-Holland. Sittichai Jiampojamarn and Grzegorz Kondrak. 2009. Online discriminative training for grapheme-to- phoneme conversion. In INTERSPEECH-2009, pages 13031306. Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek Sherif. 2007. Applying many-to-many alignments and hidden Markov models to letter-to-phoneme conversion. In Human Language Technologies 2007: The Conference of the North American Chap- ter of the Association for Computational Linguistics, pages 372379. ACL. Douglas C. Johnson. 1972. Formal Aspects of Phono- logical Descriptions. Mouton. Bryan Jurish. 2010. More than words: Using to- ken context to improve canonicalization of historical German. JLCL, 25(1):2340. Bryan Jurish. 2010a. Efficient online k-best lookup in weighted finite-state cascades. In Thomas Han- neforth and Gisbert Fanselow, editors, Language and Logos: Studies in Theoretical and Computa- tional Linguistics, volume 72 of Studia grammatica, pages 313327. Akademie Verlag, Berlin. Reinhard Kneser and Herman Ney. 1995. Improved backing-off for m-gram language modeling. In In- ternational Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 181184. John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling se- quence data. In Proceedings of the Eighteenth In- ternational Conference on Machine Learning, pages 282289. Morgan Kaufmann. Thomas Lavergne, Olivier Cappe, and Francois Yvon. 2010. Practical very large scale CRFs. In Proceed- ings the 48th Annual Meeting of the Association for Computational Linguistics, pages 504513. ACL. Patrick Lehnen, Stefan Hahn, Andreas Guta, and Her- mann Ney. 2011. Incorporating alignments into conditional random fields for grapheme to phoneme conversion. In International Conference on Acous- tics, Speech and Signal Processing, pages 4916 4919. IEEE. Vladimir I. Levenshtein. 1966. Binary codes capa- ble of correcting deletions, insertions, and reversals. Soviet Physics Doklady, 10(1966):707710. Mehryar Mohri. 2002. Semiring frameworks and algorithms for shortest-distance problems. Jour- nal of Automata, Languages and Combinatorics, 7(3):321350. Josef R. Novak, Paul R. Dixon, Nobuaki Minematsu, Keikichi Hirose, Chiori Hori, and Hideki Kash- ioka. 2012a. Improving WFST-based g2p conver- sion with alignment constraints and RNNLM n-best rescoring. In INTERSPEECH-2012. Josef R. Novak, Nobuaki Minematsu, and Keikichi Hi- rose. 2012b. WFST-based grapheme-to-phoneme conversion: Open source tools for alignment, model-building and decoding. In Proceedings of the 10th International Workshop on Finite State Meth- ods and Natural Language Processing, pages 4549. ACL. Fernando C. Pereira and Michael D. Riley. 1997. Speech recognition by composition of weighted fi- nite automata. In Emmanuel Roche and Yves Schabes, editors, Finite-State Language Processing, chapter 15, pages 433453. MIT Press. Jordi Porta, Jose-Luis Sancho, and Javier Gomez. 2013. Edit transducers for spelling variation in Old Spanish. In Proceedings of the workshop on com- putational historical linguistics at NoDaLiDa 2013, NEALT Proceedings Series 18 / Linkoping Elec- tronic Conference Proceedings 87, pages 7079. Lawrence R. Rabiner. 1989. A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2):257 285. Uwe Reichel, Hartmut R Pfitzinger, and Horst-Udo Hain. 2008. English grapheme-to-phoneme conver- sion and evaluation. Speech and Language Technol- ogy, 11:159166. Uwe D. Reichel. 2012. PermA and Balloon: Tools for string alignment and text processing. In INTERSPEECH-2012. Brian Roark, Richard Sproat, Cyril Allauzen, Michael D. Riley, Jeffrey Sorensen, and Terry Tai. 2012. The OpenGrm open-source finite-state grammar software libraries. In Proceedings of the ACL 2012 System Demonstrations, pages 6166. ACL. Emmanuel Roche and Yves Schabes. 1997. Introduc- tion. In Emmanuel Roche and Yves Schabes, ed- itors, Finite-State Language Processing, chapter 1, pages 165. MIT press. Terence J. Sejnowski and Charles R. Rosenberg. 1987. Parallel networks that learn to pronounce English text. Complex Systems, 1(1):145168. Paul Taylor, Alan W. Black, and Richard J. Caley. 1998. The architecture of the Festival speech syn- thesis system. In Proceedings of the Third Interna- tional Workshop on Speech Synthesis. Hanna M. Wallach. 2004. Conditional random fields: An introduction. Technical Report MS-CIS-04-21, University of Pennsylvania, Department of Com- puter and Information Science. Klaus Wothke. 1993. Morphologically based auto- matic phonetic transcription. IBM Systems Journal, 32(3):486511. </chunk></section></sec_map>