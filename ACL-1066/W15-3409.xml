<sec_map><section><chunk>Proceedings of the Eighth Workshop on Building and Using Comparable Corpora, pages 6267, Beijing, China, July 30, 2015. c 2015 Association for Computational Linguistics Extracting Bilingual Lexica from Comparable Corpora Using Self-Organizing Maps Hyeong-Won Seo Min-Ah Cheon Jae-Hoon Kim Department of Computer Engineering, Korea Maritime and Ocean University, Busan 606-791, Republic of Korea wonn24@gmail.com minah014@outlook.com jhoon@kmou.ac.kr </chunk></section><section><heading>Abstract </heading><chunk>This paper aims to present a novel method of extracting bilingual lexica from compa- rable corpora using one of the artificial neural network algorithms, self-organiz- ing maps (SOMs). The proposed method is very useful when a seed dictionary for translating source words into target words is insufficient. Our experiments have shown stunning results when contrasted with one of the other approaches. For fu- ture work, we need to fine-tune various parameters to achieve stronger perfor- mances. Also we should investigate how to construct good synonym vectors. </chunk></section><section><heading>1 Introduction </heading><chunk>Bilingual lexicon extraction from comparable cor- pora has been studied by many researchers since the late 1990s (Fung, 1998; Rapp 1999; Chiao &amp; Zweigenbaum, 2002; Ismail &amp; Manandhar, 2010; Hazem &amp; Morin, 2012). To our knowledge, one of the basic approaches is the context vector-based approach (Rapp, 1995; Fung, 1998) called the standard approach in the literatures, and many other studies have been de- rived from this approach. Some of these are con- cerned with similarity score measurement (Fung, 1998; Rapp, 1999; Koehn &amp; Knight, 2002; Pro- chasson et al., 2009), the size of the context win- dow (Daille &amp; Morin, 2005; Prochasson et al., 2009), and the size of the seed dictionary (Fung, 1998; Rapp, 1999; Chiao &amp; Zweigenbaum, 2002; Koehn &amp; Knight, 2002; Daille &amp; Morin, 2005). The extended approach, one of such approaches, (Dejean et al., 2002; Daille &amp; Morin, 2005) has been proposed in order to reduce the load on the seed dictionary. It gathers k nearest neighbors to augment the context of the word to be translated. In spite of their efforts, using comparable corpora for extracting such lexica yields quite poor perfor- mances unless orthographic features are used. However, such features may bring other costs. Under the circumstances like this, this paper is motivated to propose an efficient method in which comparable corpora with a minimum of resources are considered for extracting bilingual lexica. The SOM-based approach, we propose in this paper, can yield stronger performances with the same ex- perimental circumstance than earlier studies can do. In order to show this, we compare the pro- posed method to the standard approach. Of course, it does not meaning our method outperforms for every data. We just show the proposed method is reasonable for this field. The rest of the paper is structured as follows: Section 2 presents several works closely related to our method. Section 3 describes our method (the SOM-based approach) in more detail. Section 4 shows experimental results with discussions, and Section 5 concludes the paper and presents future research directions. </chunk></section><section><heading>2 Related Works </heading></section><section><heading>2.1 Context-based approach </heading><chunk>As has been noted earlier, the standard approach (Rapp, 1995; Fung, 1998) is proposed to extract bilingual lexica from comparable corpora. It uses 62 contextually relevant words in a small-sized win- dow. Selecting similar context vectors between source and target languages is the key feature of the approach. Since the approach uses comparable corpora, a seed dictionary to translate one to an- other language is required. Additionally, a large scale of corpora as well as sufficient amount of initial seed dictionaries should be prepared for a better performance. </chunk></section><section><heading>2.2 Self-organizing maps </heading><chunk>A self-organizing map (SOM) (Kohonen, 1982; 1995) is one of the artificial neural network mod- els and represents a huge amount of input data in a more illustrative form in a lower-dimensional space. In general, a SOM is an unsupervised and competitive learning network. It has been studied extensively in recent years. For example, SOMs have been studied in pattern recognition (Li et al., 2006; Ghorpade et al., 2010), signal processing (Wakuya et al., 2007), multivariate statistical analysis (Nag et al., 2005), data mining (Junior et al., 2013), word categorization (Klami &amp; Lagus, 2006), and clustering (Juntunen et al., 2013). Since a SOM tries to keep the topological prop- erties of input data, semantically/geometrically similar inputs are generally mapped around one neuron, usually in the form of a two-dimensional lattice (i.e. a map). Significantly, the SOM can be used for clustering the input vectors and finding features inherent to the problem. In this perspec- tive, we can expect that actual similar words have one common winner (winning neuron) or share the same neighbors if input vectors are semanti- cally well-formed. Based on this characteristic, a main idea of the proposed method is to make two different words that are translations of each other have one com- mon winner. If a new input data has a similar input trained already, the SOMs can extract its transla- tions based on its neighbors. Consequently, neigh- bors (i.e. semantically similar words) also share similar areas in the feature map. </chunk></section><section><heading>3 SOM-based approach </heading><chunk>The overall structure of the SOM-based approach can be summarized as follows (see Figure 1 for more details): i. Building synonym vectors: In this paper, the synonym vector indicates a vector that consists of words semantically related to each other. There- fore, synonym vectors should be constructed in a semantic fashion not a co-relational fashion. For example, the vector for baby should very similar to the vector for kid not just for closely related toy or sitter. Therefore, building synonym vectors is one of the most important issues in this work. For this, we firstly build context vectors via contextu- ally related words in a fixed-size window. This context vector is weighted by an association measure, such as the PMI or the chi-square. After context vectors are built, similarity scores be- tween the vectors are computed. In this paper, the similarity score, as occurs so often in information retrieval, is computed by cosine similarity. Synonyms can be identified based on the scores higher than a reasonable threshold. Synonym vec- tors are then weighted by the scores. For instance, let kid be a base word to be vectored. In this case, its elements are similarity scores between kid and the most similar k words, such as baby, teenager, and youth. Consequently, well-made synonym vectors have a SOM reflects the topological prop- erties of input data and will obtain common win- ners after the SOMs are trained. Note that such context vectors are very sensi- tive to experimental data and parameters such as association/similarity measures, so any kind of vector is welcomed here. We just assume seman- tically formed synonym vectors are already avail- able before we train SOMs. ii. SOM training: After the source and target syn- onym vectors are built, we train two sorts of SOMs in different ways. Figure 2 describes how two SOMs are trained interactively. Source corpus Target corpus Building synonym vectors SOM training Extracting translations Bilingual dictionary Figure 1. Overall structure of SOM-based ap- proach 63 Firstly, we train the source SOM in an unsuper- vised fashion. The general SOM algorithm to train all source words can be summarized as follows: 1) Set an initial weight vector i ii i(0) with small random values [0, 1], and set learning rate i i14i i14(i ii i) with a small positive value ( 0 &lt; i i14i i14(i ii i) i i14i i14(i ii i 1) 1). The iteration i ii i is for one input data. 2) For every single input i ii i, find the winning neuron (i.e. winner) i ii i which has minimum score based on Euclidean distances between an input and weight vectors i ii i i ii i i ii i = min i ii i i ii i i ii i i ii i . 3) Update the weight vectors of winning neuron i ii i and its neighbors as follows: i ii i i ii i (i ii i + 1) = i ii i i ii i (i ii i) + i i14i i14(i ii i)h(i ii i)[i ii i(i ii i) i ii i i ii i (i ii i)] , where i ii i denotes time, i ii i(i ii i) is an input vector at i ii i, and h(i ii i) is the neighborhood kernel around the winner i ii i. In this step, we update them in online mode which means one update per one input (c.f. an offline mode means one update per all inputs). 4) Repeat the steps 2) and 3) until a certain ter- mination condition like the maximum number of iterations is reached. After the source SOM is trained in an unsuper- vised fashion, we train the target SOM in a super- vised fashion. In this case, most of steps are the same with the case of the source. Note that we should aware of updating the target weight vectors. Target winners which of words excluded in the seed dictionary are updated naturally as the case of the source. The others which of words included </chunk></section><section><heading>1 Korean: http://www.naver.com, French: http://www.lemonde.fr, and Spanish: http://www.abc.es </heading><chunk>in the seed dictionary are updated by calling re- lated source winners. Therefore, two different words which are translations to each other can be located in the same topological location of two different SOMs. We think that we can teach cor- rect labels to insiders (i.e. the target words that in- cluded in the seed dictionary) not for outsiders. As mentioned before, if synonym vectors are well- formed as well as two SOMs are well-trained, a source word and its translation will have one com- mon winner. Although a target word is not trained yet, the word can be extracted when its synonym is trained. iii. Extracting translations: After two SOMs are trained interactively, SOM vectors should be con- structed based on each feature map (i.e. the source and target). In this case, similarity scores between an input vector and weight vectors become ele- ments of SOM vectors. That is, a length of the SOM is a dimension of the SOM vector. After the SOM vectors are built, similarity scores between one source SOM vector and all target SOM vectors are calculated by cosine sim- ilarity. And then, the top k candidates are selected and added to the bilingual lexicon. </chunk></section><section><heading>4 Experiments </heading><chunk>In this paper, we evaluate the proposed method for two language pairs KoreanFrench (KRFR) and KoreanSpanish (KRES). Regarding the comparison, we implemented the standard ap- proach mentioned in Section 2.1. Note that the standard approach implemented here is not com- plete. There are many chances to show better per- formances by fine-tuning several parameters, such as the size of the context window, and asso- ciation/similarity measures. However, we can briefly estimate them because both methods are implemented by using same resources. Several parameters are fixed as follows: the context size of the window as 5, and the association measure as a chi-square test, and the similarity measure as a cosine similarity. These measures were empiri- cally chosen from our experimental data. We used three comparable corpora (Kwon et al., 2014) in Korean, French, and Spanish. Each cor- pus included around 800k sentences collected from the Web 1 . The Korean corpus consists of news articles and some are derived from different sources (Seo et al., 2006). The others also consists Seed Dict i ii i i ii i i i i i  i ii i i ii i i i i i  i i i i i i i i  i i i i (i ii i i ii i i i i i  , i ii i i ii i i i i i  ) (kid) (baby) 0.82 (teenage) 0.64 ... ... Unsupervised training the source SOM Source synonym vectors (kid) i ii i i ii i i ii i i ii i i ii i i ii i i i i i i i i i  i i i i (i ii i i ii i i ii i , i ii i i ii i i ii i ) bebe (baby) 0.90 jeunesse (youth) 0.83 enfant (kid) ... ... Target synonym vectors Iterative SOM training enfant (kid) Supervised training the target SOM Figure 2. SOM training 64 of news articles (around 400k sentences), and some are combined with the European parliament proceedings (400k randomly sampled sentences) (Koehn, 2005). The Korean corpus has around 280k word types (180k for French and 185k for Spanish), and the average number of words per sentence is 16.2 (15.9 for French and 16.1 for Spanish). Consequently, the balance of three cor- pora is well-formed. We extracted nouns from these corpora for our test sets as well as input data. We considered only nouns to reduce the sizes of the dimensions of ei- ther synonym vectors or SOMs. Thus, we finally collected almost 190k Korean noun types (45k for French and 58k for Spanish). The reason why the number of Korean noun types was higher than others was due to Korean characteristics. We should split the Korean words into morpheme units because there are a lot of compound words and omitted morphemes. Furthermore, we col- lected very finely segmented Korean nouns to eliminate indulgent compound nouns that were possibly missed during a word segmentation task. All collected nouns were considered candidates of both test sets and seed words independently. After the input data was prepared, we built syn- onym vectors, as mentioned previously. We al- ready introduced the method how to construct synonym vectors. However, this paper doesnt mainly propose the efficient way of representing words semantically in vector spaces. If synonym vectors are built based on context vectors and their similarity scores, the size of the vector dimension would be very huge. It would cause many time- consuming problems. In this paper, we simply use word2vec 2 to build synonym vectors. As far as we know, word2vec cannot yield semantically related vectors as output. However, we used this tool to reduce vector sizes and assume these outputs (i.e. vectors) are reasonable as the input data for train- ing SOMs. Some parameters for building syno- nym vectors can be presented as follows: window size is 5, word vector size is 100, and training it- eration is 100. </chunk></section><section><heading>4.1 Evaluation dictionary </heading><chunk>We manually built evaluation dictionaries to eval- uate our method because such dictionaries for KRFR/ES are publicly unavailable. Each dic- tionary contains 200 high-frequency nouns. The reason why we picked high-frequency nouns is 2 http://code.google.com/p/word2vec/ that these nouns have more chances to have neigh- bors than low-frequency words. In order to evalu- ate whether the proposed approach is valid (i.e. whether trained SOM can extract new input data that not trained), we need to train words having many neighbors. These 200 source words were se- lected if actual translations were in their corpora. Thus, the 200th source word did not indicate a 200th high-frequency word. The KRFR 3 dic- tionary had total of 288 translations (451 transla- tions in the FRKR dictionary), and the KRES dictionary contained 377 translations (687 trans- lations in the ESKR dictionary). Additionally, regretfully, there were several duplicated transla- tions for every language. In the case of KRFR, the Korean words had 447 French translations (420 types) and the French words had 209 Korean translations (189 types). In the case of KRES, the Korean words had 456 Spanish translations (369 types) and the Spanish words had 509 Korean translations (421 types). We did not perform any heuristic process to give each source word a unique sense. Instead, we assumed related source words corresponding to a single translation were semantically the same. </chunk></section><section><heading>4.2 Seed dictionary </heading><chunk>The seed dictionaries were also built manually based on the high-frequency nouns as mentioned before. Seed words, however, were not over- lapped with evaluation data. We chose 11,910 Ko- rean noun types (8,105 French types and 7,458 Spanish types) out of 94% of the total words in the corpus. As mentioned before, 11,910 Korean noun types out of 190k (total) noun types is an ex- tremely low number. Except 200 of the highest- frequency words (contained in the evaluation dic- tionary), we finally collected 2,399 Korean seed nouns having their translations in the target cor- pora for KRFR, 4,387 Korean seed nouns for KRES, 2,138 French seed nouns for FRKR, and 1,813 Spanish seed nouns for ESKR, re- spectively. </chunk></section><section><heading>5 Results </heading><chunk>Unfortunately, we do not have a publicly accepted gold standard or experimental guidelines in these language pairs. By and large, the best perfor- mances depended on various experimental set- tings, such as languages, document domains, and 3 The symbol means unidirectional way (i.e. source to target only). 65 seed dictionaries. Doubtless, the quality of syno- nym vectors and seed dictionaries including trained SOMs are the most important issues for achieving high performances. Additionally, we ignore evaluations of the quality of synonym vec- tors in this paper. We only consider accuracies for the top 20 candidates for two sets of language pairs (i.e. KRFR and KRES). For simplified experiments, we fixed several parameters as follows: The dimension of the syn- onym vector as 100, the size of the Gaussian func- tion as 25 (55), the learning rate as 0.1, and the epoch as 2000. These parameters were given based on preceding experiments. In case of a SOM size, all sizes are different for covering most of seed words (one-to-one mapping had shown poor performances due to the fixed and small- sized Gaussian function). We tried to find the best parameters via fine-tuning, but most could be fur- ther improved in future research. The accuracies for two sets of language pairs are described in Figures 2 to 5. In those figures, the BASE means the standard approach, the SOM means the SOM-based approach, the number around brackets means a size of the SOM, x-axis indicates ranks, and y-axis indicates accuracies. As can be seen, the SOM-based approach outper- formed the standard approach over all language settings. 4 The Korean gloss is presented before a semicolon in brackets. </chunk></section><section><heading>5 The similarity score between AUAu and Au is 0.88. </heading><chunk>In our experimental results of the KR to FR pair, for example, we extracted strategie (strategy) as the translation of the source word Au (jeonryak 4 ; strategy, operation) where their neighbors, AUAu 5 (jakjeon; operation, tactic, strategy) and ope- ration 6 (operation), are included in the seed dic- tionary. If new input data (to be tested) have very similar seed words, we can extract correct transla- tions through well-trained SOMs. Although the sizes of SOMs were neither the same nor the best sizes, we can see the proposed approach is quite outstanding compared with the standard approach. </chunk></section><section><heading>6 Conclusion </heading><chunk>This paper proposes a novel method for extracting bilingual lexica from comparable corpora by us- ing SOMs. The method trains two sorts of SOMs, either in an unsupervised fashion and a supervised fashion, respectively. As we can see the experi- mental results, our method generally outperforms the standard approach under the same experi- mental conditions (i.e. the same seed dictionaries and corpora). Although the given parameters are not the best for both approaches so far, our method shows stunning results. For future work, we can tune parameter factors such as the size of SOMs, the Gaussian function, and the epoch. Moreover, various parts-of-speech </chunk></section><section><heading>6 The similarity score between operation and strategie is 0.82. </heading><chunk>0% 10% 20% 30% 40% 50% 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 BASE SOM (1400) Figure 2. Accuracies of the KRFR pair 0% 10% 20% 30% 40% 50% 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 BASE SOM (1600) Figure 3. Accuracies of the FRKR pair 0% 10% 20% 30% 40% 50% 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 BASE SOM (1600) Figure 5. Accuracies of the ESKR pair 0% 10% 20% 30% 40% 50% 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 BASE SOM (3600) Figure 4. Accuracies of the KRES pair x-axis: rank, y-axis: accuracy 66 could be considered, as we only considered nouns in this work. In addition, a deep analysis of errors is required. </chunk></section><section><heading>Acknowledgements </heading><chunk>This work was supported by the ICT R&amp;D program of MSIP/IITP. [10041807 , Development of Original Software Technology for Automatic Speech Transla- tion with Performance 90% for Tour/International Event focused on Multilingual Expansibility and based on Knowledge Learning] </chunk></section><section><heading>References </heading><chunk>Y.-C. Chiao and P. Zweigenbaum. 2002. Looking for candidate translational equivalents in specialized, comparable corpora. In Proceedings of the 19th in- ternational conference on Computational Linguistics, Coling02, pp. 12081212. B. Daille and E. Morin. 2005. French-English termi- nology extraction from comparable corpora. In Pro- ceedings of the 2nd International Joint Conference on Natural Language Processing, IJCNLP05, pp. 707718. H. Dejean, E. Gaussier, and F. Sadat. 2002. An ap- proach based on multilingual thesauri and model combination for bilingual lexicon extraction. In Pro- ceedings of the 19th International Conference on Computational Linguistics (COLING02), 1: 1-7. P. Fung. 1998. A statistical view on bilingual lexicon extraction: from parallel corpora to non-parallel cor- pora. In Proceedings of the 3rd conference of the As- sociation for Machine Translation in the Americas, Amta98, pp. 116. S. Ghorpade, J. Ghorpade, and S. Mantri. 2010. Pattern Recognition Using Neural Networks. International Journal of Computer Science &amp; Information Tech- nology, IJCSIT, 2(6): 92-98. A. Hazem and E. Morin. 2012. Qalign: A new method for bilingual lexicon extraction from comparable cor- pora. In Proceedings of the 13th International Con- ference on Computational Linguistics and Intelligent Text Processing, CICLing12, volume 2 of Lecture Notes in Computer Science, pp. 8396. A. Ismail and S. Manandhar. 2010. Bilingual lexicon extraction from comparable corpora using in-domain terms. In Proceedings of the 23rd International Con- ference on Computational Linguistics, Coling10, pp. 481489. E. Junior, G. Breda, E. Marques, and L. Mendes. 2013. Knowledge discovery: Data mining by self-organiz- ing maps. Web Information Systems and Technolo- gies, Lecture Notes in Business Information Pro- cessing, 140: 185200. P. Juntunen, M. Liukkonen, M. Lehtola, and H. Yrjo. 2013. Cluster analysis by self-organizing maps: An application to the modelling of water quality in a treatment process. Applied Soft Computing, 13(7): 31913196. M. Klami and K. Lagus. 2006. Unsupervised word cat- egorization using self-organizing maps and automat- ically extracted morphs. Intelligent Data Engineer- ing and Automated Learning, IDEAL 2006, volume 4224 of Lecture Notes in Computer Science, pp. 912 919. P. Koehn and K. Knight. 2002. Learning a translation lexicon from monolingual corpora, In Proceedings of the Association for computational linguistic on unsu- pervised lexical acquisition, pp. 916. P. Koehn. 2005. Europarl: a parallel corpus for statisti- cal machine translation. In Proceeding of 10th Con- ference on Machine Translation Summit, 7986. T. Kohonen. 1982. Self-organized formation of topo- logically correct feature maps. In Biological Cyber- netics, 43(1): 5969. T. Kohonen. 1995. Self-organizing maps. Springer, volume 30. H. Kwon, H.-W. Seo, M.-A. Cheon, and J.-H. Kim. 2014. Iterative bilingual lexicon extraction from comparable corpora using a modified perceptron al- gorithm. Journal of Contemporary Engineering Sci- ences, 7(24): 13351343. C. Li, H. Zhang, J. Wang, and R. Zhao. 2006. A new pattern recognition model based on heuristic SOM network and rough set theory. In Vehicular Electron- ics and Safety 2006, ICVES 2006, IEEE International Conference on, pp. 4548. A. K. Nag, A. Mitra, and S. Mitra. 2005. Multiple out- lier detection in multivariate data using self-organiz- ing maps title. Computational Statistics, 20(2): 245 264. E. Prochasson, E. Morin, and K. Kageura. 2009. An- chor points for bilingual lexicon extraction from small comparable corpora. In Proceedings of the 12th Conference on Machine Translation Summit (MT Summit XII), pp. 284291. R. Rapp. 1995. Identifying word translations in non- parallel texts. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, ACL 33, pp. 320322. R. Rapp. 1999. Automatic identification of word trans- lations from unrelated English and German corpora. In Proceedings of the 37th Annual Meeting of the As- sociation for Computational Linguistics, ACL 99, pp. 519526. H.-W. Seo, H.-C. Kim, H.-Y. Cho, J.-H. Kim, and S.- I. Yang. 2006. Automatically constructing English Korean parallel corpus from Web documents (in Ko- rean). In Proceeding of 26th Conference on Korea In- formation Processing Society fall conference, KIPS, 13(2): 161164. H. Wakuya, H. Harada, and K. Shida. 2007. An archi- tecture of self-organizing map for temporal signal processing and its application to a braille recognition task (in Japanese). Systems and Computers in Japan, 38(3):6271. Translated from Denshi Joho Tsushin Gakkai Ronbunshi, J87-D-II (3): 884892. 67 </chunk></section></sec_map>