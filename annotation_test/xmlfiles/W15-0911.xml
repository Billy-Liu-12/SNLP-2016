<sec_map><section><chunk>Proceedings of NAACL-HLT 2015, pages 6569, Denver, Colorado, May 31 June 5, 2015. c 2015 Association for Computational Linguistics Phrase translation using a bilingual dictionary and n-gram data: A case study from Vietnamese to English Khang Nhut Lam, Feras Al Tarouti and Jugal Kalita Computer Science Department University of Colorado, Colorado Springs, USA {klam2,faltarou,jkalita}@uccs.edu Abstract Past approaches to translate a phrase in a lan- guage L 1 to a language L 2 using a dictionary- based approach require grammar rules to re- structure initial translations. This paper intro- duces a novel method without using any gram- mar rules to translate a given phrase in L 1 , which does not exist in the dictionary, to L 2 . We require at least one L 1 L 2 bilingual dic- tionary and n-gram data in L 2 . The average manual evaluation score of our translations is 4.29/5.00, which implies very high quality. </chunk></section><section><heading>1 Introduction </heading><chunk>This paper tackles the problems of phrase transla- tion from a source language L 1 to a target language L 2 . The common approach translates words in the given phrase to L 2 using an L 1 L 2 dictionary, then restructures translations using grammar rules which have been created by experts or are extracted from corpora. We propose a new method for phrase trans- lation using an L 1 L 2 dictionary and n-gram data in L 2 , instead of grammar rules, with a case study in translating phrases from Vietnamese to English. We note that the given Vietnamese phrases for transla- tion do not exist in the dictionary. For example, we translate Vietnamese phrases bb mon khoa hhc may tinh, thuu thu nhhp ca nhan and i mmt chut to English: computer science department, indi- vidual income tax, and wait a little, respectively. In particular, given a Vietnamese phrase, our algo- rithms return a list of ranked translations in English. One purpose of the phrase translations in our work is to support language learners. Assume that, us- ing a Vietnamese-English dictionary, a learner has looked up translations of bb mon, khoa hhc and may tinh as department/faculty, science and calculator/computer, respectively. Now, he wants to obtain the translation of bb mon khoa hhc may tinh, a phrase which does not exist in the dictionary. We present a method to generate phrase translations based on information in the dictionary. </chunk></section><section><heading>2 Overall Vietnamese morphology </heading><chunk>Vietnamese is an Austroasiatic language (Lewis et al., 2014) and does not have morphology (Thomp- son, 1963) and (Aronoff and Fudeman, 2011). In Vietnamese, whitespaces are not used to separate words. The smallest meaningful part of Vietnamese orthography is a syllable (Ngo, 2001). Some exam- ples of Vietnamese words are shown as following: Single words: nha- house, lla- silk, nhht- pick up, mua- buy and ban- sell. Compound words: mua ban- buy and sell, ban ghh- table and chair, ng ruung- rice field, me en- black sesame, cay cci- trees, uung xa- street, mmu giao- kindergarden, hanh chanh- administration, thh ccm- bro- cade, vang vang- yellowish, ngi ngi- hes- itate, gt ga gt gu- nod repeatedly out of sat- isfaction, lli nhhi- annoyingly insistent. Thus, what we call a word in Vietnamese may con- sist of several syllables separted by whitespaces. 3 Related work The two methods, commonly used for phrase trans- lation, are dictionary-based and corpus-based. A 65 dictionary-based approach, e.g., (Abiola et al., 2014) generate translation candidates by translating the given phrase to the target language using a bilin- gual dictionary. The candidates are restructured using grammar rules which are developed manu- ally or learned from a corpus. In corpus-based ap- proaches, a statistical method is used to identify bilingual phrases from a comparable or parallel cor- pus (Pecina, 2008), (Koehn and Knight, 2003), and (Bouamor et al., 2012). Researchers may also ex- tract phrases from a given monolingual corpus in the source language and translate them to the tar- get language using a bilingual dictionary (Cao and Li, 2002), and (Tanaka and Baldwin, 2003). Finally, a variety of methods are used to rank translation candidates. These include counting the frequency of candidates in a monolingual corpus in the target language, standard statistical calculations (Pecina, 2008), or even using Naive Bayes Classifiers and TF-IDF vectors with the EM algorithm (Cao and Li, 2002). (Marino et al., 2006) extract translations from a bilingual corpus using an n-gram model aug- mented by additional information, target-language model, a word-bonus model and two lexicon mod- els. More pertinent to our work is (Hai at al., 1997), who introduced a phrase transfer model for Vietnamese-English machine translation focusing on one-to-zero mapping, which means that a word in Vietnamese may not have appropriate single-word translation(s) and may need to be translated into a phrase in English. They translate Vietnamese words to English using a bilingual dictionary, then use con- version rules to modify the structures of the En- glish translation candidates. The modifying process builds phrases level-by-level from simple to com- plex, restructures phrases using a syntactic parser and additional rules, and applies measures to solve phrase conflict. </chunk></section><section><heading>4 Proposed approach </heading><chunk>This section introduces a new simple and effective approach to translate from Vietnamese to English using a bilingual dictionary and n-gram data. An entry in n-gram data is a 2-tuple &lt; w E , f rq &gt;, where w E is a sequence of n words in English and f rq is the frequency of w E . An entry in a bilin- gual dictionary is also a 2-tuple &lt; w s , w t &gt;, where w s and w t are a word or a phrase in the source lan- guage and its translation in the target language, re- spectively. If the word w s has many translations in the target language, there are several entries such as &lt; w s , w t1 &gt;, &lt; w s , w t2 &gt; and &lt; w s , w t3 &gt;. We note that an existing bilingual dictionary may con- tain phrases and their translations. Our work finds translations for phrases which do not exist in the dic- tionary. The general idea of our approach is that we translate each word in the given phrase to English using a Vietnamese-English dictionary, then use n- gram data to restructure translations. Our work is divided into 4 steps: segmenting Vietnamese words, filtering segmentations, generating ad hoc transla- tions, selecting the best ad hoc translation, and find- ing and ranking English translation candidates. </chunk></section><section><heading>4.1 Segmenting Vietnamese words </heading><chunk>A Vietnamese phrase P, consisting of a sequence of n syllables &lt; s 1 s 2 ... s n &gt;, can be segmented in different ways, each of which will produce a seg- mentation S. A segmentation S is defined as an or- dered sequence of words w i separated by semicolons ; such as S =&lt; w 1 ; w 2 ; w 3 ; ...; w i ; ...; w m &gt;, where m is the number of words in S, m n and 1 i m. We note that a word may contain one or more syllables s. Generally, we have 2 n1 pos- sible segmentations for a Vietnamese phrase P. For example, the phrase khoa khoa hhc - science de- partment/faculty, has 4 possible segmentations: S 1 = &lt;khoa; khoa; hhc&gt;, S 2 = &lt;khoa; khoa hhc&gt;, S 3 = &lt;khoa khoa; hhc&gt;, and S 4 = &lt;khoa khoa hhc&gt;. </chunk></section><section><heading>4.2 Filtering segmentations </heading><chunk>Each word in each segment may have k 0 transla- tions in English. The total number of English trans- lation candidates for a Vietnamese phrase, with m words, is O(2 n1 m k ). To reduce the number of candidates, we check whether or not every Viet- namese word in each segmentation has an English translation in a Vietnamese-English dictionary. If at least one word does not have a translation in the dictionary, we delete that segmentation. For exam- ple, we delete S 3 and S 4 because they contain the words khoa khoa and khoa khoa hhc which do not have translations in the dictionary. As a result, the phrase khoa khoa hhc has 2 remaining seg- 66 mentations: S 1 =&lt;khoa; khoa; hhc&gt; and S 2 =&lt;khoa; khoa hhc&gt;. </chunk></section><section><heading>4.3 Generating ad hoc translations </heading><chunk>To generate an ad hoc translation T, we translate each word in a segmentation S to English using the Vietnamese-English dictionary. The ad hoc transla- tions of a given phrase are the translations of seg- mentations. For instance, the translations of the segmentation S 1 for khoa khoa hhc are &lt;faculty; faculty; study&gt;, &lt;department; department; study&gt;, &lt;subject of study; subject of study; study&gt;; and the translations for S 2 are &lt;faculty; science&gt;, &lt;depart- ment; science&gt;, &lt;subject of study; science&gt;. There- fore, the six ad hoc translations of khoa khoa hhc are T 1 =faculty faculty study, T 2 =department de- partment study, T 3 =subject of study subject of study study, T 4 =faculty science, T 5 =department science, and T 6 = subject of study science. </chunk></section><section><heading>4.4 Selecting the best ad hoc translation </heading><chunk>We have generated several ad hoc translations by simply translating each word in the segmentations to English. Most are not grammatically correct. We use a method, presented in Algorithm 1, to reduce the number of ad hoc translations. We consider words in each entry in the English n-gram data as a bag of words N B (lines 1-3), i.e., the words in each entry is simply considered a set of words instead of a sequence. For example, the 3-gram computer sci- ence department is considered as the set {computer, science, department}. Each ad hoc translation T , created in Section 4.3, is also considered a bag of words T B (lines 4-6). For every bag of words T B, we find each bag of words N B , belonging to the set of all N Bs, such that N B contains all words in T B (lines 7-9), i.e., T B N B . Each bag of words T B is given a score score T B which is the sum of frequency of all bags of words N B (line 10). The bag of words T B with the greatest score is consid- ered the best ad hoc translation (lines 12-18). After this step, only one ad hoc translation T will remain. For example, we eliminate 5 ad hoc transla- tions (viz., T 1 , T 2 , T 3 , T 4 and T 6 ) of the Vietnamese phrase khoa khoa hhc, and select department sci- ence (T 5 ) as the best ad hoc translation of it. We note that the best ad hoc translation may still be grammatically incorrect in English. Algorithm 1 Selecting the best ad hoc translation Input: all ad hoc translations T s Output: the best ad hoc translation bestAdhocT ran 1: for all entries N n-gram data do 2: generate bags of words N B 3: end for 4: for all ad hoc translations T do 5: generate bags of words T B 6: end for 7: for all T B do 8: score T B = 0 9: Find all N B set of all N Bs that contain all words in T B 10: score T B = F requency(N B ) 11: end for 12: bestAdhocT ran=T B 0 13: for all T B do 14: if score T B &gt; score bestAdhocT ran then 15: bestAdhocT ran=T B 16: end if 17: end for 18: return bestAdhocT ran </chunk></section><section><heading>4.5 Finding and ranking translation candidates </heading><chunk>To restructure translations, we use n-gram data in- stead of grammar rules. We take advantage that the n-gram information implicitly encodes the gram- mar of a language. Having the best ad hoc transla- tion T B and several corresponding bags N B from the previous step, we find and rank the translation candidates. For every N B , we retrace its corre- sponding entry in the n-gram data, and mark the words in the entry as a translation candidate cand. Then, we rank the selected translation candidates. If there exists one or many cands such that the sizes of each cand and T B are equal, these cands are more likely to be correct translations than other candidates. We simply rank cands based on their n-gram frequencies. The candi- date cand with the greatest frequency is consid- ered the best translation. For example, the best ad hoc translation of khoa khoa hhc is de- partment science. In the n-gram data, we find an entry &lt;science department, 112&gt; which contains exactly the same words in the best ad hoc translation found. We accept science de- partment as a correct translation of khoa khoa 67 hhc and its rank is 112, which is the n-gram frequency of science department. The rest of the candidates are ranked using the following formula: rank(cand) = F requency(cand) |size(cand)size(T B)|100 . Our motivation for the rank formula is the fol- lowing. If a candidate has a greater frequency, it has a greater likelihood to be a correct trans- lation. However, if the size of the candidate and the size of T B are very different, that can- didate may be inappropriate. Hence, we divide the frequency of cand by the difference in the number of words between cand and T B. To normalize, we divide results by 100. </chunk></section><section><heading>5 Experiments </heading><chunk>We work with the Vietnamese-English dictionary obtained from EVbcorpus 1 . The dictionary contains about 130,000 entries. We also use the free lists of English n-gram data available at the ngrams.info 2 Website. The free lists have the one million most frequent entries for each of 2, 3, 4 and 5-grams. The n-gram data has been obtained from the corpus of contemporary American English 3 . Currently, we limit our experiments to translation candidates with equal or smaller than 5 syllables. We obtain 200 common Vietnamese phrases, which do not exist in the dictionary, from 4 volunteers who are fluent in both Vietnamese and English. Later, these volunteers are asked to evaluate our transla- tions using a 5-point scale, 5: excellent, 4: good, 3: average, 2: fair, and 1: bad. The average score of translations created using the baseline approach, which is simply translating words in segments to English, is 2.20/5.00. The av- erage score of translations created using our pro- posed approach is 4.29/5.00, which is quite high. The rating reliability is 0.72 obtained by calculating the Intraclass Correlation Coefficient (Koch, 1982). Our approach returns translations for 101 phrases out of the 200 input phrases. This means the pre- cision and recall of our translations are 85.8% and 50.5%, respectively. 1 https://code.google.com/p/evbcorpus/ 2 http://www.ngrams.info/ 3 http://corpus.byu.edu/coca/ We also compute the matching percentage be- tween our translations and translations performed by the Google Translator. The matching percentage of our translations for phrases is 42%. The translations marked as unmatched do not mean our transla- tions are incorrect. A few such examples are pre- sented in Table 1. Table 1: Some translations we create are correct but do not match with translations from the Google Translator. The average score of our translations is high; however, the recall is low. If our algorithms can re- turn a translation for an input phrase, that translation is usually specific, and is evaluated as excellent or good in most cases. Our approach relies on an exist- ing bilingual dictionary and n-gram data in English. If we have a dictionary covering the most common words in Vietnamese, and the n-gram data in English is extensive with different lengths, we believe that our approach will produce even better translations. </chunk></section><section><heading>6 Conclusion and future work </heading><chunk>We have introduced a new method to translate a given phrase in Vietnamese to English using a bilin- gual dictionary and English n-gram data. Our ap- proach can be applied to other language pairs that have a bilingual dictionary and n-gram data in one of the two languages. We plan to compute Vietnamese n-gram data from a Wikipedia dump and try to trans- late phrases from English to Vietnamese next. 68 References O.B. Abiola, Adetunmbi A. O., Fasiku A. I., and Olatunji K. 2014. A web-based English to Yoruba noun- phrases machine transaltion system. International Journal of English and Literature. Pages 7178. Mark Aronoff, and Kirsten Fudeman. 2011. What is morphology, vol. 8. John Wiley &amp; Sons. Dhouha Bouamor, Nasredine Semmar, and Pierre Zweigenbaum. 2012. Identifying bilingual Multi- Word Expressions for Statistical Machine Translation. In Proceedings of LREC. Istanbul, Turkey, May. Pages 674679. Yunbo Cao, and Hang Li. 2002. Base noun phrase trans- lation using web data and the EM algorithm. In Pro- ceedings of the 19th international conference on Com- putational linguistics. Pages 17. Le Manh Hai, Asanee Kawtrakul, and Yuen Poovorawan. 1997. Phrasal transfer model for Vietnamese-English machine translation. In NLPRS. Gary G. Koch. 1982. Intraclass correlation coefficient. Encyclopedia of statistical sciences. Philipp Koehn, and Kevin Knight. 2003. Feature-rich statistical translation of noun phrases. In Proceedings of the 41st Annual Meeting on Association for Com- putational Linguistics. Sapporo, Japan, July. Volume 1, pages 311-318. Association for Computational Lin- guistics. Paul M. Lewis, Gary F. Simons, and Charles D. Fennig (eds.). 2014. Ethnologue: Languages of the World, 17th edition. Dallas, Texas: SIL International. Jose B. Marino, Rafael E. Banchs, Josep M. Crego, Adria de Gispert, Patrik Lambert, Jose A.R. Fonollosa, and Marta R. Costa-Jussa. 2006. N-gram-based ma- chine translation. Computational Linguistics 32, no. 4 (2006): 527549. Binh N. Ngo. 2001. The Vietnamese language learn- ing framework . Journal of Southeast Asian Language Teaching 10. Pages 124. Pavel Pecina. 2008. A machine learning approach to multiword expression extraction. In Proceedings of the LREC Workshop Towards a Shared Task for Mul- tiword Expressions. Marrakech, Morocco, June. Pages 5461. Takaaki Tanaka, and Timothy Baldwin. 2003. Trans- lation selection for Japanese-English noun-noun com- pounds. In Proceedings of Machine Translation Sum- mit IX. Marrakech, Morocco, June. Pages 378385. Laurence C. Thompson. 1963. The problem of the word in Vietnamese. Word journal of the International Lin- guistic Association, 19(1):3952. 69 </chunk></section></sec_map>