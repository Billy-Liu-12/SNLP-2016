<sec_map><section><chunk>Proceedings of the 14th Meeting on the Mathematics of Language (MoL 14), pages 1525, Chicago, USA, July 2526, 2015. c 2015 Association for Computational Linguistics Abstract Categorial Parsing as Linear Logic Programming Philippe de Groote Inria Nancy - Grand Est France Philippe.deGroote@inria.fr Abstract This paper shows how the parsing problem for general Abstract Categorial Grammars can be reduced to the provability problem for Multi- plicative Exponential Linear Logic. It follows essentially a similar reduction by Kanazawa, who has shown how the parsing problem for second-order Abstract Categorial Grammars reduces to datalog queries. </chunk></section><section><heading>1 Introduction </heading><chunk>Kanazawa (2007; 2011) has shown how parsing and generation may be reduced to datalog queries for a class of grammars that encompasses mildly context-sensitive formalisms. These grammars, which he calls context-free -term grammars, cor- respond to second-order abstract categorial gram- mars (de Groote, 2001). In this paper, we show how Kanazawas reduction may be carried out in the case of abstract categorial grammars of a degree higher than two. The price to pay is that we do not end up with a datalog query, but with a provability problem in multiplicative expo- nential linear logic (Girard, 1987). This is of course a serious difference. In particular, it is not known whether the multiplicative exponential fragment of linear logic is decidable. The paper is organized as follows. Section 2 presents some mathematical preliminaries concern- ing the linear -calculus. We then introduce, in Sec- tion 3, the notion of abstract categorial grammar. Section 4 is the core of the paper, where we ex- plain Kanazawas reduction. To this end, we proceed by stepwise refinement. We first introduce an obvi- ously correct but inefficient parsing algorithm. We then improve it by successive correctness-preserving transformations. Finally, we conclude in Section 5. 2 Linear -calculus We assume from the reader some acquaintance with the basic concepts of the (simply typed) -calculus. Nevertheless, in order to fix the terminology and the notations, we briefly reminds the main definitions and properties that will be needed in the sequel. In particular, we review the notions linear implicative types, higher-order linear signature, and linear - terms built upon a higher-order linear signature. Let A be a set of atomic types. The set T (A) of linear implicative types built upon A is inductively defined as follows: 1. if a A, then a T (A); 2. if , T (A), then ( ) T (A). Given two sets of atomic types, A and B, a map- ping h : T (A) T (B) is called a type homo- morphism (or a type substitution) if it satisfies the following condition: h( ) = h() h() A type substitution that maps atomic types to atomic types is called a relabeling. In order to save parentheses, we use the usual convention of right association, i.e., we write 1 2 n for ( 1 ( 2 ( n ) )). A higher-order linear signature consists of a triple = A, C, , where: 15 1. A is a finite set of atomic types; 2. C is a finite set of constants; 3. : C T (A) is a function that assigns to each constant in C a linear implicative type in T (A). Given, a higher-order linear signature , we write A , C , and , for its respective components. The above notion of linear implicative type is iso- morphic to the usual notion of simple type. Conse- quently, there is no technical difference between a higher-order linear signature and a higher-order sig- nature. The only reason for using the word linear is to emphasize that we will be concerned with the typing of the linear -terms, i.e., the -terms whose typing system corresponds to the implicative frag- ment of multiplicative linear logic (Girard, 1987). Let X be a infinite countable set of -variables. The set () of linear -terms built upon a higher- order linear signature is inductively defined as fol- lows: 1. if c C , then c (); 2. if x X, then x (); 3. if x X, t (), and x occurs free in t exactly once, then (x. t) (); 4. if t, u (), and the sets of free variables of t and u are disjoint, then (t u) (). () is provided with the usual notions of capture- avoiding substitution, -conversion, -reduction, and -reduction (Barendregt, 1984). Let t and u be linear -terms. We write t u and t = u for the relations of -reduction and -conversion, respec- tively, We use similar notations for the relations of reduction and conversion induced by and . Let 1 and 2 be two signatures. We say that a mapping h : ( 1 ) ( 2 ) is a -term homo- morphism if it satisfies the following conditions: h(x) = x h(x. t) = x. h(t) h(t u) = h(t) (h(u)) Given a higher-order linear signature , each lin- ear -term in () may possibly be assigned a lin- ear implicative type in T (A ). This type assign- ment obeys the following typing rules: c : (c) (CONS) x : x : (VAR) , x : t : (x. t) : ( ) (ABS) t : ( ) u : , (t u) : (APP) where dom( ) dom() = . We end this section by reviewing some properties that will turn out to be useful in the sequel. The set of linear -terms being a subset of the set of simply typed -terms, it inherits the universal properties of the latter (e.g., strong normalization, or existence of a principal type scheme). It also satis- fies the usual subject-reduction property. Proposition 1 Let , t, u, , and be such that t : and t u. Then u : . The set of simply typed -terms, which is not closed in general under -expansion, is known to be closed under linear -expansion. Consequently, the set of linear -terms satisfies the subject-expansion property. Proposition 2 Let , t, u, , and be such that u : and t u. Then t : . The subject-reduction property also holds for the relation of -reduction. This is not the case, how- ever, for the subject-expansion property. This pos- sible difficulty may be circumvented by using the notion of -long form. A linear -term is said to be in -long form when every of its sub-terms of functional type is either a -abstraction or the operator of an application. The set of linear -terms in -long forms is closed under both -reduction and -expansion. Consequently, the following proposition holds. Proposition 3 Let t and u be -terms in -long forms. Then, t = u if and only if t = u. In the sequel, we will often assume that the linear - terms under consideration are in -long forms. This 16 will allow us to only consider -reduction and - expansion, while using the relation of -conversion as the notion of equality between linear -terms. Finally, it is known from a categorical coherence theorem that every balanced simple type is inhab- ited by at most one -term up to -conversion (see (Babaev and Solovev, 1982; Mints, 1981)). It is also known that the principal type of a pure linear - term is balanced (Hirokawa, 1991). Consequently, the following property holds. Proposition 4 Let t be a pure linear -term (i.e., a linear -term that does not contain any constant), and let t : be its principal typing. If u is a pure linear -term such that u : , then t = u. 3 Abstract Categorial Grammar This section gives the definition of an abstract cate- gorial grammar (ACG, for short) (de Groote, 2001). We first define a lexicon to be a morphism be- tween higher-order linear signatures. Let 1 = A 1 , C 1 , 1 and 2 = A 2 , C 2 , 2 be two higher- order signatures. A lexicon L : 1 2 is a realization of 1 into 2 , i.e., an interpretation of the atomic types of 1 as types built upon A 2 , to- gether with an interpretation of the constants of 1 as linear -terms built upon 2 . These two inter- pretations must be such that their homomorphic ex- tensions commute with the typing relations. More formally, a lexicon L from 1 to 2 is defined to be a pair L = F, G such that: 1. F : A 1 T (A 2 ) is a function that inter- prets the atomic types of 1 as linear implica- tive types built upon A 2 ; 2. G : C 1 ( 2 ) is a function that interprets the constants of 1 as linear -terms built upon 2 ; 3. the interpretation functions are compatible with the typing relation, i.e., for any c C 1 , the following typing judgement is derivable: </chunk></section><section><heading>2 G(c) : F ( 1 (c)) (1) </heading><chunk>where F is the unique homomorphic extension of F . Remark that Condition (1) compels G(c) to be typable with respect to the empty typing environ- ment. This means that G interprets each constant c as a closed linear -term. Now, defining G to be the unique homomorphic extension of G, Condition (1) ensures that the following commutation property holds for every t ( 1 ): if 1 t : then 2 G(t) : F () In the sequel, given such a lexicon L = F, G, L (a) will stand for either F (a) or G(a), according to the context. We now define an abstract categorial grammar as quadruple, G = 1 , 2 , L , S, where: 1. 1 and 2 are two higher-order linear signa- tures; they are called the abstract vocabulary and the object vocabulary, respectively; 2. L : 1 2 is a lexicon from the abstract vocabulary to the object vocabulary; 3. S is an atomic type of the abstract vocabulary; it is called the distinguished type of the gram- mar. Every ACG G generates two languages: an ab- stract language, A(G ), and an object language O(G ). The abstract language, which may be seen as a set of abstract parse structures, is the set of closed linear -terms built upon the abstract vocabulary and whose type is the distinguished type of the grammar. It is formally defined as follows: A(G ) = {t ( 1 ) : 1 t : S is derivable} The object language, which may be seen as the set of surface forms generated by the grammar, is defined to be the image of the abstract language by the term homomorphism induced by the lexicon. O(G ) = {t ( 2 ) : u A(G ). t = L (u)} Both the abstract language and the object lan- guage generated by an ACG are sets of linear - terms. This allows more specific data structures such as strings, trees, or first-order terms to be repre- sented. A string of symbols, for instance, can be encoded as a composition of functions. Consider an 17 MAN : N WOMAN : N WISE : N N A s : N (NP s S) S A o : N (NP o S) S SEEK : ((NP o S) S) NP s S INJ : S S Figure 1: The abstract vocabulary 1 MAN := man : WOMAN := woman : WISE := x. wise + x : A s := xp. p (a + x) : ( ) A o := xp. p (a + x) : ( ) SEEK := px. p (y. x + seeks + y) : (( ) ) INJ := x. x : Figure 2: The lexicon L : 1 2 arbitrary atomic type s, and define = s s to be the type of strings. Then, a string such as abbac may be represented by the linear -term: x. a (b (b (a (c x)))), where the atomic strings a, b, and c are declared to be constants of type . In this setting, the empty word is represented by the identity function: = x. x and concatenation is defined to be functional com- position: + = . . x. ( x), which is indeed an associative operator that admits the identity function as a unit. We end this section by giving a fragment of a cate- gorial grammar that will serve as a running example throughout the rest of this paper. 1 The abstract vocabulary, which specifies the ab- stract parse structures, is given in Fig. 1. In this signature, the atomic types (N , NP s , NP o , S, S) must be thought of as atomic syntactic cate- gories. The lexicon, which is given in Fig. 2, al- lows the abstract structures to be transformed in sur- face forms. These surface forms are strings that are built upon an object vocabulary, 2 , which includes the following atomic strings as constants of type : man, woman, wise, a, seeks. For such a grammar, the parsing problem consists in deciding whether a possible surface form (i.e., 1 This grammar, which follows the categorial type-logical tradition (Moortgat, 1997), has been devised in order to present the main difficulties encountered in ACG parsing: it is higher order (it assigns third-order types to the quantified noun phrases, and a fourth-order type to an intensional transitive verb such as seek); it is lexically ambiguous (it assigns two different lexi- cal entries to the indefinite determiner); and it includes a non- lexicalized entry (the coercion operator INJ). 18 term t ( 2 )) belongs to the object vocabulary of the grammar. Spelling it out, is there an abstract parse structure (i.e., a term u ( 1 ) of type S) whose image through the lexicon is the given sur- face form (i.e., L (u) = t). Consider, for instance, the following string: a + wise + woman + seeks + a + wise + man (2) One can show that it belongs to the object language of the grammar. Indeed, when applying the lexicon to the following abstract term: A s (WISE WOMAN) (x. INJ (SEEK (p. A o (WISE MAN) (y. INJ (p y))) x)) (3) one obtains a -term that is -convertible to (2). In fact, it is even the case that (2) is ambiguous in the sense that there is another abstract term, essentially different from (3), whose image through the lexicon yields (2). 2 This abstract term is the following: A s (WISE WOMAN) (x. A o (WISE MAN) (y. INJ (SEEK (p. INJ (p y)) x))) (4) 4 Development of the parsing algorithm In this section, we develop a parsing algorithm based on proof-search in the implicative fragment of linear logic. We start with a simple non-deterministic algo- rithm, which is rather inefficient but whose correct- ness and semi-completeness are obvious. Then, we proceed by stepwise refinement, preserving the cor- rectness and semi-completeness of the algorithm. By correctness, we mean that if the parsing algo- rithm answers positively then it is indeed the case that the input term belongs to the object language of the grammar. By semi-completeness, we mean that if the input term belongs to the object language of the grammar, then the parsing algorithm will even- tually give a positive answer. In the present state of knowledge, semi- completeness is the best we may expect. Indeed, 2 If the grammar was provided with a Montague semantics, the abstract parse structures (3) and (4) would correspond to the de dicto and de re readings, respectively. the ACG membership problem is known to be equivalent to provability in multiplicative exponen- tial logic (de Groote et al., 2004; Yoshinaka and Kanazawa, 2005), the decidability of which is still open. </chunk></section><section><heading>4.1 Generate and test </heading><chunk>Our starting point is a simple generate and test algo- rithm: 1. derive S using the rules of implicative linear logic with the types of the abstract constants (Fig. 3) as proper axioms; 2. interpret the obtained derivation as a linear -term (through the Curry-Howard isomor- phism); 3. apply the lexicon to the resulting -term, and check whether it yields a term -convertible to the input term. N (MAN) N (WOMAN) N N N (NP s S) S N (NP o S) S ((NP o S) S) NP s S S S Figure 3: The type of the abstract constants as proper axioms The above algorithm is obviously correct. It is also semi-complete because it enumerates all the terms of the abstract language. Now, if the input term belongs to the object language of the grammar then its abstract parse structure(s) will eventually ap- pear in the enumeration. </chunk></section><section><heading>4.2 Type-driven search </heading><chunk>The generate and test algorithm proceeds by trial and error without taking into account the form of the input term. In order to improve our algorithm, we must focus on the construction of an abstract term 19 whose image by the lexicon would be the input term. To this end, we take advantage of Proposition 4. In general, the input term is not a pure -term. Consequently, in order to apply Proposition 4, we must consider each occurrence of a constant in the input term as a fresh free variable. Applying this idea to our example, we obtain the following prin- cipal typing that characterizes uniquely the input string (in -long -normal form): a 1 : s 1 s 0 , wise 1 : s 2 s 1 , woman : s 3 s 2 , seeks : s 4 s 3 , a 2 : s 5 s 4 , wise 2 : s 6 s 5 , man : s 7 s 6 z. a 1 (wise 1 (woman (seeks (a 2 (wise 2 (man z))))))) : s 7 s 0 The types assigned to the constant occurrences of the input term induce a new specialized object vo- cabulary, which we will call S 2 . We take for granted the definition of the forgetful homomor- phism | | : S 2 2 that allows to project S 2 on 2 . Roughly speak- ing, this forgetful homomorphism consists simply in identifying the several occurences of a same object constant. Remark that at the level of the types, this forgetful homomorphism is a relabeling because the input string has been given in -long form. In our case, this relabeling is the following one: |s i | = s (0 i 7) The next step is to adapt the abstract vocabulary and the lexicon to this specialized object vocabulary. We start with the abstract atomic types. Let a A 1 , and define the set (a) as follows: (a) = { T (A S 2 ) : || = L( 1 (a))} For instance, we have: (N ) = {s i s j : 0 i 7 &amp; 0 j 7} Then we define the set of atomic types of the spe- cialized abstract signature as follows: A S 1 = {a : a A 1 &amp; (a)} and we let L S (a ) = Back to our example, it means that the specialised abstract signature contains 64 copies of N : N s 0 s 0 , N s 0 s 1 , . . . N s 0 s 7 , . . . . . . . . . . . . N s 7 s 0 , N s 7 s 1 , . . . N s 7 s 7 . In order to accommodate the abstract constants, we look at the lexicon. Consider the first two lexical entries. Their typing, according to the specialized object vocabulary, is as follows: MAN := z. man z : s 7 s </chunk></section><section><heading>6 WOMAN := z. woman z : s </heading><chunk>3 s 2 Accordingly, we let the specialized abstract vocabu- lary contain the following two constants: MAN : N s 7 s 6 WOMAN : N s 3 s 2 Consider now the third entry: WISE := xz. wise (x z) : (s s) s s There are two ways of specializing it. On the one hand, the object constant wise may be replaced by its first occurrence (wise 1 ) or by its second one (wise 2 ). On the other hand, each occurrence of the atomic type s may be instantiated by one of s 0 , s 1 , ..., s 7 . This give rise to 8,192 a priori possibilities. These possibilities, however, do not all correspond to ac- tual typing judgements. Filtering out the ill-typed ones (which is effective since typing is decidable), we are left with 16 new lexical entries which obey the following schemes: WISE 1i := xz. wise 1 (x z) : (s i s 2 ) s i s 1 (0 i 7) WISE 2i := xz. wise 2 (x z) : (s i s 6 ) s i s 5 (0 i 7) and we add the following 16 constants to the spe- cialized abstract vocabulary: WISE 1i : N s i s 2 N s i s 1 (0 i 7) WISE 2i : N s i s 6 N s i s 5 (0 i 7) By proceeding in the same way with the other lex- ical entries, we obtain a new specialized abstract sig- nature S 1 together with a new specialized lexicon: L S : S 1 S 2 Clearly, there exists a forgetful homomorphism be- tween S 1 and 1 , and the specialized abstract sig- nature and specialized lexicon are such that the fol- lowing diagram commutes: 20 2 S 2 || 1 L / / S 1 L S / / || We may now use the specialized grammar to drive the proof-search on which the generate and test algo- rithm is based. Remember that the specialized object type assigned to the input string is s 7 s 0 . Our pars- ing problem is then reduced to the following proof- search problem: derive S s 7 s 0 using the rules of implicative linear logic with the types of the specialized ab- stract constants as proper axioms. Now, suppose that we derive S s 7 s 0 , and that t ( S 1 ) is the specialized abstract linear -term corresponding to this derivation. By construction of the specialized grammar, we have that: S 2 L s (t) : s 7 s 0 (5) Then, by Proposition 4, we have that L s (t) = z. a 1 (wise 1 (woman (seeks (a 2 (wise 2 (man z)))))) (6) because S 2 z. a 1 (wise 1 (woman (seeks (a 2 (wise 2 (man z)))))) : s 7 s 0 (7) amounts to a principal typing. Finally, by taking t = |t|, we obtain a term t ( 1 ) such that: L (t ) = z. a (wise (woman (seeks (a (wise (man z)))))) (8) This shows the correctness of the algorithm. To establish its semi-completeness, suppose that there exists an abstract linear -term t ( 1 ) such that (8). From this, one can easily construct a term t ( S 1 ) of type S such that |t| = t and Equation (6) holds. Since the lexical entries are given in -long forms, so is L s (t). Then, because the specialized input term is in -long -normal form, by Proposition 3, we have that: L s (t) z. a 1 (wise 1 (woman (seeks (a 2 (wise 2 (man z)))))) (9) Then, (5) follows from (7) and (9) by Proposition 2. From this, it is not too difficult to establish that t is of type S s 7 s 0 . </chunk></section><section><heading>4.3 Proof-search in the implicative fragment of linear logic </heading><chunk>The type-driven algorithm that we have sketched presents two serious defects. On the one hand, the construction of the specialized grammar is both time and space consuming. For our simple running exam- ple, for instance, we would obtain 6,226 specialized lexical entries. On the other hand, the reduction de- pends upon the input string. In order to circumvent these difficulties, consider again the specialized lexical entries corresponding to the third lexical entry of the original grammar: WISE 10 := xz. wise 1 (x z) : (s 0 s 2 ) s 0 s 1 WISE 11 := xz. wise 1 (x z) : (s 1 s 2 ) s 1 s 1 . . . WISE 17 := xz. wise 1 (x z) : (s 7 s 2 ) s 7 s 1 WISE 20 := xz. wise 2 (x z) : (s 0 s 6 ) s 0 s 5 WISE 21 := xz. wise 2 (x z) : (s 1 s 6 ) s 1 s 5 . . . WISE 27 := xz. wise 2 (x z) : (s 7 s 6 ) s 7 s 5 In fact, all the specialized object types assigned to these lexical entries are instances of the principal typing of the corresponding lexical entry of the orig- inal lexicon: wise : j i xz. wise (x z) : (k j) k i This means that if the specialized object vocabulary assigns the constant wise with the following type: wise : j i (10) then the specialized abstract vocabulary should con- tain abstract constants obeying the following type scheme: N kj N ki (11) 21 man[i, j] N [i, j] woman[i, j] N [i, j] wise[i, j] N [j, k] N [i, k] a[i, j] N [j, k] (NP s [i, k] S[l, m]) S[l, m] a[i, j] N [j, k] (NP o [i, k] S[l, m]) S[l, m] seeks[i, j] ((NP o [j, k] S[l, k]) S[m, n]) NP s [l, i] S[m, n] S[i, j] S[i, j] Figure 4: The lexicon as a linear logic program man[i, j] N [i, j] (M) woman[i, j] N [i, j] (W) wise[i, j] N [j, k] , N [i, k] (WI) a[i, j] N [j, k] , NP s [i, k] S[l, m] , , S[l, m] (As) a[i, j] N [j, k] , NP o [i, k] S[l, m] , , S[l, m] (Ao) seeks[i, j] , NP o [j, k] S[l, k] S[m, n] NP s [l, i] , , S[m, n] (S) S[i, j] S[i, j] (I) Figure 5: The lexicon as a set of inference rules Writing N [j, k] for N kj and representing (10) by the predicate wise[i, j], we may represent the depen- dence between 10 and 11 by the following linear logic sequent: 3 wise[i, j] N [j, k] N [i, k] Applying the same process to the other lexical en- tries, we end up with the set of sequents given in Fig. 4. Our parsing problem amounts then to a proof- search problem in linear logic: 3 Following (Kanazawa, 2011) and (Kanazawa, 2007), when writing N [j, k] for N kj , we write the variables in the reverse order. derive a[0, 1], wise[1, 2], woman[2, 3], seeks[3, 4], a[4, 5], wise[5, 6], man[6, 7] S[0, 7] using the rules of implicative linear logic with the set of sequents of Fig. 4 as proper axioms. We give in Fig. 6 and Fig. 7 (in the annex) the derivations corresponding to the de dicto parsing (3) and to the de re parsing (4). These two derivations use the inference rules given in Fig. 5, which are equivalent to the sequents of Fig. 4. Acknowledgments I am grateful to Makoto Kanazawa for fruitful discussions about his work on parsing as datalog 22 queries. A preliminary version of the results re- ported in this paper has been presented in a talk given in June 2007 at the Colloquium in Honor of G  erard Huet on the occasion of his 60th birth- day. This work has been supported by the French agency Agence Nationale de la Recherche (ANR- 12-CORD-0004). </chunk></section><section><heading>References </heading><chunk>A.A. Babaev and S.V. Solovev. 1982. A coherence the- orem for canonical morphisms in cartesian closed cat- egories. Journal of Soviet Mathematics, 20(4):2263 2279. Original in Russian: Zapiski Nauchnykh Semi- narov Leningradskogo Otdeleniya Matematicheskogo Instituta imeni V. A. Steklova Akademii Nauk SSSR (LOMI), 88:329, 1979. H.P. Barendregt. 1984. The lambda calculus, its syntax and semantics. North-Holland, revised edition. Ph. de Groote, B. Guillaume, and S. Salvati. 2004. Vec- tor addition tree automata. In Proceedings of the 19th annual IEEE symposium on logic in computer science, pages 6473. Ph. de Groote. 2001. Towards abstract categorial gram- mars. In Association for Computational Linguistics, 39th Annual Meeting and 10th Conference of the Eu- ropean Chapter, Proceedings of the Conference, pages 148155. J.-Y. Girard. 1987. Linear logic. Theoretical Computer Science, 50:1102. J.R. Hindley. 1969. The principal type-scheme of an object in combinatory logic. Transaction of the Amer- ican Mathematical Society, 146:2960. S. Hirokawa. 1991. Principal type-schemes of bci- lambda-terms. In T. Ito and A.R. Meyer, editors, The- oretical Aspects of Computer Software, TACS91, vol- ume 526 of Lecture Notes in Computer Science, pages 633650. Springer-Verlag. M. Kanazawa. 2007. Parsing and generation as datalog queries. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, pages 176183. Association for Computational Linguistics. M. Kanazawa. 2011. Parsing and generation as datalog query evaluation. Last revised August 26, 2011. 74 pages. (Under review). G.E. Mints. 1981. Closed categories and the theory of proofs. Journal of Soviet Mathematics, 15(1):45 62. Original in Russian: Zapiski Nauchnykh Semi- narov Leningradskogo Otdeleniya Matematicheskogo Instituta imeni V. A. Steklova Akademii Nauk SSSR (LOMI), 68:83114, 1977. M. Moortgat. 1997. Categorial type logics. In J. van Benthem and A. ter Meulen, editors, Handbook of Logic and Language, chapter 2. Elsevier. R. Yoshinaka and M. Kanazawa. 2005. The complexity and generative capacity of lexicalized abstract catego- rial grammars. In Philippe Blache, E. Stabler, J. Bus- quets, and R. Moot, editors, Logical Aspects of Com- putational Linguistics, LACL 2005, volume 3492 of Lecture Notes in Computer Science, pages 330346. Springer-Verlag. 23 wise[5, 6] wise[5, 6] man[6, 7] man[6, 7] man[6, 7] N [6, 7] (M) wise[5, 6], man[6, 7] N [5, 7] (WI) (1) NPo[4, 7] S[0, 7] NPo[4, 7] S[0, 7] NPo[4, 7] NPo[4, 7] NPo[4, 7] S[0, 7], NPo[4, 7] S[0, 7] (APP) NPo[4, 7] S[0, 7], NPo[4, 7] S[0, 7] (I) (2) seeks[3, 4] seeks[3, 4] a[4, 5] a[4, 5] . . . . (1) wise[5, 6], man[6, 7] N [5, 7] . . . . (2) NPo[4, 7] S[0, 7], NPo[4, 7] S[0, 7] a[4, 5], wise[5, 6], man[6, 7], NPo[4, 7] S[0, 7] S[0, 7] (Ao) NPs[0, 3] NPs[0, 3] seeks[3, 4], a[4, 5], wise[5, 6], man[6, 7], NPs[0, 3] S[0, 7] (S) (3) a[0, 1] a[0, 1] wise[1, 2] wise[1, 2] woman[2, 3] woman[2, 3] woman[2, 3] N [2, 3] (W) wise[1, 2], woman[2, 3] N [1, 3] (WI) . . . . (3) seeks[3, 4], a[4, 5], wise[5, 6], man[6, 7], NPs[0, 3] S[0, 7] seeks[3, 4], a[4, 5], wise[5, 6], man[6, 7], NPs[0, 3] S[0, 7] (I) a[0, 1], wise[1, 2], woman[2, 3], seeks[3, 4], a[4, 5], wise[5, 6], man[6, 7] S[0, 7] (As) Figure 6: The derivation corresponding to A s (WISE WOMAN) (x. INJ (SEEK (p. A o (WISE MAN) (y. INJ (p y))) x)) 24 seeks[3, 4] seeks[3, 4] NPo[4, 7] S[0, 7] NPo[4, 7] S[0, 7] NPo[4, 7] NPo[4, 7] NPo[4, 7], NPo[4, 7] S[0, 7] S[0, 7] (APP) NPo[4, 7], NPo[4, 7] S[0, 7] S[0, 7] (I) NPs[0, 3] NPs[0, 3] seeks[3, 4], NPs[0, 3], NPo[4, 7] S[0, 7] (S) (1) a[4, 5] a[4, 5] wise[5, 6] wise[5, 6] man[6, 7] man[6, 7] man[6, 7] N [6, 7] (M) wise[5, 6], man[6, 7] N [5, 7] (WI) . . . . (1) seeks[3, 4], NPs[0, 3], NPo[4, 7] S[0, 7] seeks[3, 4], NPs[0, 3], NPo[4, 7] S[0, 7] (I) seeks[3, 4], a[4, 5], wise[5, 6], man[6, 7], NPs[0, 3] S[0, 7] (Ao) (2) a[0, 1] a[0, 1] wise[1, 2] wise[1, 2] woman[2, 3] woman[2, 3] woman[2, 3] N [2, 3] (W) wise[1, 2], woman[2, 3] N [1, 3] (WI) . . . . (2) seeks[3, 4], a[4, 5], wise[5, 6], man[6, 7], NPs[0, 3] S[0, 7] a[0, 1], wise[1, 2], woman[2, 3], seeks[3, 4], a[4, 5], wise[5, 6], man[6, 7] S[0, 7] (As) Figure 7: The derivation corresponding to A s (WISE WOMAN) (x. A o (WISE MAN) (y. INJ (SEEK (p. INJ (p y)) x))) 25 </chunk></section></sec_map>