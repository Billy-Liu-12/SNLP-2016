<sec_map><section><chunk>Proceedings of the 3rd Workshop on EVENTS at the NAACL-HLT 2015, pages 4352, Denver, Colorado, June 4, 2015. c 2015 Association for Computational Linguistics Detecting Causally Embedded Structures Using an Evolutionary Algorithm Chen Li Department of Linguistics University of Illinois at U-C 707 S Mathews Avenue, Urbana, IL 61801 chenli@illinois.edu C. Roxana Girju Department of Linguistics University of Illinois at U-C 707 S Mathews Avenue, Urbana, IL 61801 girju@illinois.edu Abstract Causality is an important relation among events and entities. Embedded causal struc- tures represent an important class, express- ing complex causal chains; but they are tra- ditionally difficult to uncover automatically. In this paper we propose a method for the effi- cient identification and extraction of embed- ded causal relations with minimal supervision, by combining a representation of structured language data with modified prototype theory specifically suited to the data type. We then utilize a form of genetic algorithm specifically adapted for our purpose to locate the likely can- didate linguistic structures that contain causal chains. With this procedure, we were able to identify many embedded structures with com- plex causal chains in two corpora of different genres, applying this algorithm as a ranking procedure for all structures in the data. We obtained 79.5% percision for top quantiles of both of our datasets (BNC &amp; novels). </chunk></section><section><heading>1 Embedded Causality </heading><chunk>Long chains of causal relations are frequently de- noted by a complex embedding of multiple clauses through lexico-syntactic structures, structures which are causally linked. Following previous approaches (Menzies 2009, Beamer &amp; Girju 2009), we define a causal relation as e 1 cause e 2 , where e 1 precedes e 2 temporally and, had e 1 failed to take place, e 2 would also not have taken place, or more generally, P (e 2 |e 1 ) &gt; P (e 2 |e 1 ). This is a general and agreed upon definition of causality which encompasses vari- ous classes of causal types of interest (if one chooses to go deeper into this problem). Our unit of rep- resentation (for both the cause and the effect) is a semantic frame, given by a predicate and a list of arguments in the form (ARG i , ARG j , ARG k , ....). This corresponds to a clause. Such clauses ocurring in embedded structures can form a causal chain. For example (from Little Women): 1. a smart shower at eleven had evidently quenched the enthu- siasm of the young ladies who were to arrive at twelve for nobody came and at two the exhausted family sat down in a blaze of sunshine to consume the perishable portions of the feast (prepared in anticipation of the guests) that nothing might be lost (Alcott, 1868) (a) a smart shower at eleven had evidently quenched the enthusiasm of the young ladies who were to arrive at twelve (b) cause nobody came (c) cause the exhausted family sat down in a blaze of sunshire (d) cause consume the perishable portions of the feast (e) cause nothing might be lost In this paper we focus on causal relations between clauses (marked or not by discourse markers). </chunk></section><section><heading>1.1 Distinct characteristics </heading><chunk>Each embedded causal structure has a causer entity identified by the main clause, and an effect event identified by the embedded (i.e. subordinate) clause. A class of semantically rich verbs is often present, that convey some notion of causation, coloring the causing event with additional manner of causation verbs such as inspire, suggest, prompt, bribe, incite, bully, force, compel, etc. We call this class MCC- verbs. Other verbs such as cause, bring-about, how- ever, are just simple causatives (Girju 2003). De- pending on its complexity, there may be one or more intermediate clausal structures that represent links in the causal chain, along with intermediate causal agents whose presence could have little specific se- mantic information, e.g. ...caused the circumstances to line up in such a way as to..., but informs of its properties as a causal chain. Due to the complexity of these elements and the intervening structures, there are many combinatorial possibilities, and the depths of such structures are po- tentially unbounded. So rather than finding a com- prehensive set of exemplars that cover all cases, it is better to assemble patterns that represent a diffuse prototype, finding characteristic structures common in embedded causal frames, such as: 43 i EN T IT Ycauser caused it to come about that EN T IT Ycausee [P RED emb ....] ii EN T IT Ycauser arranged the events so that it comes about that EN T IT Ycausee [P RED emb ....] iii EN T IT Ycauser had the forsight to prepare the circumstances so that it comes about that EN T IT Ycausee [P RED emb ....] For all examples above, we can see that a subtree producing the terminals would be to come about that ..... A subtree like this can be used to further identify larger embedded structures as causal, and each embedded causative construction thus identified would contain one or more such subtrees. </chunk></section><section><heading>1.2 Data </heading><chunk>We considered two different genres: 1) the British National Corpus (BNC, 2007), and 2) novels from romantic fiction and historical novelas (mostly from Project Gutenberg, 2005), such as The Great Gatzby, Pride and Prejudice, Little Women, Emma, and Lily of the Nile. The training set consists of 500 positive instances (i.e., manually identified to contain a causal chain of at least one cause - effect relationship) which were selected from the 3 rd quarter of BNC. The test- ing sets consist of the 1 st quarter of BNC, and the novels set, respectively. </chunk></section><section><heading>2 Previous work </heading><chunk>There is a variety of approaches to causal rela- tions in the literature, approaches which rely mostly on machine learning methods over high-dimensional semantic-feature spaces (Abe et. al., 2008; Berthard &amp; Martin, 2008; Riaz &amp; Girju; Do et. al., 2011; Radinsky et. al. 2012 / 2013; Oh et. al. 2013; Hashimoto et. al., 2014; etc). Other researchers have focused on pre-identified lexico-syntactic pat- terns (Khoo et. al. 2001; Girju 2003) which they use to bootstrap an Expectation-Maximization pro- cedure (Chang &amp; Choi 2006; Paul et. al. 2009) for causality and similar semantic relations. Fur- thermore, these parametric and pattern recognition works are generally fucussed on pair-wise causal rela- tions between event representations. We instead fo- cus on linguistic structures of unbounded complexity that are capable of expressing sequences of events in- volved in long causal chains. Our work explores novel representations of causality, and procedures rooted in evolutionary computing in order to deal with the structural complexity of these expressions as well as retain the flexibility of parametric approaches. </chunk></section><section><heading>3 Diffuse prototype </heading><chunk>We need to encompass available lexico-semantic (symbolic) and morphosyntactic (structural) infor- mation into a single representation that can be com- pared and transformed. And since our goal is to ex- tract causal chains from complex structures, the rep- resentation needs to generalize the information over the member frames/clauses. We mostly focus on the intervening information and structural configuration between clausal subtrees, where the substructures are found based on sub-graph isomorphism between two positive samples treated as trees. The ideal product would be a set of maximally complex sub-structures in the reflection of their causality, which would not compromise their ability to generalize over all embed- ded causal structures. In this case, a purely paramet- ric approach will not work for any tree structure of sufficient size, given the number of binary parame- ters that would need to represent the presence or ab- sence of an edge v i , v j is O(n(T ) 2 ). And thus, the number of possible configurations comes to O(2 n(T ) 2 ) without taking into account labels or other sources of complexity. For potential cognitive models of cate- gorization, prototype and exemplar s are the primary theories most frequently considered. A single pro- totype is ideal for representing a set of similar ob- jects that can be unimodally represented in feature space. A set of exemplar s has the advantage of al- lowing distributions in many modes in feature-space, each cluster being represented by a single exemplar. Thus, we propose and formulate a novel catego- rial model combining strengths of both prototype and exemplars, with a graph theoretic focus. Like proto- type, it provides few structures far more concise than sample-set, allowing a high degree of generalization. Like exemplar s, it is adaptable in a multi-modal dis- tribution over naturally defined feature space, with a wide coverage of subtypes. This we will term a dif- fuse prototype of the class, which are shared graph- theoretic substructures of at least two postitive sam- ples. Given a feature space X = [x [1] , x [2] , .... x [n] ] {0, 1} n , a substructure, as a component within a dif- fuse prototype (DP), is X s = {x [j ] } | j [1, 2, ...., n] such that Y p , Y q Y j [Y p [j ] = Y q [j ] ] , where Y = set of positive samples for that semantic class. Thus, the samples Y p , Y q agree on some substructure within the feature space. When the feature space is structured in some way, an addi- tional constraint of contiguity is necessary. X s above must follow linear contiguity for its contiguity defini- tion. This requires that i, j X [i] , X [j ] X s and where P ij := i, ..., j is some consecutive sequence N, we have that k P ij [ k X s ] ( here symoblizes sub-sequence relation). So now in this example, any substructure must be restricted by some linearly contiguous region of X. We have a more complex structure of the feature space - the no- tion of continguity, referred to as N + T (v i ) and N T (v i ), with which we determine the allowable extensions of 44 any substructure T s . The allowed substructures are: Tt = G(Xs) vp, vq V (Tt) Ppq := i, ..., k, ... j P P k , P k+1 P i v [ P k+1 ] N + T (v [ P k ] ) o (1) Where P is a specific ordering of V (T ) that con- forms to the path P . The only types of X s sought are those that form a proper subtree T t of the origi- nal T . This is a natural way to allow generalization into members of the DP, and thus some fragmented forest subgraph of T is not desirable. As an illustra- tion, the trees T and T in Figure 1 contain a pair of substructures T s and T t corresponding to red / vio- let regions. The shared subgraphs are used to find Figure 1: 2 trees containing common substructures yet some other T where variable (blue-grey) regions differ from either T or T . 4 Extraction procedure The key difficulty is the isomorphic comparison of two trees. For this, we developed a form of graph- theoretic genetic algorithm, simulating the growth of subtrees shared between two reference trees T, T . </chunk></section><section><heading>4.1 Baseline genetic algorithm </heading><chunk>Inspired by On the Origin of Species (Darwin 1859), genetic algorithms are a class of adaptive algorithms (Turing 1950; Barricelli 1962; Rechenberg 1973; Hol- land 1975; de Jong 1975), with wide array of ap- plication (Brindle 1981; Baker 1985 / 1989; Gold- berg 1989; Goldberg &amp; Deb 1993; Fogel 1998). Our algorithm has similarities to genetic programming (Cramer 1985; Schmidhuber 1987), and to aspects of the original biological model, beyond traditional GA, due to greater variability afforded by substructure growth. Two processes are responsible for growth and diversification of chromosomes, mutation and re- combination in GA. An elimination stage culls a part of the population with regard to some notion of fit- ness (directed selection), its magnitude determined by carrying capacity (Goldberg et. al., 1991). </chunk></section><section><heading>4.2 Proposed modifications to GA </heading><chunk>We adapted the baseline GA, redefining the oper- tors graph-theoretically according to specific struc- ture types in the DP. For our evolutionary algo- rithm, we have thouroughly reformulated the three primary operators, non-homogenizing, homogenizing, and culling, as well as how gene loci are structured, from the baseline GA. For a minimal ecological niche, we find some lexico-syntactic cues and associated structures discussed in Section 1.1 that is shared by at least a pair of positive samples. To better discrim- inate between non-causal structures and embedded causal structures, we need to maximize the complex- ity of the DP members, in order to minimize the number of possible T T (set of samples) that could contain such, thus maximizing the specificity of DP. 4.2.1 Individual and population Our genotype is cast as a piece of structural in- formation within some induced subtree T s of T, T that conveys causality, so chromosome is modeled as the set of parameters necessary to encode T s de- noted as Ts . Thus, the phenotype is simply whether Ts , once decoded into T s fits inside the ecological niche as induced subgraph. Whether a phenotype is well adapted for the ecological niche can sim- ply be a subgraph isomorphism test, which hereon we will denote as I S (T s , T ). The baseline GA rep- resents chromosome modeled an ordered set of traits with linear contiguity. Since it is highly inefficient to represent all structural information of a chromo- some as individual binary parameters, we redesigned this as a graph-theoretic representation of the linguis- tic structure. The members of DP are represented as subgraphs within embedded causal structures, so each GA-operator must be reformulated according to graph-theoretic concepts. We will use standard graph theoretic notations, where G = V, E (vertices and edges); and N +/ T (v) is the operator that locates the neighbors set of v V of tree T in the +/ direction. The genetic makeup of an individual is modeled as a single chromosome Ts , so the entire set of such sub-structures of T, T becomes our population. Following our definition of diffuse prototype, a chromosome is not an ordered set of parameters, but a configuration of subgraph; and location of gene loci is not its linear position, but its relative location WRT to others, in a tree structure. Ts = vr, v r i vr V (T ) vs V (Ts)[vs N T (vs)] o i v r V (T ) v s V (T s )[v s N T (v s )] o V l = v l vm N + T (v l )[vm / N + Ts (v l )] |N + T (v l )| = 0 V l = v l v m N + T (v l )[v m / N + Ts (v l )] |N + T (v l )| = 0 (2) 45 Ts must contain locations of the boundary nodes of substructure within T ; such boundaries of both T and T are contained within Ts , where each point in the boundary is implemented as a pointer to a tree node. So Ts is a collection of pointers WRT T, T : By moving pointers around V (T ), V (T ), we can decode T s . The and operators indicate the root and leaves of T s WRT any habitat tree T . vr = T ( Ts ) | vr V ( T ) V l = T ( Ts ) | v l V l [v l V ( T )] (3) The initial generation G 0 consists of identical single nodes between T, T , and G is max generation limit, { T ( Ts )} = T ( Ts ) { T ( Ts )} = T ( Ts ). 4.2.2 Non-homogenizing operator The non-homogenizing operator should be de- signed to create new gene variations in the pop- ulation, this is equivalent to mutation in baseline GA. Since we cannot efficiently encode all possible subgraphs of T , we use the far more efficient Ts . So we reformulated the non-homogenizing operator as a process that grows a tree sub-structure one edge+node at a time, and thus introduces new de- grees of freedom each generation. We define an oper- ation that might add a new vertex v i V (T ) \ V (T s ) and edge v i , v j or v j , v i E(T ), v j V (T s ). This is easiest realized in two subtypes, due to the directed nature of T and has no effect on the genetic makeup of the following generation. The previous configura- tion Ts remains if conditions are not met. r( Ts , T, T ) = vj , v j , T ( Ts ), T ( Ts ) A vj = T ( Ts ), vi N T (vj ) a A v j = T ( Ts ), vi N T (vj ) a A (vj ) = (v j ) a (4) where l, r are leaf and root directions. When both T, T agree on a common addition to the current sub- structure, it returns T s , grown from the structure of T s in the r-direction. Here is in the l direction (the operator v h = Tt v k denotes that they are topologi- cally equivalent with respect to the substructure T t that is shared within the pair T, T ): l ( Ts , T, T ) = T ( Ts ), T ( Ts ), T ( Ts ) {vi}, T ( Ts ) {v i }} vi V (T ), v i V (T ), vi = Ts v i A vi / V (Ts) vj T ( Ts ) [ vi N + T (vj ) ] a A v i / V (Ts) vj T ( Ts ) [ v i N + T (vj ) ] a A (vi) = (v i ) a (5) During the non-homogenizing stage of a gener- ation, each individual Ts within the population has a chance to undergo either r ( Ts , T, T ) or l ( Ts , T, T ). The probabilities are mediated by the random variables R and R ; the ratio between R , R is governed by the mean branching factor of T, T , so to ensure even growth in all directions. 4.2.3 Homogenizing operator A homogenizing operator in biological systems or GA randomizes the distribution of alleles and re- distribute new allelic types among the population, by exchange of information between distinct units of inheritance between homologous loci; the most preva- lent is recombination. For our purposes, this is similar to individual haploid organisms exchanging genetic material (e.g. plasmids). So we reformulate the ho- mogenizing operator as process of separating and re- grafting tree substructures together to form new tree configurations. These disparate configuration types are analogous to single-point and 2-point cross-overs in linear genomes. The former is a single contiguous region of shared loci between T s , T t , Ts I Tt . One or more significant regions being shared between to substructures gives us a good anchor for perform- ing cross-over of the remaining, differentiating re- gions of the substructure, essentially a form of elitism (Chakraborty &amp; Chaudhuri, 2003; Mashohor, 2005; Yang, 2007; Chudasama, 2011; Yaman &amp; Yilmaz, 2012; Bora et. al. 2012; etc). We do so by iden- tifying the regions of two substructure with identical graph topology as well as labels of eachs vertices. Given some minimum size for the shared region c : Ts I T t Vm(Ts) Ts,T t (Vm), |Vm| c V m V (Ts) [ Ts,T t (V m ) |V m | &gt; |Vm|] ; Ts ,T t (Vp) = A vi Vm[(vi) = (v i )] a A vi, vj Vp(Ts) v i , v j Vp(Tt) a (6) The second type is two discontiguous regions of shared loci between T s , T t ; denoted as Ts I Tt , a pair of disjoint maximum common subgraphs of T s , T t . This is analogous to the previous formula- tion for the shared region of single-point crossover scenario, except that there are two discontiguous re- gions with a differentiating graph region in between. where we may denote the elements in the pair as Ts I T t [s] , &amp; Ts I T t [t] . These shared regions of T s , T t of Ts I Tt essentially function as a highly special- ized form of rank elitism (Chakraborty &amp; Chaud- huri, 2003; Mashohor, 2005; Yang, 2007; Chudasama, 2011; Yaman &amp; Yilmaz, 2012; Bora et. al. 2012; etc), that operates specifically with our sub-structures, where the regions function to filter pairs of T s , T t so only the highly compatible pairs would undergo homogenization. We denote subgraph relation as , a set of all connected componts of G as (G). We use S c for denoting the choosing of c elements from the set S, and employ a random variable R S , so S c R S preferentially chooses those of the greatest size. Here, , the differentiating regions that may be grafted 46 onto another corresponding substructure, by finding the set of disjoint graph regions () of a induced subgraph of the substructures T s , T t , induced with vertices outside of the shared ( ) region. Ts I T t S 2 R S , S 2 R S S = A A (V (Ts) \ V ( Ts I T t ))(Ts) aa , S = A A (V (Tt) \ V ( Ts I T t ))(Tt) aa ; (Ep) = G( {vq||vq, vr Ep vr, vq Ep}, Ep ) (7) We denote the elements within the target loci range: Ts I T t [S,0] , Ts I T t [S,1] , Ts I T t [T,0] , Ts I T t [T,1] . The correspond- ing type regions is obtained by locating the disjoint regions of the induced subgraph of T s , T t , induced by the vertices outside of the shared region: Ts I T t Tu, Tv (Tu, S, Ts) (Tv, S , Tt) S = A A (V (Ts) \ V ( Ts I T t [s] ))(Ts) aa , S = A A (V (Tt) \ V ( Ts I T t [t] ))(Tt) aa ; (Ep) = G({vq||vq, vr Ep vr, vq Ep}, Ep ); (Tw, Sx, T ) = Tw Sx vi, vj Ts I T t i Pi,j = [vi, ..., vj ] T, [v h , v k E(Tw) v h , v k E(Pi,j )] o (8) Random variables R and R give the prob- abilities of each or type operator would be applied. -type operation is shown for the [1]component ([0]component would be analo- gous), as st (s t) (t [1]component grafted onto T s ), and ts (T s , T t ) (s [1]component grated onto T t ). () and () provide configuration of the nodes relations WRT the and regions, omitted due to space constraints. st (Ts, Tt) V st = (V (Ts) \ V ( Ts I T t [S,1] )) V ( Ts I T t [T ,1] ) E st = E( V st (Ts) ) E A Ts I T t [T ,1] a {{vi, v j } A (vi, vj ) (vj , vi) a A (v i , v j ) (v j , v i ) a ; (9) It takes the necessary vertices from the graft [1]component of T t , and the remainder of T s , and add a new edge so that they are still attached in the same configuration as they were in T s and T t . The t s process is the mirror image of s t when the same Ts I T t Ts I T t , omitted due to space. Correspondingly, the type operation is similar to a two-point cross-over, with two new edges v i , v j , v p , v q necessary for the new compos- ite form. We define type operation, with the two recombinations as (T s , T t ), and demonstrate one direction of grafting of component onto the remain- der of T s , the opposite direction is analogous. (Ts, Tt) V = (V (Ts) \ V ( Ts I T t [S] )) V ( Ts I T t [T ] ) E = E(V (Ts)) E( Ts I T t [T ] ) {{vi, v j , v p , vq} vi = vq AA (vi, vj ) (vj , vi) a A (vp, vq) (vq, vp) aa AA (v i , v j ) (v j , v i ) a A (v p , v q ) (v q , v p ) aa (10) Similar to , the type operator takes the nec- essary nodes from the two shared regions between T s , T t and any non-shared regions not between shared regions. It then locates the nodes in the graft com- ponent and edges between them. Finally, it includes two new edges, making the connection between graft and host, while preserving the local configurations at the attachment points. It is easier illustrated pic- Figure 2: before single-point crossover Figure 3: after single-point crossover torially, such as type operation in Figures 2 - 3; the single red region are shared between the substru- tures, while the orange, green regions within T s , and yellow, purple regions in T t , undergo re-grafting into new host structures from one figure to the next. 47 4.2.4 Culling operator &amp; genetic drift Death is an essential component of evolution in na- ture; with significant death rate, natural selection has an opportunity to apply its pressure. In a biological system, this process is a mixture of directed selection, (depends on the fitness of an organism in an eco- logical niche), or migration patterns among niches; and some randomization in selection, which in nature include genetic drift and immigration/emmigration. Directed selection is the primary driver for adapta- tion, when the environment remains static over sev- eral generations. The primary metric of usefulness of any T s is its complexity measured as n(T s ), which entails the maximization of the number of potential non-homogenizing operations on T l s . So the base for- mulation of fitness is based the total capacity to re- produce (potential rate * reproductive span), termed fecundity, and the actual rate given population and environmental factors, termed fertility. This impor- tant ratio is f (T s ) = f ertility f ecundity = f Ts e Ts . Also a factor in the usefulness of sub-structure T s is the distribu- tion of terminal symbols of T s within the corpus. We incorporated lift of tokens of tree terminals within positive sample, against all tokens in the training data. Let (T s ) be a function linearizes the terminals of the tree T s , and where X E is the set of terminal sequences from the positive samples, and X E&amp;i are samples showing both traits; the fitness F is: F (Ts) = f (Ts) f Ts e Ts x j (Ts) L(X E = xj ) | (Ts )| L(X E = xj ) = S(X E&amp;i ) S(X E )S(X i ) | xj Xi S(Xi) = x j X i Nj x k X N k Nj n(Xj ) (11) Since degrees of freedom increase over generations, Boltsmann selection is unnecessary and may even de- lay arrival at global maximum. The procedure used is a roulette selection, since variability of fitness within a single generation is small. Genetic drift is not an issue here, since the degree of freedom available in- creases with each generations non-homogenizing op- eration. Each testing sample is tested against the extracted substructures. This process still has high time complexity, potentially O(n k+4.5 ) (k is the de- gree limit) (Bodlaender, 1988). Additional pre-filters (i.e., number of vertices, degree-list, label-histogram of V ) are applied to further reduce complexity. </chunk></section><section><heading>5 Test results </heading></section><section><heading>5.1 Dataset and model parameters </heading><chunk>The BNC is a mixed corpus with complex genres such as parliamentary proceedings and news articles. The training set needs to have sufficiently complex frames to have a significant probability of being embedded causals. Other non-training parts of BNC, as well as the novels corpus, were used for testing. The labelled data is lexed and parsed, and some tree transforma- tions are detected and reconstructed, and separated into semantic frames. The BNC-testing data con- tained 196314 lines, and novels set 129695 lines. For the novels testing set, 26356 instances of semantic frames were detected, and for the BNC testing set, 31807 instances of frames were detected. This pro- cedure provides no specific threshold, since it is not binary, but produces a score for likelihood of complex causality. For evaluation, due to output frame count, and the fact that embedded causal structures are a small fraction of all possible clauses, standard preci- sion + recall over the corpus is not feasible. The most sensible method is a sparse quantile-based annota- tion. We annotated three sets of k = 100+ (actually 115 each, to ensure at least 100 determinable). The annotation of this initial testing phase was performed by one of the authors. The labels for sample are Y (causal), N (non-causal), and U (undeterminable) </chunk></section><section><heading>5.2 Ranking evaluation </heading><chunk>The results are ranked sets of samples. A positive causal chain sample will contain at least some clearly identifiable e i cause e j , where e i , e j are events ex- pressed by clauses in the surface sequence. It is not required that each pair of adjacent pair of events e i , e i+1 would be causal; and some causal relation e i caus e j may not be immediately adjacent pairs (may skip some event in sequence). We explored how quickly the result by annotating the next sev- eral quantiles, each with the aforementioned approxi- mately 115 samples to guarantee each quantile having at least 100 determinable ones. Since it is very labor intensive, we annotated each until a trend in quantile precision emerges, which was 7 for BNC-testing, and 10 for novels, when we observe a large difference from the highest quantile and a trend tending to a distri- bution tail. There are now 805 annotated samples from top 7 quantiles (Y:225, N:457, U:93) from the BNC-testing, where the top quantile had precision of 0.795, next highest quantile 0.677, and 7th quan- tile 0.133 (quantile precision is shown in Figure 4). There is a total of 1150 from top 10 quantiles (Y:401, N:672, U:77) from novels; the top quantile had a pre- cision of 0.800, next highest 0.574, 7th quantile 0.206 (shown in Figure 5). The top 2 quantiles for each set is significantly above %50, thus a relatively high- confidence threshold can be set at top 200 for a binary classification task. The samples mostly contain 2-5 events in a causal chain, with the longest of 7. 48 Figure 4: BNC precision in its top 7 absolute quantiles Figure 5: Novels precision in their top 10 absolute quantiles </chunk></section><section><heading>5.3 Comparison with baselines </heading><chunk>We compared the results of our system to baselines, a textual entailment system as well as an n-gram model; since annotation is highly labor intensive, the annotated data are from the top 10 quantiles of our ranking. Thus these samples are already pre-selected by our system to be relatively likely to be causal; so we mainly test to see if a correlation with our sys- tem exists, and whether they produce the same gra- dient of precisions that rank from highest quantile to the lowest among these 1150 samples. For each, we expect some positive correlation with ours; but our system, being more specifically designed for complex causality, should outperform each. We are unaware of any comparable system for com- plex causality, so textual-entailment (TE) is the most similar to our task. Thus, we used the TE system VENSES (Delmonte et. al. 2007/2009). This test is not approrpiate for the original purpose of VENSES, but is done with our data and annotation to see any correlation to our results, a comparison of the clos- est system. For any given sample of testing set, we determine whether any pair of the multiple clauses, is identified as entailed by VENSES. We compared the results against our gold standard (for embedded causality). The samples are the top 10 quantiles of the novels data-set (set with the most annotated sam- ples), ranked according to our algorithm. Figure 6 contain the TE fraction of each quantile according to VENSES (red), whether VENSES judgement on TE is consistent with our human annotation on causality (green), and our systems output (blue). TE results Figure 6: fractions of TEs according to VENSES, fraction of VENSES Y/N output same as human judgement on causality, and our system; for each of the top 10 quntiles for novels. The black lines with shading are the corresponding trend lines labels contained many false negatives, since it is not designed for causality. This also serves as a baseline for our system, given TE is the closest system avail- able for testing, where our system overperformed sig- nificantly given the task of complex causality. Causal chains are highly sequential structures, so an n-gram model is a reasonable method for com- parison. We also produced a standard n-gram model with smoothing and back-off, trained on the same training data as our system. Each sample of multiple clauses/frames is presented a a single sequence of ter- minal tokens. We determined that a trigram model is the optimum to obtain good specificity and avoid over-training. Thus, we tested it against each of the annotated testing samples, and produced a ranked score using the harmonic mean of probability of each token in the sequence according to the trigram model. Given that the testing samples are preselected by our system to be top-10 quantile, the n-gram model pro- vides a re-ranking of these. We examined this re- ranking to see whether we get the same differentia- tion in precision in the new 10-quantiles of the same size after re-ranking (Figure 7). Thus the results of our system are also weakly correlated with n-gram re- ranking; but our system provides much better Y/N separation of the gold-standard in the trajectory over the top quantiles, and provides a more consistent and monotonic trend. 49 Figure 7: precision in re-ranked quantiles according to n-gram, with trendline, and original ranked quantiles from our system </chunk></section><section><heading>5.4 Further Analysis </heading><chunk>Given causality has many divergent definitions, we used a detailed characterization scheme allowing each annotator to select from categories of causations. Each of these characterizes one frequently accepted aspect of causation, including the four classical ma- terial (constitution of component sub-events), for- mal, efficent, and final (purpose) causes (Aristo- tle 350 B.C. / 322 B.C.), which are often regarded in cognative studies as relevant aspects of causation that humans use in recognition of causality (Rach- lin 1992, Hogan 1994, Killeen 2001, Killeen &amp; Nash 2003, Alvarez 2009); as well as other common aspects of causality, cause of necessity (enablement), cause with intermidate volition (inducement), and latent causal chain (outcome). We also labelled the top 150 samples of the novels set, for the presence/absence of each of these 7 classes. Since long causal chains may contain multiple relations of different semantic types in one sequence, a sample may have multiple la- bels. The number and percent of the top 150 ranked samples are efficient: 17, 11.3%; necessity: 36, 24.0%; formal: 42, 28.0%; final: 40, 26.7%; inducement: 44, 29.3%; material: 17, 11.3%; la- tent: 10, 6.7%; which has a wide distribution among the 7, and has no particular dominant class. It is unsurprising that latent causal chain is contained in the least number of samples, since it is also the most difficult for people to detect. We here provide some top-quantile samples with the said annotation with a variety of classification scheme labels: eurotunnel is already in default of its credit agreement with the bank synidcate, [that it] is seeking an extra xx billions on top of the xx billions raise so far . eurotunnel is already in default of its credit agreement with the bank syndicate ef f icient it is seeking an extra xx bil- lions on top of the xx billions raised so far before the housewives could rest several people called and there was a scramble to get ready to see them (receive them with hospitality) several people called [the housewives to visit] ef f icient there was a scramble to get ready purpose to see them (here meaning receiving the guests) she tries to find highborn women to bear him a son that she can take in as her own she tries to find highborn women enables to bear him a son enables she can take in as her own by late afternoon, I (Cleopatra Selene II) joined the rest of the women of the household Lady Octavia took it upon her- self to [Lady Octavia] teach me (Cleopatra Selene II) to spin whorl I joined the rest of the women of the household constitute Lady Octavia took it upon herself purpose teach me purpose spin wool I (Cleopatra Selene II) was a Ptolemy princess (meaning de- scended from Hellenic-pharonic bloodline), a queen in exile who must bide her time until she could think of some plot, some plan to [some plot/plan] return her to her throne I was a Ptolemy princess constitute [I was] a queen in exile implication who must bide her time enables she could think of some plot, some plan purpose return her to her throne one of the guards searched Euphronius he actually put his unclean hands on our wizards hold person I (Cleopatra Selene II) watched, aghast, trying to ignore the curious mo- tion within the basket an echo of fear that snaked around my heart then the ill-mannered Roman guard approached me and I held my basket out to him hoping hed reach in- side (Counterfactual) hoping that whatever evil spirit lurked there would fly out strike him dead one of the guards searched Euphronius ef f icient I watched aghast trying to ignore the curious motion within the basket outcome the ill-mannered Roman guard ap- proached me induces I held my basket out to him purpose hed reach inside ef f icient whatever evil spirit lurked there would fly out ef f icient strike him dead </chunk></section><section><heading>6 Conclusion &amp; future direction </heading><chunk>For this study, we designed and demonstrated a pro- cedure to rank the likelihood of causality from com- plex linguistic structures. The process takes lexico- semantic as well as morpho-syntactic information in the expressions into a single form of representation; a collection of which then is extended into a diffuse pro- totype, a composite cognitive categorization model, for a complex multi-modal description of causality. An evolutionary algorithm, with a graph theoretic focus, is developed specifically to obtain the diffuse prototype from a limited number of training samples. The output model then can be used to score unseen samples according to a variegated notion of causality. Due to the nature of the model representation and the GA-like procedure, it is adaptable for a wide va- riety of human definitions of causality. This system in the future needs to be further developed from a rank- ing procedure to a discrete classification task. It will also be worth to look at further sub-classifications of causality, to see whether a similar procedure can pro- vide a yet more fine-grained recognition of different deep semantic types of this relation. 50 References S. Abe, K. Inui and Y. Matsumoto 2008. Two-phrased event relation acquisition: Couplingthe relation- oriented and argument-oriented approaches. Proceed- ings of the 22nd International Conference on Compu- tational Linguistics (COLING2008), 18 L. M. Alcott 1997. Little women. Roberts Brothers Publishing, Boston. M. P. Alvarez 2009. The four causes of behavior: Aris- totle and Skinner. International Journal of Psychology and Psychological Therapy, 9(1):4557 Aristotle 300 B.C. (Physics). Trans- lated by R. P. Hardie and R. K. Gaye, MIT Press 1994. Aristotle before 322 B.C. (Meta- physics), ed. J. Verner. Oxford Classical Texts: Oxford University Press, 1957. J. E. Baker 1985. An Analysis of the Effects of Selection in Genetic Algorithms. International Conference on Genetic Algorithms and Their Applications, 101111 J. E. Baker 1989. An Analysis of the Effects of Selec- tion in Genetic Algorithms. Ph.D. Thesis, Vanderbilt University, Nashville, 1989 N. A. Barricelli 1989. Numerical testing of evolution the- ories : Part I Theoretical introduction and basic tests. Acta Biotheoretica, Issue 16 (1-2):6998 R. Girju and B. Beamer 2009. Using a bigram event model to predict causal potential. In Proceedings of Conference on intelligent text processing and compu- tational linguistics 2009, Mexico City, Feb 2628 S. Berthard &amp; J. H. Martin 2008. Learning semantic links from a corpus of parallel temporal and causal relations. Proceedings of ACL-08: HLT, Short Papers (Compan- ion Volume), 177180, Association for Computational Linguistics H. Bodlaender 1988. Dynamic programming on graphs with bounded treewidth. Proceedings of 15th Interna- tional Colloquium on Automata, Languages, and Pro- gramming, volume 317 of Lecture Notes in Computer Science, 105118. Springer-Verlag, Berlin Heidelberg T.C. Bora, L. Lebensztajn, L.D.S. Coelho 2012. Non- Dominated Sorting Genetic Algorithm Based on Rein- forcement Learning to Optimization of Broad-Band Re- flector Antennas Satellite. IEEE Transactions in Mag- netics, 48(Number 2 Supplement 4 Part 1):767770, Piscataway, NY A. Brindle 1981. Genetic algorithms for function opti- mization, Technical Report, 8182, University of Al- berta, Canada British National Corpus 2007. University of Ox- ford Press, Longman Publishing, W &amp; R Cham- bers Publishing, in conjunction with British Li- brary, University of Oxford, and Lancaster University url:http://www.natcorp.ox.ac.uk/ B. Chakraborty and P. Chaudhuri 2003. On The Use of Genetic Algorithm with Elitism in Robust and Non- parametric Multivariate Analysis. Austrian Journal of Statistics, Volume 32 D.S. Chang, K.S. Choi 2006. Incremental cue phrase learning and bootstrapping method for causality extrac- tion using cue phrase and word pair probabilities In- formation Processing and Management, 42(3):662678 C. Chudasama, S. M. Shah, M. Panchal 2011. Compar- ison of parents selection methods of genetic algorithm for TSP. International Conference on Computer Com- munication and Networks, published by International Journal of Computer Applications (IJCA) N. L. Cramer 1985. A Representation for the adaptive generation of simple sequential programs. Proceedings of International Conference on Genetic Algorithms ans their Applications, Carnegie-Mellon University C. Darwin 1859. on the Origin of species: (by Means of Natural Selection, The Preservation of Favoured Races in the Struggle for Life) John Murray Publishing R. Delmonte, A. Bristot, M.A. Piccolino Boniforti, S.Tonelli 2007. Entailment and anaphora resolution in RTE3. Proceedings of ACL Workshop on Text Entail- ment and Paraphrasing, 4853, Association of Com- putational Linguistics, Prague D. B. Fogel 1998. Evolutionary computation: the Fossil record, IEEE Press, Piscataway, NJ R. Girju 2003 Automatic detection of causal relations for question answering, The 41st Annual Meeting of the Association for Computational Linguistics (ACL 2003), Workshop on Multilingual Summarization and Question Answering : Machine Learning and Beyond D. Goldberg 1989. Genetic Algorithms in Search, Opti- mization and Machine Learning, Addison-Wesley Pub- lishing, Reading MA D. Goldberg and K. Deb 1993. A comparative analysis of selection schemes used in genetic algorithms. Foun- dations of Genetic Algorithms, 6993 D. Goldberg, K. Deb, J. Clark 1991. Genetic algo- rithms, noise, and sizing of population. Complex Sys- tem, 6:333-362 Project Gutenberg, M. Hart 2005. Gutenberg corpus, http://www.gutenberg.org/ C. Hashimoto, K. Torisawa, J. Kloetzer, M. SanosIstvan, V. J.H. Oh, Y. Kidawara 2014. Toward future sce- nario generation: extracting event causality exploiting semantic relation, context, and association features. Proceedings of the 52nd Annual Meeting of the Associ- ation for Computational Linguistics (ACL) J. D. Holland 1975. Adaptation in Natural and Artificial Systems. University of Michigan Press, Ann Arbor, Michigan K. A. de Jong 1975. an Analysis of the behavior of a class of genetic adaptive systems, Ph. D. Dissertation, University of Michigan Press, Ann Arbor, Michigan C. Khoo, S. Myaeng, R. Oddy 2001. Using cause- effect relations in text to improve information retrieval precision, Information Processing and Management, 37:119145 P.R. Killeen 2001. The four causes of behavior, Current Directions in Psychological Science, 10:136140 P.R. Killeen and M.R. Nash 2003. The four causes of hypnosis. The International Journal of Clinicaland Ex- perimental Hypnosis, 51:195231 51 S. Kirkpatrick, J. C.D. Gelatt, M. P. Vecchi 1983. Optimization by simulated annealing. Science, 220:671680 S. Mashohor 2005. Elitist selection schemes for genetic algorithm based printed circuit board inspection system. Evolutionary Computation, The 2005 IEEE Congress, 2:974978 P. Menzies 2009. Counterfactual theories of cau- sation. Stanford Encyclopedia of Philosophy, Fall 2009, ed: E. N. Zalta, web published: plato.stanford.edu/entries/causation-counterfactual Stanford University Department of Philosophy J.H. Oh, K. Torisawa, C. Hashimoto, M. Sano, S. de Saeger, K. Ohtake 2013. Why-question answering us- ing intra- andinter-sentential causal relations Proceed- ings of the 51st Annual Meeting of the Association for Com-putational Linguistics (ACL 2013), 51:17331743 M. Paul, C. Girju, C. Li 2009. Mining the web for recip- rocal relationships, Proceedings of the Thirteenth Con- ference on Computational Natural Language Learning (CoNLL), Boulder, Colorado H. Rachlin 1992. Teleological behaviorism. American Psychologist, 47:1371-1382, American Psychological Association K. Radinsky, S. Davidovich, S. Markovitch 2012. Learn- ing causality for newsevents prediction. Proceedings of International World Wide Web Conference 2012 (WWW 2012), 909918 I. Rechenberg 1973. Evolutionsstrategic: Optimierung technicher System nach Principen der Biologischen Evolution, Frommmann-Holzboog Verlag, Stuttgart M. Riaz and C. R. Girju 2010. Another look at causal- ity: Discovering scenario-specific contingency relation- ships with no supervision, Proceedings of ICSC, CERN School of Computing J. Schmidhuber 1987. Evolutionary principles in self- referential learning: On Learning now to learn: the meta-meta-meta..., Doctoral Thesis, Technische Uni- versit  at Munchen, Germany A. Turing 1950. Computing machinery and intelligence Mind: a Quarterly Review of Psychology and Philoso- phy, LIX(236):433460, The Mind Association F. Yaman, A. E. Yilmaz 2012. Elitist genetic algo- rithm performance on the uniform circular antenna array pattern synthesis problem, PRZEGLD ELEK- TROTECHNICZNY (Electrical Review) S. Yang 2007. Genetic algorithms with elitism- based immigrants for changing optimization problems, EvoWorkshops 2007, LNCS 4448:627636, Springer Verlag, Berlin. 52 </chunk></section></sec_map>