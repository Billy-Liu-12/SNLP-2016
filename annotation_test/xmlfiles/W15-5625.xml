<sec_map><section><chunk>nGramas de Caractere como Tecnica de Normalizacao  Morfologica para Lingua Portuguesa: Um Estudo em  Categorizacao de Textos  Guilherme T. Guimaraes, Marcus V. Meirose, Silvia M. W. Moraes Faculdade de Informatica  Pontificia Universidade Catolica do Rio Grande do Sul (PUCRS) Caixa Postal 1429 90619900  Porto Alegre  RS  Brazil guilherme.guimaraes1991@gmail.com, mvmeirose@gmail.com,  silvia.moraes@pucrs.br Abstract.  This paper describes  a  study on text categorization using  a  character ngrams approach for the morphological normalization. In recent work, this approach has emerged as a way to simplify the normalization of terms. In our research, we compared this approach to the usual normalization methods of stemming and lemmatization. In our case study, we used a subset of the PLNBR CATEG corpus and SMO classification  algorithm from the Weka tool. The results show that the character ngram approach is promising. Resumo.  Este artigo descreve  um  estudo em  categorizacao de textos  que  utiliza ngramas de caractere como metodo de normalizacao morfologica. Em  trabalhos recentes,  essa abordagem  tem surgido como uma forma  de  simplificar  a  normalizacao dos termos. Em nossa investigacao, comparamos  essa abordagem a metodos  usuais de normalizacao como stemming e lematizacao. Em nossos casos de estudo, usamos um subconjunto do corpus em PLNBR CATEG e o algoritmo de classificacao SMO da ferramenta Weka. Os resultados obtidos mostram que a abordagem de ngrama por caractere e  promissora. </chunk></section><section><heading>1. Introducao </heading><chunk>Com a evolucao da era digital, a quantidade de informacao que se encontra ao nosso  alcance cresceu de uma forma significativa. Cresceu, tambem, a necessidade de  organizar tais informacoes e transformalas em dados uteis. Atualmente, tribunais,  empresas, escritorios entre outros negocios necessitam de uma forma automatizada de  organizacao dos textos. Para isso a tecnica de classificacao em categorias tem sido de  grande ajuda. Como a organizacao desses artefatos exige uma grande demanda de  tempo e trabalho  manual, resultando em perda de efetivo para o negocio, a solucao  tem sido o uso de formas automatizadas de organizacao. Tais formas incluem  as  tecnicas de categorizacao de texto.  A categorizacao ou classificacao de textos  consiste em atribuir objetos  (documentos textuais)  de um universo a duas ou mais classes (ou categorias) [Manning  e Schutze, 1999; Sebastiani, 2002]. Como a base de execucao dessa tarefa esta centrada  nos termos 1 existentes nos  textos, a normalizacao  linguistica  acaba tendo um papel  1 Um termo pode ser a raiz de uma palavra, uma palavra, uma sequencia de palavras ou mesmo uma  sentenca inteira. Proceedings of Symposium in Information and Human Language Technology. Natal, RN, Brazil, November 47, 2015. c 2015 Sociedade Brasileira de Computac ao. 211 importante nesse processo. E por meio de tecnicas de normalizacao  linguistica  que  podemos reduzir o conjunto de  termos, unificando  as variantes  de um termo  a uma  mesma forma de representacao.  Nesse trabalho, estudamos o impacto, no processo de categorizacao de textos em  portugues, da substituicao de  tecnicas  usuais de normalizacao morfologica como  stemming (ou radicalizacao) e lematizacao por ngramas 2  de caractere. Um ngrama de  caractere e uma sequencia consecutiva de n caracteres. Segundo a literatura na area, ha  varias  razoes  que justificam o uso de  ngramas  de caractere  no processo de  categorizacao de textos: essa tecnica e puramente estatistica, nao e dependente de  linguagem,  nao requer qualquer outro conhecimento  sobre o texto  para ser aplicada  [Rahmound e Zakaria, 2007]  e, ainda e mais tolerante  tanto a  erros ortograficos  e  sintaticos quanto a ruidos existentes em textos digitalizados [Cavnar e  Trenkle, 1994]. Em nossos casos de  estudo  em categorizacao de textos,  usamos  o  corpus  PLN_BR CATEG 3 . Para este corpus, criamos, inicialmente, dois casos de estudo, ditos  de  referencia, baseados em unigramas de palavra  para cada forma de normalizacao  usual: stemming e lematizacao. Em seguida, definimos varios casos de estudo baseados  em  ngrama de caractere para diferentes valores de  n. Em todos  os casos de estudo,  utilizamos a tecnica de limiar por ranking como forma de selecao de caracteristicas. Na  etapa de classificacao,  usamos  o algoritmo da ferramenta Weka 4 : Sequential Minimal  Optimization (SMO), que e uma versao do algoritmo Support Vector Machine (SVM).  Os resultados obtidos em nosso estudo mostram que a abordagem baseada em ngramas  de caractere  como forma normalizacao morfologica  para  lingua  portuguesa  e  promissora, no entanto mais estudos precisam ser realizados.  Cabe mencionar que as  principais vantagens dessa abordagem  sao  a sua simplicidade,  tolerancia a erros  diversos e sua indepedencia de linguagem. Este artigo esta organizado em 5 Secoes. A Secao 2 descreve de forma sucinta  alguns metodos  de normalizacao linguistica. A Secao 3 descreve brevemente alguns  trabalhos correlatos ao nosso. A Secao 4 detalha o nosso estudo em  ngramas de  caractere aplicado a categorizacao de textos. E, por fim, a Secao 5 apresenta as nossas  conclusoes. 2. Normalizacao Linguistica  O objetivo da normalizacao linguistica e transformar as variantes de um termo em uma  forma unica de representacao. A normalizacao linguistica pode ser morfologica,  lexicosemantica ou sintatica  [Galvez  et al,  2005].  A normalizacao morfologica  e  aplicada a termos com formas semelhantes cujos conceitos, em geral, estao  relacionados, tais como  conectado, conexao  e conectando.  Nesse caso, as  variantes poderiam ser representadas por conexao. A normalizacao lexicosemantica e  usada em termos com similaridade semantica como estado emocional, estado  afetivo e sentimento.   Esses termos poderiam ser reduzidos ao termo sentimento.  Ja a normalizacao sintatica e usada em termos com estruturas sintaticas diferentes que  possuem significados semelhantes como em  desempenhou com eficiencia,  desempenho eficiente  e eficiencia em desempenho. Todas essas formas poderiam  ser transformadas em desempenho eficiente. 2 Ngramas podem ser definidos em nivel de palavras, caracteres ou bytes [Graovac, 2012]. 3 Esta colecao foi obtida atraves do projeto Recursos e Ferramentas para a Recuperacao de Informacao  em Bases Textuais em Portugues do Brasil (PLNBR), apoio CNPq #550388/20052. 4 http://www.cs.waikato.ac.nz/ml/weka/ n-Gramas de Caractere como T  ecnica de Normalizac ao Morfol  ogica para L  ngua Portuguesa: Um Estudo em Categorizac ao de Textos 212 A normalizacao morfologica e efetuada por meio de metodos de conflacao.  Conflacao consiste em fundir variantes em uma unica forma. Ha varios metodos  automaticos de conflacao, dentre os mais usuais estao o  stemming  (radicalizacao) e a  lematizacao  [Gonzalez e Lima, 2003;  Galvez  et al.,  2005]. No  stemming,  a  normalizacao  e  baseada na remocao de afixos,   transformando as variantes  em seus  radicais. Por exemplo, conectado e conectando seriam representados por conect.  Ja na lematizacao, as variantes sao levadas a sua forma canonica (lema): os verbos vao  para a forma infinitiva e os adjetivos e substantivos, para masculino singular (se existir).  A conflacao por lematizacao transformaria os termos exemplificados em conectar. Metodos  baseados em  ngramas de caractere tambem podem ser usados como  formas  de conflacao [Galvez  et al.,  2005;  Sharma, 2012]. Um desses metodos e o  bigrama compartilhado. Nesse metodo, primeiramente, os termos sao divididos em duas  letras consecutivas, os bigramas. Por exemplo, o termo filho possui os bigramas fi,  il,lh e ho. O processo de conflacao e definido a partir da quantidade de bigramas  compartilhados  pelos termos. Para identificar esse  compartilhamento sao usadas,  geralmente, medidas de similaridade, tal como o coeficiente Dice [Galvez et al., 2005;  Sharma, 2012].  Alguns  autores classificam  esse  metodo  como um algoritmo de  stemming baseado em ngrama, com abordagem estatistica [Jivani, 2011; Diyanati et al.  2014]. Hassan e Chaurasia em [Hassan e Chaurasia, 2012] descrevem outro metodo de  conflacao baseado em ngramas de caractere. Eles definem ngramas iniciais, medios e  finais.  Os  ngramas  iniciais sao gerados  com os  n  primeiros caracteres do  termo;   os  finais, com os  n  ultimos e os medios, com os n mais centrais.  Por exemplo, a palavra  casa possui ca como bigrama inicial, as como bigrama medio e sa como  bigrama final .  Os  ngramas iniciais  tambem foram usados por  Mayfield e McNamee  como metodo de conflacao em  [Mayfield e McNamee, 2003], no entanto eles os  chamaram de pseudosradicais (pseudostem). Para esses autores, essa abordagem e um  metodo de  stemming  para o qual e gerado apenas  unico  ngrama  inicial  de caractere  (Single Ngram Stemming). Neste trabalho, usamos como metodo de conflacao os ngramas iniciais. Nossa  escolha se baseou nos bons resultados encontrados por Hassan e Chaurasia em seus  estudos em categorizacao de textos [Hassan e Chaurasia, 2012].  Outro motivo foi o fato  de  ngramas iniciais  serem mais simples,  exigindo  menos processamento  computacional. 3. Trabalhos Relacionados O primeiro trabalho que encontramos usando ngramas de caractere para categorizacao  de texto  data de 1994.  Nesse trabalho, Cavnar e Trenkle  usam o metodo de  bigrama  compartilhado [Cavnar e  Trenkle, 1994]. Inicialmente, os autores usam os termos dos  textos do conjunto de treino para definir o perfil (baseado no modelo bagofwords) de  cada categoria de texto.  Cada perfil e formado por  k  ngramas de caractere mais  frequentes. Em seguida, os autores definem um perfil para cada documento a ser  classificado (do conjunto de teste) e, para  definir a classe, medem a distancia entre o  perfil desses  documentos  em relacao  ao das categorias.  Os autores  usam,  em seus  experimentos,  o  corpus  Usenet newsgroup em diferentes linguagens. No experimento  cujo objetivo era classificar os artigos  de acordo com a linguagem,  a  taxa de  classificacoes corretas  foi de 99,8%. Ja naquele em que a meta era a classificacao por  assunto, a taxa ficou em torno de 80%.  Rahmoun e Zakaria  em [Rahmoun e Zakaria,  n-Gramas de Caractere como T  ecnica de Normalizac ao Morfol  ogica para L  ngua Portuguesa: Um Estudo em Categorizac ao de Textos 213 2007]  utilizam  uma  abordagem  semelhante  a  de  Cavnar e  Trenkle.  Eles usam, no  entanto, a medida 2 para associar os  ngramas  de caractere  aos perfis, e  as medidas  cosseno e de Kullback &amp; Liebler para classificar os documentos. Na investigacao deles,  foram usados os corpora Reuters 21578 e 20Newsgroup, ngramas de caractere com n  variando de 2 a 7 e perfil com comprimento  k  entre 100 e 800.   No caso do  corpus  Reuters 21578,  a melhor media F1 foi de 70%, para  n=5  e  k=400  . Ja  no caso do  corpus 20Newsgroup, F1 foi de 71% para n=5 e k=600. Em  trabalhos  mais  recentes,  Hassan e  Chaurasia  utilizam  a categorizacao  de  textos  para  atribuir  a autoria  a documentos  em  lingua  inglesa  [Hassan  e Chaurasia,  2012]. Para isso, eles analisam  o uso bigramas e trigramas de caractere iniciais, medios  e finais  na etapa de selecao de caracteristicas.  Os autores  realizaram  varios testes  e  obtiveram bons resultados com bigramas e trigramas iniciais, alcancando mais de 95%  de acuraria.  Ja Kumari e outros em [Kumari  et al., 2014] aplicam a categorizacao  de  textos com outro fim. Eles buscam o aprimoramento da classificacao de paginas web em  relacao aos seus generos (servico, comercio, entretenimento,...). Em sua investigacao, os  autores utilizam o  corpus  7Genre, que contem 1.400 paginas  web  em ingles, e o  algoritmo  SVM  como classificador.  Nos estudos realizados  por eles, foram testados  ngramas iniciais com n variando entre 3 e 8.   O melhor resultado foi obtido com n=5  para o qual a media F1 atingiu 95,8%. Diferente dos trabalhos pesquisados, nosso estudo e voltado para  lingua  portuguesa. E importante mencionar que nao e de nosso conhecimento a existencia de  trabalhos que investiguem  ngramas de caractere como metodo de normalizacao  linguistica para o portugues.  A seguir, descrevemos a nossa investigacao usando essa  abordagem em categorizacao de textos. 4. Estudo em Categorizacao de Textos Em nosso estudo, usamos  um subconjunto do  corpus  em  lingua  portuguesa PLNBR  CATEG. Este corpus possui em sua totalidade cerca de 30 mil textos do jornal Folha de  Sao Paulo dos anos de 1994 a 2005.   Usamos as secoes do jornal como categorias dos  textos. Selecionamos as categorias desse corpus considerando dois aspectos: quantidade  de textos e uniformidade de conteudo. Na tarefa de categorizacao de textos, o  balanceamento e a qualidade das amostras do conjunto de treino interfere  diretamente  nos resultados [Batista et al., 2004]. Sendo assim, categorias com poucos textos como  Agrofolha (166 textos apenas) ou com uma diversidade grande de conteudo como a  categoria Tudo foram desconsideradas.  Como nosso foco era especificamente a investigacao dos ngramas de caractere,  procuramos minimizar, na medida do possivel, fatores que pudessem prejudicar a tarefa  de classificacao,  tal como o desbalanceamento das  amostras do conjunto de treino  [Japkowicz  e  Stephen,  2002].  Por questoes de desempenho, optamos por utilizar a  tecnica  de balanceamento  undersampling  (subamostragem),  a qual  permite  a  eliminacao de amostras de classes majoritarias [Batista et al., 2004]. Sabemos que essa  tecnica pode levar a perda de informacao, se o subconjunto de amostras  do treino nao  for escolhido adequadamente,  em decorrencia da  ausencia de uma heuristica que guie  esse processo de selecao. No entanto, acreditamos que essa perda eventual nao prejudica  os resultados  obtidos, visto que  nossa investigacao  e de natureza comparativa.  Se a  perda ocorrer, ela se dara igualmente em todos os casos estudados. Em nossa investigacao, foram usadas  apenas  6  categorias  do  corpus  PLNBR  n-Gramas de Caractere como T  ecnica de Normalizac ao Morfol  ogica para L  ngua Portuguesa: Um Estudo em Categorizac ao de Textos 214 CATEG: Brasil (5.606 textos), Cotidiano (6.458 textos), Dinheiro (4.153 textos),  Esporte (4.632  textos), Ilustrada (2.935  textos) e Mundo (2.410  textos).  Juntas  elas totalizaram 26.194 textos. Apos, alguns testes preliminiares, acabamos escolhendo  1.000 textos de cada categoria  para formar o conjunto de treino.  Os  textos restantes  foram usados como conjunto de teste. Alem disso, utilizamos, em todos os casos de  estudo,  o mesmo  preprocessamento. Os textos foram tokenizados e removidos os tokens correspondentes  a  stopwords 5 , pontuacao, numeracao e caracteres especiais. Aplicamos tambem  o  mesmo processo de selecao de caracteristicas, que foi limiar por ranking, a exemplo de  Hassan e  Chaurasia em [Hassan e  Chaurasia, 2007].  Em nosso estudo, testamos  diferentes comprimentos k (quantidade de termos) para bagofwords. Cabe mencionar  que a  bagofwords  final e resultante da uniao dos  k  termos mais relevantes  (mais  frequentes) de cada categoria.  A partir da bagofwords determinada na etapa de selecao, os textos receberam  uma representacao vetorial cujos pesos foram definidos usando a  medida  TFIDF.  Escolhemos essa tecnica por ela ser muito usual na tarefa de categorizacao de textos.  Por fim, usamos  o mesmo algoritmo de classificacao  em todo o estudo: SMO  da  ferramenta Weka.  Escolhemos esse algoritmo por  sua aplicacao ser  recorrente  em  trabalhos correlatos ao nosso. Por fim, analisamos os resultados com base nas medidas  comumente utilizadas para avaliar a tarefa em questao: Precision, Recall e F1. Na secoes seguintes descrevemos configuracao dos nossos casos de estudo e os  resultados obtidos. 4.1. Configuracao dos Casos de Estudo Para que pudessemos analisar o impacto do uso de ngramas de caractere como metodo  de normalizacao morfologica no processo de categorizacao de textos, definidos 3 tipos  de casos de estudo.  Nesses casos, a  principal diferenca  foi  o metodo de normalizacao  aplicado aos termos. Esses casos de estudos foram nomeados e organizados da seguinte  forma: Caso de referencia usando Stemming: utiliza unigrama em nivel de palavra e usa  como  metodo de normalizacao o  Stemming.  Usamos o  stemmer 6  de Caldas  Junior e outros [Caldas Junior  et al., 2001]  cuja  implementacao e baseada no  algoritmo de Porter [Porter, 1980]. Caso de  referencia  usando Lematizacao: usa unigrama em nivel de palavra  tambem, mas utiliza como forma de normalizacao a lematizacao. Os textos que  utilizamos do  corpus  PLNBR CATEG foram lematizados pela ferramenta  FORMA, desenvolvida por Marco Gonzalez e discutida em [Gonzalez  et al.,  2006].  Caso de estudo usando ngramas de caractere: aplica ngramas iniciais em nivel  de caractere  como metodo de normalizacao morfologica. Para este caso, foram  testados  os seguintes valores de  n:  {3,4,5,6,7}.  Para definir  esse intervalo,  inicialmente, analisamos o comprimento medio das palavras existentes nos  textos de nosso estudo. Descobrimos que, em media, as palavras possuiam  5 Usamos a stoplist definida por Stanley Loh, que esta disponivel em  http://miningtext.blogspot.com.br/2008/11/listasdestopwordsstoplistportugues.html 6 http://www.nilc.icmc.usp.br/nilc/tools/stemmer.html n-Gramas de Caractere como T  ecnica de Normalizac ao Morfol  ogica para L  ngua Portuguesa: Um Estudo em Categorizac ao de Textos 215 comprimento igual a 5. A partir dessa informacao, decidimos investigar  ngramas iniciais de caractere cuja diferenca de comprimento variava de 2 a +2  em relacao a media. Consideramos que comprimento n=2 seria muito pequeno  para um pseudoradical, assim como 8 seria muito longo. Cabe ressaltar que sao  definidos  ngramas de  caractere apenas  palavras  nos quais  o  comprimento e  maior que o valor de n. No caso do comprimento ser menor ou igual, a palavra e  mantida e considerada na sua forma original (inteira). Os resultados obtidos a partir desses casos de estudo sao comentados nas secoes  a seguir. 4.2. Resultados do Caso de Referencia usando Stemming Neste caso de referencia, realizamos  o preprocessamento descrito anteriormente e  aplicamos  a normalizacao  por  stemming.  Avaliamos  diferentes  comprimentos  k  para  bagofwords,  onde  k=  {50,100, 150, 200, 250}. Os melhores resultados foram  encontrados quando  definimos  bagofwords  de  150  termos  para cada categoria. A  Tabela 1 exibe os valores das medidas  Precision,  Recall  e F1, por categoria, para  a  melhor configuracao encontrada para este caso. Tabela 1  Melhor resultado para o caso de de referencia usando stemming, com k=150 Categoria Precision Recall F1 Mundo 0,51 0,82 0,63 Brasil  0,65 0,62 0,64 Cotidiano 0,74 0,66 0,71 Dinheiro 0,73 0,73 0,73 Esporte 0,96 0,91 0,94 Ilustrada 0,76 0,89 0,82 Media 0,73 0,77 0,75 A categoria Esporte foi a que obteve melhor classificacao, provavelmente por  utilizar um vocabulario mais constante. Os textos usados comentam 11 anos de esporte.  Mesmo para um intervalo tao grande de tempo como esse, o termos usados nessa area  pouco se alteraram. Diferente da categoria Mundo, para qual o classificador gerou o  pior resultado em precisao. No espaco de 11 anos, muito do que se escreve sobre o  mundo e e noticia mudou, o que deve ter provocado uma variacao maior nos termos. 4.3. Resultados do Caso de Referencia usando Lematizacao Neste  caso  de  referencia, realizamos  o mesmo  preprocessamento,  mas  aplicamos  a  normalizacao  por  lematizacao.  Tambem usamos o mesmo classificador e testamos  igualmente diferentes valores para k ={50,100, 150, 200, 250}.  O melhor resultado da  tambem foi para k=150. A Tabela  2 exibe os valores das medidas  Precision, Recall e  F1, por categoria, para a melhor configuracao encontrada para este caso. n-Gramas de Caractere como T  ecnica de Normalizac ao Morfol  ogica para L  ngua Portuguesa: Um Estudo em Categorizac ao de Textos 216 Tabela 2  Melhor resultado para o caso de referencia usando lematizacao, com k=150 Categoria Precision Recall F1 Mundo 0,39 0,85 0,53 Brasil  0,68 0,59 0,63 Cotidiano 0,73 0,64 0,68 Dinheiro 0,71 0,68 0,70 Esporte 0,96 0,80 0,87 Ilustrada 0,73 0,83 0,77 Media 0,73 0,70 0,71 Nesse estudo,  os resultados  gerais de  classificacao  cairam um  pouco,  mas o  Recall teve uma pequena melhora na maioria das categorias. 4.4. Resultado do Caso de Estudo usando nGramas Iniciais de Caractere Neste caso tambem aplicamos o mesmo preprocessamento, mas usamos conflacao por  ngramas iniciais de caractere. Repetimos o estudo usando o comprimento k=150, que  foi o que gerou melhores  resultados nos casos de referencia  apresentados. Para esta  configuracao, foram testados os valores de n={3,4,5,6,7}. A Tabela 3 exibe os valores  das medidas  Precision,  Recall  e F1, por categoria, para  a melhor configuracao  encontrada, que foi para n=5. Tabela 3  Melhor resultado para o caso de ngramas iniciais de caractere, com k=150 e  n=5 Categoria Precision Recall F1 Mundo 0,49 0,82 0,62 Brasil  0,67 0,62 0,64 Cotidiano 0,78 0,68 0,72 Dinheiro 0,72 0,72 0,72 Esporte 0,96 0,91 0,94 Ilustrada 0,78 0,88 0,82 Media 0,76 0,74 0,75 Os resultados obtidos com esta abordagem se aproximaram muito a do caso de  referencia usando  stemming.  Esse resultado e interessante, pois indica que uma  abordagem mais simples e, portanto, com menor exigencia computacional pode ser uma  alternativa  quando  o  tempo  de resposta e tao  importante  quanto  bons  resultados  de  classificacao.  Na secao seguinte, comparamos os casos de estudo apresentados. 4.5. Analise Geral dos Resultados No grafico apresentado  pela Figura 1, comparamos as medidas  Precision, Recall e F1  dos melhores casos de referencia  para stemming e lematizacao com os casos baseados  em ngramas iniciais de caractere (NGC). Analisando o grafico percebemos que a partir de n=5 para ngramas de caractere  n-Gramas de Caractere como T  ecnica de Normalizac ao Morfol  ogica para L  ngua Portuguesa: Um Estudo em Categorizac ao de Textos 217 (NGC_n=5), os resultados de categorizacao nao melhoraram. Isso aconteceu  provavelmente porque o comprimento medio das palavras do corpus era 5, ou seja, nao  deveriam existir muitas palavras com comprimento maior ou igual a 6. Em relacao aos  casos de referencia, no estudo que fizemos, os  ngramas iniciais de caractere foram  competitivos e resultaram em valores proximos ou ligeiramente melhores  que as  normalizacoes tradicionais. No entanto, precisamos realizar um estudo mais abrangente  incluindo outros  corpora  e outros algoritmos de  stemming  e lematizacao para  considerarmos os resultados mais conclusivos. De qualquer forma, acreditamos que a  abordagem e uma alternativa atrativa, pois e simples, demanda pouco processamento e  nao requer praticamente tratamento linguistico. Figura 1  Comparacao dos casos de estudo 5. Conclusao A  classificacao de textos e uma area  que tem muita  aplicabilidade,  especialmente na  web,  onde ha muitos  documentos disponiveis em formato digital.  Dado ao  grande  volume de  textos  nesse ambito, e importante  aprimorar  tanto a  precisao  quanto  a  escalabilidade  de  sistemas  classificadores.  Para isso  e imprescindivel  que exista  um  preprocessamento mais efetivo dos textos, com baixo custo computacional, para tratar  e selecionar somente os termos mais relevantes, a fim de reduzir a alta dimensionalidade  comum nessa tarefa. Acreditamos que a abordagem de ngramas iniciais pode ser usada para lingua  portuguesa  como metodo de normalizacao  linguistica, pois, alem de ser simples, seu  custo computacional e baixo.  As vantagens oferecidas pela abordagem a tornam  competitiva em ambientes onde o custo computacional e muito relevante. Embora mais  estudos precisem ser realizados, acreditamos, com base no nosso estudo, que o tamanho  medio das palavras do  corpus  possa  ser um bom valor inicial para definir o  comprimento (n) do  ngramas  de caractere.  Faz parte de nossos trabalhos futuros,  expandir nosso estudo testando  outros  corpora  e  outros  algoritmos  de normalizacao  morfologica para a lingua portuguesa.   Stemming Lematizacao NGC_n=3 NGC_n=4 NGC_n=5 NGC_n=6 NGC_n=7 0.67 0.68 0.69 0.7 0.71 0.72 0.73 0.74 0.75 0.76 0.77 Comparacao dos Casos de Estudo PLN_BR CATEG com k=150 Pr Re F1 Tecnica de Normalizacao Medidas de Classificacao n-Gramas de Caractere como T  ecnica de Normalizac ao Morfol  ogica para L  ngua Portuguesa: Um Estudo em Categorizac ao de Textos 218 Referencias Batista,  G.,  Prati,  R.C.  e  Monard,  M.C.  (2004). A study of the behavior of several  methods for balancing machine learning training data. SIGKDD Explor. Newsl.6, 1  (June 2004), 2029. Caldas Junior, J.; Imamura, C.Y, M. e Rezende, S.O. (2001).Avaliacao de um  Algoritmo de Stemming para Lingua Portuguesa. In the Proceedings of the 2nd  Congress of Logic Applied to Technology, Vol. 2, 267274. Cavnar, W. B e  Trenkle, J. M. (1994). NGramBased Text Categorization. In Ann  Arbor MI, Vol. 48113, No. 2, 161175 . Diyanati, M.H, Sadreddini, M. H., Rasekh, A. H, Fakhrahmad, S. M. e TaghiZadeh, H.  (2014). Words Stemming Based on Structural and Semantic Similarity. In  Computer Engineering and Applications, Vol. 3, No. 2, 8999. Galvez, C., MoyaAnegon, F. e Solana, V. H. (2005). Term conflation methods  in  information retrieval: nonlinguistic and linguistic approaches. In Journal of  Documentation , Vol. 61, No. 4, 520547. Gonzalez, M. e Lima, V. L. S. (2003). Recuperacao de Informacao e Processamento da  Linguagem Natural.  In XXIII Congresso da Sociedade Brasileira de Computacao,  Campinas, Anais do III Jornada de MiniCursos de Inteligencia Artificial, Volume  III, 347395. Gonzalez, M., Lima, V. L. S.  e Lima, J. V. (2006) Tools for Nominalization: an  Alternative for Lexical Normalization, In the Proceedings of the 7th Workshop on  Computational  Processing of the  Portuguese Language  Written and Spoken,  PROPOR 2006, SpringerVerlag, p.100109. Graovac, J. (2012). Serbian text categorization using byte level ngrams.  In  Proceedings CLoBL, 9397. Hassan, F. I. H e Chaurasia, M. A. (2012). NGram Based Text Author Verification.  In International Conference on Innovation and Information Management (ICIIM  2012), Vol. 36, 6771. Japkowicz,  N.  e  Stephen,  S.  (2002). The class imbalance problem: A systematic  study, Intell. Data Anal.6, 5 , 429449. Jivani, A. G. (2011). A Comparative Study of Stemming Algorithms. In  International Journal Comp. Tech. Appl., Vol 2 ., No. 6, 19301938 Kumari, K.P., Reddy, A.V. e Fatima, S . (2014). Web Page Genre Classification:  Impact of nGram Lengths. In International Journal of Computer Applications, Vol.  88, No.13, 1317. Manning, C.D. e Schutze, H. (1999). Foundations of Statistical Natural Language  Processing. MIT Press. Mayfield, J. e McNamee,P. (2003)  Single Ngram Stemming, In Proceedings of the  26th annual international ACM SIGIR conference on Research and development in  information retrieval, 415416. Porter, M. (1980).  An algorithm for suffix stripping.  Program,  14(3), 130137.  http://www.tartarus.org/~martin/PorterStemmer/def.txt. n-Gramas de Caractere como T  ecnica de Normalizac ao Morfol  ogica para L  ngua Portuguesa: Um Estudo em Categorizac ao de Textos 219 Rahmoun, A. e Zakaria, E. (2007). Experimenting Ngrams in text categorization, In  International Arab Journal of Information Technology, Vol. 4, No. 4, 377385. Sharma, D. (2012). Stemming Algorithms: A Comparative Study and their Analysis.  In International Journal of Applied Information Systems (IJAIS), Vol. 4, No. 3, 712.  Sebastiani, F. (2002). Machine Learning in Automated Text Categorization, In ACM  Computing Surveys, Vol. 34, No. 1, 147,  ACM. n-Gramas de Caractere como T  ecnica de Normalizac ao Morfol  ogica para L  ngua Portuguesa: Um Estudo em Categorizac ao de Textos 220 </chunk></section></sec_map>